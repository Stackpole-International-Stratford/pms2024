<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>prod_query.views API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>prod_query.views</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="prod_query.views.add_partial_block_to_friday"><code class="name flex">
<span>def <span class="ident">add_partial_block_to_friday</span></span>(<span>start_date, ranges)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_partial_block_to_friday(start_date, ranges):
    &#34;&#34;&#34;
    Add a partial time block from the given start_date (adjusted to 11 PM) 
    to the upcoming Friday at 11 PM, and append it to the provided ranges list.

    Parameters:
        start_date (datetime): The starting date and time to adjust from.
        ranges (list): A list of tuples representing start and end datetime ranges.

    Returns:
        datetime: The next Sunday at 11 PM (23:00:00), following the calculated Friday.
        
    Example:
        If start_date is 2025-01-01 10:00:00 (a Wednesday),
        and ranges is an empty list, the function will:
        - Append the block (2025-01-01 23:00:00, 2025-01-03 23:00:00) to ranges.
        - Return 2025-01-05 23:00:00 (the next Sunday at 11 PM).
    &#34;&#34;&#34;
    # Adjust the start_date to 11 PM by setting the time component
    start_date = start_date.replace(hour=23, minute=0, second=0, microsecond=0)

    # Initialize upcoming_friday to the start_date
    upcoming_friday = start_date

    # Loop until the day of the week is Friday (weekday() returns 4 for Friday)
    while upcoming_friday.weekday() != 4:
        upcoming_friday += timedelta(days=1)  # Increment by one day until Friday is reached

    # Set the time on upcoming_friday to 11 PM
    upcoming_friday = upcoming_friday.replace(hour=23, minute=0, second=0)

    # Check if the block has a meaningful duration (start_date is before upcoming_friday)
    if start_date &lt; upcoming_friday:
        # Append the time block as a tuple (start_date, upcoming_friday) to the ranges list
        ranges.append((start_date, upcoming_friday))

    # Calculate the next Sunday (two days after Friday)
    next_sunday = upcoming_friday + timedelta(days=2)

    # Return the next Sunday with time adjusted to 11 PM
    return next_sunday.replace(hour=23, minute=0, second=0)</code></pre>
</details>
<div class="desc"><p>Add a partial time block from the given start_date (adjusted to 11 PM)
to the upcoming Friday at 11 PM, and append it to the provided ranges list.</p>
<h2 id="parameters">Parameters</h2>
<p>start_date (datetime): The starting date and time to adjust from.
ranges (list): A list of tuples representing start and end datetime ranges.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>datetime</code></dt>
<dd>The next Sunday at 11 PM (23:00:00), following the calculated Friday.</dd>
</dl>
<h2 id="example">Example</h2>
<p>If start_date is 2025-01-01 10:00:00 (a Wednesday),
and ranges is an empty list, the function will:
- Append the block (2025-01-01 23:00:00, 2025-01-03 23:00:00) to ranges.
- Return 2025-01-05 23:00:00 (the next Sunday at 11 PM).</p></div>
</dd>
<dt id="prod_query.views.adjust_target_to_effective_date"><code class="name flex">
<span>def <span class="ident">adjust_target_to_effective_date</span></span>(<span>target_date)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adjust_target_to_effective_date(target_date):
    &#34;&#34;&#34;
    Calculate the effective date for a production target given any date within the target week.

    The effective date is defined as the Sunday of the week immediately preceding the ISO week 
    containing `target_date`.

    Parameters
    ----------
    target_date : datetime.date
        Any date within the ISO week for which you want to find the previous Sunday effective date.

    Returns
    -------
    datetime.date
        The date of the Sunday immediately before the ISO week of `target_date`.

    Example
    -------
    &gt;&gt;&gt; adjust_target_to_effective_date(date(2025, 6, 18))  # a Wednesday in week 25
    datetime.date(2025, 6, 8)  # Sunday of week 24
    &#34;&#34;&#34;
    (temp_year,temp_week,temp_day) = target_date.isocalendar()
    effective_date = date.fromisocalendar(year=temp_year, week=temp_week, day=7)
    effective_date -= timedelta(days = 7)
    return effective_date</code></pre>
</details>
<div class="desc"><p>Calculate the effective date for a production target given any date within the target week.</p>
<p>The effective date is defined as the Sunday of the week immediately preceding the ISO week
containing <code>target_date</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>target_date</code></strong> :&ensp;<code>datetime.date</code></dt>
<dd>Any date within the ISO week for which you want to find the previous Sunday effective date.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>datetime.date</code></dt>
<dd>The date of the Sunday immediately before the ISO week of <code>target_date</code>.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; adjust_target_to_effective_date(date(2025, 6, 18))  # a Wednesday in week 25
datetime.date(2025, 6, 8)  # Sunday of week 24
</code></pre></div>
</dd>
<dt id="prod_query.views.aggregate_line_metrics"><code class="name flex">
<span>def <span class="ident">aggregate_line_metrics</span></span>(<span>metrics)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate_line_metrics(metrics):
    &#34;&#34;&#34;
    Aggregate metrics across all time blocks for a line.

    Args:
        metrics (dict): Metrics returned by `fetch_line_metrics`.

    Returns:
        list: Aggregated metrics for each machine.
    &#34;&#34;&#34;
    aggregated_data = {}
    # print(&#34;[INFO] Starting aggregation of line metrics&#34;)

    for block in metrics[&#39;details&#39;][:10]:  # Only process the first 10 blocks for debugging
        for machine in block[&#39;machines&#39;]:
            try:
                aggregate_machine_metrics(machine, aggregated_data)
            except KeyError as e:
                print(f&#34;[WARNING] Missing data for machine: {machine.get(&#39;machine_id&#39;, &#39;Unknown&#39;)} - {e}&#34;)

    # print(&#34;[INFO] Aggregated data for first 10 blocks:&#34;, aggregated_data)
    return list(aggregated_data.values())</code></pre>
</details>
<div class="desc"><p>Aggregate metrics across all time blocks for a line.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>metrics</code></strong> :&ensp;<code>dict</code></dt>
<dd>Metrics returned by <code><a title="prod_query.views.fetch_line_metrics" href="#prod_query.views.fetch_line_metrics">fetch_line_metrics()</a></code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>Aggregated metrics for each machine.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.aggregate_machine_groups"><code class="name flex">
<span>def <span class="ident">aggregate_machine_groups</span></span>(<span>machines_data, group_definitions)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate_machine_groups(machines_data, group_definitions):
    &#34;&#34;&#34;
    Aggregates machine totals for defined groups and returns a dictionary of aggregated totals.
    
    Args:
        machines_data (dict): Original machine data with each machine having a &#39;totals&#39; dictionary.
        group_definitions (dict): Mapping from group label to a list of machine IDs to aggregate.
            Example: {&#39;1500T&#39;: [&#39;272&#39;, &#39;273&#39;]}
    
    Returns:
        dict: A dictionary mapping each group label to a totals dictionary that mirrors the structure
              of an individual machine&#39;s totals.
    &#34;&#34;&#34;
    aggregated = {}
    for group_label, machine_list in group_definitions.items():
        total_minutes_up = 0
        total_unplanned_down = 0
        total_planned_down = 0
        total_potential_minutes = 0
        total_parts_produced = 0
        total_target = 0
        weighted_cycle_sum = 0  # Sum of (machine weighted cycle * machine potential minutes)
        potential_for_weight = 0  # Sum of potential minutes (to weight the cycle time)
        block_range = &#34;&#34;
        
        for m in machine_list:
            machine_totals = machines_data.get(m, {}).get(&#39;totals&#39;)
            if machine_totals:
                total_minutes_up += machine_totals.get(&#39;total_minutes_up&#39;, 0)
                total_unplanned_down += machine_totals.get(&#39;total_unplanned_down&#39;, 0)
                total_planned_down += machine_totals.get(&#39;total_planned_down&#39;, 0)
                tp = machine_totals.get(&#39;total_potential_minutes&#39;, 0)
                total_potential_minutes += tp
                total_parts_produced += machine_totals.get(&#39;total_parts_produced&#39;, 0)
                tot_target = machine_totals.get(&#39;total_target&#39;, 0)
                if isinstance(tot_target, (int, float)):
                    total_target += tot_target
                # Use each machine&#39;s potential minutes as weight for its cycle time
                wc = machine_totals.get(&#39;weighted_cycle&#39;, 0)
                if isinstance(wc, (int, float)) and tp:
                    weighted_cycle_sum += wc * tp
                    potential_for_weight += tp
                # Use the block range from the first machine (if available)
                if not block_range:
                    block_range = machine_totals.get(&#39;block&#39;, &#34;&#34;)
        
        if potential_for_weight:
            weighted_cycle = weighted_cycle_sum / potential_for_weight
        else:
            weighted_cycle = &#34;N/A&#34;
        
        # Compute availability, performance, and OEE
        availability = (total_minutes_up / total_potential_minutes) if total_potential_minutes else 0
        performance = (total_parts_produced / total_target) if total_target else 0
        oee = availability * performance
        
        aggregated[group_label] = {
            &#39;block&#39;: block_range,
            &#39;total_minutes_up&#39;: total_minutes_up,
            &#39;total_unplanned_down&#39;: total_unplanned_down,
            &#39;total_planned_down&#39;: total_planned_down,
            &#39;total_potential_minutes&#39;: total_potential_minutes,
            &#39;weighted_cycle&#39;: round(weighted_cycle, 2) if isinstance(weighted_cycle, (int, float)) else weighted_cycle,
            &#39;total_parts_produced&#39;: total_parts_produced,
            &#39;total_target&#39;: total_target,
            &#39;availability&#39;: round(availability, 2),
            &#39;performance&#39;: round(performance, 2),
            &#39;oee&#39;: round(oee, 2)
        }
    return aggregated</code></pre>
</details>
<div class="desc"><p>Aggregates machine totals for defined groups and returns a dictionary of aggregated totals.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>machines_data</code></strong> :&ensp;<code>dict</code></dt>
<dd>Original machine data with each machine having a 'totals' dictionary.</dd>
<dt><strong><code>group_definitions</code></strong> :&ensp;<code>dict</code></dt>
<dd>Mapping from group label to a list of machine IDs to aggregate.
Example: {'1500T': ['272', '273']}</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary mapping each group label to a totals dictionary that mirrors the structure
of an individual machine's totals.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.aggregate_machine_metrics"><code class="name flex">
<span>def <span class="ident">aggregate_machine_metrics</span></span>(<span>machine, aggregated_data)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate_machine_metrics(machine, aggregated_data):
    &#34;&#34;&#34;
    Aggregate metrics for a single machine across multiple time blocks.

    Args:
        machine (dict): Metrics for the machine from a time block.
        aggregated_data (dict): Dictionary to update with aggregated values for the machine.

    Returns:
        None: Updates the aggregated_data in place.
    &#34;&#34;&#34;
    machine_id = machine[&#39;machine_id&#39;]
    try:
        if machine_id not in aggregated_data:
            # Initialize the data for this machine
            aggregated_data[machine_id] = {
                &#39;machine_id&#39;: machine_id,
                &#39;total_produced&#39;: 0,
                &#39;total_target&#39;: 0,
                &#39;total_adjusted_target&#39;: 0,  # To sum adjusted targets across blocks
                &#39;total_downtime&#39;: 0,
                &#39;total_potential_minutes&#39;: 0
            }

        # Update aggregated values by summing them
        aggregated_data[machine_id][&#39;total_produced&#39;] += machine.get(&#39;produced&#39;, 0)
        aggregated_data[machine_id][&#39;total_target&#39;] += machine.get(&#39;target&#39;, 0)
        aggregated_data[machine_id][&#39;total_adjusted_target&#39;] += machine.get(&#39;adjusted_target&#39;, 0)
        aggregated_data[machine_id][&#39;total_downtime&#39;] += machine.get(&#39;total_downtime&#39;, 0)
        aggregated_data[machine_id][&#39;total_potential_minutes&#39;] += machine.get(&#39;total_potential_minutes&#39;, 0)

        if aggregated_data[machine_id][&#39;total_produced&#39;] is None:
            print(f&#34;[WARNING] Total produced is None for machine {machine_id}&#34;)

    except TypeError as e:
        print(f&#34;[ERROR] Issue aggregating data for machine {machine_id}: {e}&#34;)</code></pre>
</details>
<div class="desc"><p>Aggregate metrics for a single machine across multiple time blocks.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>dict</code></dt>
<dd>Metrics for the machine from a time block.</dd>
<dt><strong><code>aggregated_data</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary to update with aggregated values for the machine.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>Updates the aggregated_data in place.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.aggregate_operation_totals"><code class="name flex">
<span>def <span class="ident">aggregate_operation_totals</span></span>(<span>operation)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate_operation_totals(operation):
    &#34;&#34;&#34;
    Given an operation dict, iterate through its machines (which are already
    fetched and included) and calculate the totals for:
      - Parts (total produced)
      - Target
      - Downtime
      - Planned Downtime
      - Unplanned Downtime
    Optionally, also calculate a downtime percentage.
    
    The downtime percentage might be defined differently depending on your
    overall time or target calculation. In this example, we assume a simple
    weighted percent based on downtime over a fixed period if available.
    
    Modify the keys as needed to match your machine data structure.
    &#34;&#34;&#34;
    totals = {
        &#34;total_parts&#34;: 0,
        &#34;total_target&#34;: 0,
        &#34;total_downtime&#34;: 0,
        &#34;total_planned_downtime&#34;: 0,
        &#34;total_unplanned_downtime&#34;: 0,
    }

    # Iterate over each machine&#39;s data in the current operation.
    for machine in operation.get(&#34;machines&#34;, []):
        totals[&#34;total_parts&#34;] += machine.get(&#34;produced_parts&#34;, 0)
        totals[&#34;total_target&#34;] += machine.get(&#34;target&#34;, 0)
        totals[&#34;total_downtime&#34;] += machine.get(&#34;downtime_minutes&#34;, 0)
        totals[&#34;total_planned_downtime&#34;] += machine.get(&#34;planned_downtime_minutes&#34;, 0)
        totals[&#34;total_unplanned_downtime&#34;] += machine.get(&#34;unplanned_downtime_minutes&#34;, 0)
    
    # Optionally, calculate downtime percentage. This could be, for example, the
    # total downtime divided by the aggregated potential minutes across all machines.
    # If each machine uses the same queried minutes (e.g., `total_queried_minutes`),
    # you might do something like:
    #
    # total_queried_minutes = operation.get(&#34;total_queried_minutes&#34;, some_default_value)
    # if total_queried_minutes &gt; 0:
    #     totals[&#34;downtime_percentage&#34;] = (totals[&#34;total_downtime&#34;] / total_queried_minutes) * 100
    # else:
    #     totals[&#34;downtime_percentage&#34;] = 0
    #
    # For now, let’s assume you have a known value or it’s computed elsewhere.
    totals[&#34;downtime_percentage&#34;] = compute_downtime_percentage(totals)  # You can write this helper too.
    
    return totals</code></pre>
</details>
<div class="desc"><p>Given an operation dict, iterate through its machines (which are already
fetched and included) and calculate the totals for:
- Parts (total produced)
- Target
- Downtime
- Planned Downtime
- Unplanned Downtime
Optionally, also calculate a downtime percentage.</p>
<p>The downtime percentage might be defined differently depending on your
overall time or target calculation. In this example, we assume a simple
weighted percent based on downtime over a fixed period if available.</p>
<p>Modify the keys as needed to match your machine data structure.</p></div>
</dd>
<dt id="prod_query.views.annotate_targets"><code class="name flex">
<span>def <span class="ident">annotate_targets</span></span>(<span>qs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def annotate_targets(qs):
    &#34;&#34;&#34;Add .effective_date_est and .cycle_time_seconds on each.&#34;&#34;&#34;
    est = ZoneInfo(&#34;America/New_York&#34;)
    total_seconds = 7200 * 60
    for t in qs:
        dt_utc = datetime.fromtimestamp(t.effective_date_unix, tz=ZoneInfo(&#34;UTC&#34;))
        t.effective_date_est = dt_utc.astimezone(est)
        t.cycle_time_seconds = (total_seconds / t.target) if t.target else None
    return qs</code></pre>
</details>
<div class="desc"><p>Add .effective_date_est and .cycle_time_seconds on each.</p></div>
</dd>
<dt id="prod_query.views.apply_color_gradient_to_line"><code class="name flex">
<span>def <span class="ident">apply_color_gradient_to_line</span></span>(<span>machine_metrics, metric_key, color_key)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_color_gradient_to_line(machine_metrics, metric_key, color_key):
    &#34;&#34;&#34;
    Applies a color gradient to machines in a single line based on their ranking,
    ensuring an even distribution of colors (red for worst, green for best).

    :param machine_metrics: Dict with machine IDs as keys and metric dictionaries as values.
    :param metric_key: The key for the metric (e.g., &#34;P&#34;, &#34;A&#34;, or &#34;adjusted_downtime_percentage&#34;).
    :param color_key: The key to store the resulting color hex (e.g., &#34;P_color&#34;, &#34;A_color&#34;, or &#34;downtime_percentage_color&#34;).
    &#34;&#34;&#34;
    # Gather (machine_id, value) pairs for machines that have the metric.
    items = [(machine_id, data[metric_key]) for machine_id, data in machine_metrics.items() if data.get(metric_key) is not None]
    if not items:
        print(f&#34;[apply_color_gradient_to_line] No values found for metric key: &#39;{metric_key}&#39;.&#34;)
        return

    # Sort the list by metric value (ascending).
    items.sort(key=lambda x: x[1])
    total = len(items)

    # Assign each machine a normalized ratio based on its rank.
    for rank, (machine_id, value) in enumerate(items):
        # Normalize rank from 0 to 1. If total is 1, default to 0.5.
        ratio = rank / (total - 1) if total &gt; 1 else 0.5
        color_hex = get_color_for_ratio(ratio)
        machine_metrics[machine_id][color_key] = color_hex</code></pre>
</details>
<div class="desc"><p>Applies a color gradient to machines in a single line based on their ranking,
ensuring an even distribution of colors (red for worst, green for best).</p>
<p>:param machine_metrics: Dict with machine IDs as keys and metric dictionaries as values.
:param metric_key: The key for the metric (e.g., "P", "A", or "adjusted_downtime_percentage").
:param color_key: The key to store the resulting color hex (e.g., "P_color", "A_color", or "downtime_percentage_color").</p></div>
</dd>
<dt id="prod_query.views.apply_color_gradient_to_line_reversed"><code class="name flex">
<span>def <span class="ident">apply_color_gradient_to_line_reversed</span></span>(<span>machine_metrics, metric_key, color_key)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_color_gradient_to_line_reversed(machine_metrics, metric_key, color_key):
    &#34;&#34;&#34;
    Same as apply_color_gradient_to_line, but inverts the ratio so that
    higher metric values map to red and lower to green.
    :param machine_metrics: Dict with IDs → metric dicts
    :param metric_key: which value to rank (e.g. &#34;downtime_percentage&#34;)
    :param color_key: where to store the hex (e.g. &#34;downtime_percentage_color&#34;)
    &#34;&#34;&#34;
    # Gather (id, value) pairs
    items = [
        (mid, data[metric_key])
        for mid, data in machine_metrics.items()
        if data.get(metric_key) is not None
    ]
    if not items:
        print(f&#34;[apply_color_gradient_to_line_reversed] No &#39;{metric_key}&#39; values found.&#34;)
        return

    # Sort ascending by value
    items.sort(key=lambda x: x[1])
    total = len(items)

    # For each rank, compute inverted ratio and assign color
    for rank, (machine_id, value) in enumerate(items):
        # standard 0→1 ratio
        ratio = rank / (total - 1) if total &gt; 1 else 0.5
        # invert it: worst (highest value) now gets ratio=0, best=1
        inv_ratio = 1 - ratio
        machine_metrics[machine_id][color_key] = get_color_for_ratio(inv_ratio)</code></pre>
</details>
<div class="desc"><p>Same as apply_color_gradient_to_line, but inverts the ratio so that
higher metric values map to red and lower to green.
:param machine_metrics: Dict with IDs → metric dicts
:param metric_key: which value to rank (e.g. "downtime_percentage")
:param color_key: where to store the hex (e.g. "downtime_percentage_color")</p></div>
</dd>
<dt id="prod_query.views.attach_spm_chart_data_to_blocks"><code class="name flex">
<span>def <span class="ident">attach_spm_chart_data_to_blocks</span></span>(<span>time_blocks, machine, interval=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def attach_spm_chart_data_to_blocks(time_blocks, machine, interval=5):
    &#34;&#34;&#34;
    For each time block in the provided list, fetch the strokes per minute chart data 
    using the given machine and time block start/end times, and attach it to the block.

    Args:
        time_blocks (list of dict): Each dict should include at least &#39;block_start&#39; and &#39;block_end&#39;.
            If available, &#39;raw_block_start&#39; and &#39;raw_block_end&#39; should contain datetime objects.
        machine (str): The machine identifier used to fetch the SPM data.
        interval (int): Interval (in minutes) for calculating strokes per minute data. Default is 5.
        
    Returns:
        list of dict: The original list, with each block now including:
                      - &#39;chart_labels&#39;: list of timestamps (for ChartJS labels)
                      - &#39;chart_counts&#39;: list of stroke rates (for ChartJS data)
    &#34;&#34;&#34;

    for block in time_blocks:
        # Use raw datetime objects if available; otherwise, parse the formatted strings.
        if &#39;raw_block_start&#39; in block and &#39;raw_block_end&#39; in block:
            block_start_dt = block[&#39;raw_block_start&#39;]
            block_end_dt = block[&#39;raw_block_end&#39;]
        else:
            block_start_dt = datetime.strptime(block[&#39;block_start&#39;], &#39;%Y-%m-%d %H:%M:%S&#39;)
            block_end_dt = datetime.strptime(block[&#39;block_end&#39;], &#39;%Y-%m-%d %H:%M:%S&#39;)
            
        start_ts = int(block_start_dt.timestamp())
        end_ts = int(block_end_dt.timestamp())
        
        # Get the chart data using your existing strokes_per_minute_chart_data function
        labels, counts = strokes_per_minute_chart_data(machine, start_ts, end_ts, interval)
        
        # Attach the fetched chart data to the block dictionary
        block[&#39;chart_labels&#39;] = labels
        block[&#39;chart_counts&#39;] = counts
        
    return time_blocks</code></pre>
</details>
<div class="desc"><p>For each time block in the provided list, fetch the strokes per minute chart data
using the given machine and time block start/end times, and attach it to the block.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>time_blocks</code></strong> :&ensp;<code>list</code> of <code>dict</code></dt>
<dd>Each dict should include at least 'block_start' and 'block_end'.
If available, 'raw_block_start' and 'raw_block_end' should contain datetime objects.</dd>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>The machine identifier used to fetch the SPM data.</dd>
<dt><strong><code>interval</code></strong> :&ensp;<code>int</code></dt>
<dd>Interval (in minutes) for calculating strokes per minute data. Default is 5.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>dict</code></dt>
<dd>The original list, with each block now including:
- 'chart_labels': list of timestamps (for ChartJS labels)
- 'chart_counts': list of stroke rates (for ChartJS data)</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_A"><code class="name flex">
<span>def <span class="ident">calculate_A</span></span>(<span>total_potential_minutes, downtime_minutes)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_A(total_potential_minutes, downtime_minutes):
    &#34;&#34;&#34;
    Compute the availability (A) percentage for a line or operation.

    Calculates:
      A = ((total_potential_minutes - downtime_minutes) / total_potential_minutes) * 100,
      rounded to the nearest integer and returned as a percentage string.

    Special case:
      - If total_potential_minutes is zero, returns &#34;0%&#34; to avoid division by zero.

    Parameters
    ----------
    total_potential_minutes : numeric
        The total number of minutes the line could potentially run.
    downtime_minutes : numeric
        The total number of minutes the line was down.

    Returns
    -------
    str
        The availability percentage as a string with a &#34;%&#34; suffix.
    &#34;&#34;&#34;
    if total_potential_minutes == 0:
        return &#34;0%&#34;  # Avoid division by zero
    a_value = round(((total_potential_minutes - downtime_minutes) / total_potential_minutes) * 100)
    return f&#34;{a_value}%&#34;</code></pre>
</details>
<div class="desc"><p>Compute the availability (A) percentage for a line or operation.</p>
<h2 id="calculates">Calculates</h2>
<p>A = ((total_potential_minutes - downtime_minutes) / total_potential_minutes) * 100,
rounded to the nearest integer and returned as a percentage string.</p>
<p>Special case:
- If total_potential_minutes is zero, returns "0%" to avoid division by zero.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>total_potential_minutes</code></strong> :&ensp;<code>numeric</code></dt>
<dd>The total number of minutes the line could potentially run.</dd>
<dt><strong><code>downtime_minutes</code></strong> :&ensp;<code>numeric</code></dt>
<dd>The total number of minutes the line was down.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The availability percentage as a string with a "%" suffix.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_Q"><code class="name flex">
<span>def <span class="ident">calculate_Q</span></span>(<span>total_produced_last_op, scrap_total)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_Q(total_produced_last_op, scrap_total):
    &#34;&#34;&#34;
    Compute the quality (Q) percentage for the last operation.

    Calculates:
      Q = (total_produced_last_op / (total_produced_last_op + scrap_total)) * 100,
      rounded to two decimal places and returned as a percentage string.

    Special case:
      - If both produced and scrap totals are zero, returns &#34;0%&#34;.

    Parameters
    ----------
    total_produced_last_op : numeric
        The count of units successfully produced by the last operation.
    scrap_total : numeric
        The count of units scrapped.

    Returns
    -------
    str
        The quality percentage as a string with a &#34;%&#34; suffix, rounded to two decimals.
    &#34;&#34;&#34;
    if total_produced_last_op + scrap_total == 0:
        return &#34;0%&#34;
    q_value = round((total_produced_last_op / (total_produced_last_op + scrap_total) * 100), 2)
    return f&#34;{q_value}%&#34;</code></pre>
</details>
<div class="desc"><p>Compute the quality (Q) percentage for the last operation.</p>
<h2 id="calculates">Calculates</h2>
<p>Q = (total_produced_last_op / (total_produced_last_op + scrap_total)) * 100,
rounded to two decimal places and returned as a percentage string.</p>
<p>Special case:
- If both produced and scrap totals are zero, returns "0%".</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>total_produced_last_op</code></strong> :&ensp;<code>numeric</code></dt>
<dd>The count of units successfully produced by the last operation.</dd>
<dt><strong><code>scrap_total</code></strong> :&ensp;<code>numeric</code></dt>
<dd>The count of units scrapped.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The quality percentage as a string with a "%" suffix, rounded to two decimals.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_a_and_p_averages"><code class="name flex">
<span>def <span class="ident">calculate_a_and_p_averages</span></span>(<span>p_values, a_values, downtime_percentages)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_a_and_p_averages(p_values, a_values, downtime_percentages):
    &#34;&#34;&#34;
    Compute rounded averages for P, A, and downtime percentages after removing the most recent entry.

    This function mutates the input lists by popping the last element from `p_values` and `a_values` (if present),
    then calculates:
      - `average_p`: the rounded mean of the remaining `p_values` (or 0 if list is empty),
      - `average_a`: the rounded mean of the remaining `a_values` (or 0 if list is empty),
      - `average_downtime`: the rounded mean of `downtime_percentages` as an integer (or 0 if list is empty).

    Parameters
    ----------
    p_values : list of numbers
        A list of numeric P values. The last element will be removed before averaging.
    a_values : list of numbers
        A list of numeric A values. The last element will be removed before averaging.
    downtime_percentages : list of numbers
        A list of downtime percentage values. No elements are removed before averaging.

    Returns
    -------
    dict
        A dictionary with keys:
          - &#39;average_p&#39; (int):       Rounded average of the truncated `p_values`.
          - &#39;average_a&#39; (int):       Rounded average of the truncated `a_values`.
          - &#39;average_downtime&#39; (int): Rounded average of `downtime_percentages`.
    &#34;&#34;&#34;
    # Pop the last number off the lists if they are not empty
    if p_values:
        p_values.pop()
    if a_values:
        a_values.pop()

    average_p = round(sum(p_values) / len(p_values)) if p_values else 0
    average_a = round(sum(a_values) / len(a_values)) if a_values else 0
    average_downtime = int(round(sum(downtime_percentages) / len(downtime_percentages))) if downtime_percentages else 0

    return {
        &#39;average_p&#39;: average_p,
        &#39;average_a&#39;: average_a,
        &#39;average_downtime&#39;: average_downtime
    }</code></pre>
</details>
<div class="desc"><p>Compute rounded averages for P, A, and downtime percentages after removing the most recent entry.</p>
<p>This function mutates the input lists by popping the last element from <code>p_values</code> and <code>a_values</code> (if present),
then calculates:
- <code>average_p</code>: the rounded mean of the remaining <code>p_values</code> (or 0 if list is empty),
- <code>average_a</code>: the rounded mean of the remaining <code>a_values</code> (or 0 if list is empty),
- <code>average_downtime</code>: the rounded mean of <code>downtime_percentages</code> as an integer (or 0 if list is empty).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>p_values</code></strong> :&ensp;<code>list</code> of <code>numbers</code></dt>
<dd>A list of numeric P values. The last element will be removed before averaging.</dd>
<dt><strong><code>a_values</code></strong> :&ensp;<code>list</code> of <code>numbers</code></dt>
<dd>A list of numeric A values. The last element will be removed before averaging.</dd>
<dt><strong><code>downtime_percentages</code></strong> :&ensp;<code>list</code> of <code>numbers</code></dt>
<dd>A list of downtime percentage values. No elements are removed before averaging.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary with keys:
- 'average_p' (int):
Rounded average of the truncated <code>p_values</code>.
- 'average_a' (int):
Rounded average of the truncated <code>a_values</code>.
- 'average_downtime' (int): Rounded average of <code>downtime_percentages</code>.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_adjusted_target"><code class="name flex">
<span>def <span class="ident">calculate_adjusted_target</span></span>(<span>target, percentage_downtime)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_adjusted_target(target, percentage_downtime):
    &#34;&#34;&#34;
    Calculate the adjusted target based on:
    Adjusted Target = Target - (Target * (Downtime%))

    :param target: Original target value (int)
    :param percentage_downtime: Downtime percentage as a string (e.g., &#34;24%&#34;)
    :return: Adjusted target (int)
    &#34;&#34;&#34;
    try:
        downtime_fraction = float(percentage_downtime.strip(&#39;%&#39;)) / 100.0
        adjusted_target = target - (target * downtime_fraction)
        adjusted_target = round(adjusted_target)
        # Debug print:
        return adjusted_target
    except Exception as e:
        print(f&#34;Error in calculate_adjusted_target: {e}&#34;)
        # If there&#39;s an error, return original target (fallback)
        return target</code></pre>
</details>
<div class="desc"><p>Calculate the adjusted target based on:
Adjusted Target = Target - (Target * (Downtime%))</p>
<p>:param target: Original target value (int)
:param percentage_downtime: Downtime percentage as a string (e.g., "24%")
:return: Adjusted target (int)</p></div>
</dd>
<dt id="prod_query.views.calculate_average_downtime"><code class="name flex">
<span>def <span class="ident">calculate_average_downtime</span></span>(<span>metrics)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_average_downtime(metrics):
    &#34;&#34;&#34;
    Calculate the average percentage downtime for each machine across the time blocks.

    Args:
        metrics (dict): Metrics returned by `fetch_line_metrics`.

    Returns:
        dict: Average percentage downtime for each machine.
    &#34;&#34;&#34;
    machine_downtime_data = {}

    # Collect percentage downtime for each machine across time blocks
    for block in metrics[&#39;details&#39;]:
        for machine in block[&#39;machines&#39;]:
            machine_id = machine[&#39;machine_id&#39;]
            percentage_downtime = machine[&#39;percentage_downtime&#39;]

            # Remove &#39;%&#39; and convert to integer
            percentage_downtime_value = int(percentage_downtime.strip(&#39;%&#39;))

            if machine_id not in machine_downtime_data:
                machine_downtime_data[machine_id] = []

            machine_downtime_data[machine_id].append(percentage_downtime_value)

    # Calculate average percentage downtime for each machine
    average_downtime = {}
    for machine_id, downtimes in machine_downtime_data.items():
        average = sum(downtimes) / len(downtimes) if downtimes else 0
        average_downtime[machine_id] = average

        # Debugging: Print the calculated average downtime for each machine
        # print(f&#34;[DEBUG] Machine {machine_id}: Average Downtime = {average}% (from downtimes: {downtimes})&#34;)

    return average_downtime</code></pre>
</details>
<div class="desc"><p>Calculate the average percentage downtime for each machine across the time blocks.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>metrics</code></strong> :&ensp;<code>dict</code></dt>
<dd>Metrics returned by <code><a title="prod_query.views.fetch_line_metrics" href="#prod_query.views.fetch_line_metrics">fetch_line_metrics()</a></code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Average percentage downtime for each machine.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_downtime_events"><code class="name flex">
<span>def <span class="ident">calculate_downtime_events</span></span>(<span>cursor, machine_number, start_timestamp, end_timestamp)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_downtime_events(cursor, machine_number, start_timestamp, end_timestamp):
    import datetime
    &#34;&#34;&#34;Calculates downtime events (gaps &gt;5 minutes) based on production timestamps.&#34;&#34;&#34;
    query_ts = &#34;&#34;&#34;
        SELECT TimeStamp
        FROM GFxPRoduction
        WHERE Machine = %s AND TimeStamp BETWEEN %s AND %s
        ORDER BY TimeStamp ASC;
    &#34;&#34;&#34;
    cursor.execute(query_ts, (machine_number, start_timestamp, end_timestamp))
    
    downtime_seconds = 0
    downtime_events = []
    previous_ts = start_timestamp

    # Iterate row-by-row using fetchone() to save memory.
    row = cursor.fetchone()
    while row is not None:
        ts = row[0]
        gap = ts - previous_ts
        if gap &gt; 300:  # Only consider gaps &gt; 5 minutes
            downtime_seconds += gap
            event_minutes = int(gap / 60)
            event_start_str = datetime.datetime.fromtimestamp(previous_ts).strftime(&#34;%Y-%m-%d %H:%M&#34;)
            event_end_str = datetime.datetime.fromtimestamp(ts).strftime(&#34;%Y-%m-%d %H:%M&#34;)
            downtime_events.append({
                &#34;start&#34;: event_start_str,
                &#34;end&#34;: event_end_str,
                &#34;minutes_down&#34;: event_minutes
            })
        previous_ts = ts
        row = cursor.fetchone()

    # Check the final gap between the last timestamp and the end of the period.
    gap = end_timestamp - previous_ts
    if gap &gt; 300:
        downtime_seconds += gap
        event_minutes = int(gap / 60)
        event_start_str = datetime.datetime.fromtimestamp(previous_ts).strftime(&#34;%Y-%m-%d %H:%M&#34;)
        event_end_str = datetime.datetime.fromtimestamp(end_timestamp).strftime(&#34;%Y-%m-%d %H:%M&#34;)
        downtime_events.append({
            &#34;start&#34;: event_start_str,
            &#34;end&#34;: event_end_str,
            &#34;minutes_down&#34;: event_minutes
        })

    return downtime_seconds, downtime_events</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.calculate_downtime_press"><code class="name flex">
<span>def <span class="ident">calculate_downtime_press</span></span>(<span>machine,<br>cursor,<br>start_timestamp,<br>end_timestamp,<br>downtime_threshold=5,<br>machine_parts=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_downtime_press(machine, cursor, start_timestamp, end_timestamp, downtime_threshold=5, machine_parts=None):
    &#34;&#34;&#34;
    Calculate the total downtime for a specific machine over a given time period.

    Also returns individual downtime events that exceed the threshold.
    &#34;&#34;&#34;
    machine_downtime = 0  # Accumulate total downtime
    prev_timestamp = start_timestamp  # For interval calculations
    downtime_events = []  # List to hold individual downtime events

    # Build the query based on machine parts provided
    if not machine_parts:
        query = &#34;&#34;&#34;
            SELECT TimeStamp
            FROM GFxPRoduction
            WHERE Machine = %s AND TimeStamp BETWEEN %s AND %s
            ORDER BY TimeStamp ASC;
        &#34;&#34;&#34;
        params = [machine, start_timestamp, end_timestamp]
    else:
        placeholders = &#39;,&#39;.join([&#39;%s&#39;] * len(machine_parts))
        query = f&#34;&#34;&#34;
            SELECT TimeStamp
            FROM GFxPRoduction
            WHERE Machine = %s AND TimeStamp BETWEEN %s AND %s AND Part IN ({placeholders})
            ORDER BY TimeStamp ASC;
        &#34;&#34;&#34;
        params = [machine, start_timestamp, end_timestamp] + machine_parts

    cursor.execute(query, params)  # Execute the query

    timestamps_fetched = False
    for row in cursor:
        timestamps_fetched = True
        current_timestamp = row[0]
        # Calculate the time difference (in minutes)
        time_delta = (current_timestamp - prev_timestamp) / 60
        if time_delta &gt; downtime_threshold:
            downtime_minutes = round(time_delta)
            downtime_events.append({
                &#39;start&#39;: prev_timestamp,
                &#39;end&#39;: current_timestamp,
                &#39;duration&#39;: downtime_minutes
            })
            machine_downtime += downtime_minutes


        prev_timestamp = current_timestamp

    if not timestamps_fetched:
        # No production timestamps: entire period is downtime
        total_potential_minutes = (end_timestamp - start_timestamp) / 60
        return round(total_potential_minutes), [{
            &#39;start&#39;: start_timestamp,
            &#39;end&#39;: end_timestamp,
            &#39;duration&#39;: round(total_potential_minutes)
        }]

    # Handle downtime from last production timestamp to the end of the period
    remaining_time = (end_timestamp - prev_timestamp) / 60
    if remaining_time &gt; 0:
        downtime_events.append({
            &#39;start&#39;: prev_timestamp,
            &#39;end&#39;: end_timestamp,
            &#39;duration&#39;: round(remaining_time)
        })
        machine_downtime += remaining_time

    return round(machine_downtime), downtime_events</code></pre>
</details>
<div class="desc"><p>Calculate the total downtime for a specific machine over a given time period.</p>
<p>Also returns individual downtime events that exceed the threshold.</p></div>
</dd>
<dt id="prod_query.views.calculate_full_blocks"><code class="name flex">
<span>def <span class="ident">calculate_full_blocks</span></span>(<span>current_start, end_date, ranges)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_full_blocks(current_start, end_date, ranges):
    &#34;&#34;&#34;
    Calculate and add full blocks of time from Sunday 11 PM to Friday 11 PM 
    within the given date range. 

    Each block starts at Sunday 11 PM and ends at the following Friday 11 PM. 
    These blocks are appended to the provided `ranges` list.

    Parameters:
        current_start (datetime): The starting Sunday at 11 PM.
        end_date (datetime): The end date (exclusive) up to which blocks are calculated.
        ranges (list): A list to which the calculated blocks (tuples) will be appended.

    Returns:
        datetime: The next start date (Sunday at 11 PM) after the last valid block.
        
    Example:
        If current_start is 2025-01-05 23:00:00 (a Sunday),
        and end_date is 2025-01-20 23:00:00, ranges will include:
        - (2025-01-05 23:00:00, 2025-01-10 23:00:00)
        - (2025-01-12 23:00:00, 2025-01-17 23:00:00)
        The function will return 2025-01-19 23:00:00 (the next Sunday after the last block).
    &#34;&#34;&#34;
    # Loop to calculate blocks until the end_date is reached
    while current_start + timedelta(days=5) &lt;= end_date:
        # Calculate the current block&#39;s end time (Friday 11 PM)
        current_end = current_start + timedelta(days=5)
        current_end = current_end.replace(hour=23, minute=0, second=0)

        # Append the block (current_start, current_end) to the ranges list
        ranges.append((current_start, current_end))

        # Move to the next block&#39;s start time (the following Sunday at 11 PM)
        current_start += timedelta(days=7)

    # Return the next Sunday at 11 PM after the last valid block
    return current_start</code></pre>
</details>
<div class="desc"><p>Calculate and add full blocks of time from Sunday 11 PM to Friday 11 PM
within the given date range. </p>
<p>Each block starts at Sunday 11 PM and ends at the following Friday 11 PM.
These blocks are appended to the provided <code>ranges</code> list.</p>
<h2 id="parameters">Parameters</h2>
<p>current_start (datetime): The starting Sunday at 11 PM.
end_date (datetime): The end date (exclusive) up to which blocks are calculated.
ranges (list): A list to which the calculated blocks (tuples) will be appended.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>datetime</code></dt>
<dd>The next start date (Sunday at 11 PM) after the last valid block.</dd>
</dl>
<h2 id="example">Example</h2>
<p>If current_start is 2025-01-05 23:00:00 (a Sunday),
and end_date is 2025-01-20 23:00:00, ranges will include:
- (2025-01-05 23:00:00, 2025-01-10 23:00:00)
- (2025-01-12 23:00:00, 2025-01-17 23:00:00)
The function will return 2025-01-19 23:00:00 (the next Sunday after the last block).</p></div>
</dd>
<dt id="prod_query.views.calculate_line_totals"><code class="name flex">
<span>def <span class="ident">calculate_line_totals</span></span>(<span>grouped_results)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_line_totals(grouped_results):
    &#34;&#34;&#34;
    Aggregate per-operation metrics into line-level totals for each date block.

    Iterates through a dictionary of grouped results (keyed by date blocks),
    sums up targets, production counts, downtime, potential minutes, and scrap;
    collects individual operation P/A/downtime percentages, computes their
    averages (dropping the most recent value), and recalculates the line-level
    adjusted target. Inserts or updates a `line_totals` entry in each operations
    dict with these aggregated metrics.

    Parameters
    ----------
    grouped_results : dict
        A mapping where each key is a date block (e.g., a string or date) and
        each value is another dict of operations. Each operation dict must
        include a `&#34;totals&#34;` sub-dict with:
          - &#39;total_target&#39; (numeric)
          - &#39;total_produced&#39; (numeric)
          - &#39;total_downtime&#39; (numeric)
          - &#39;total_potential_minutes&#39; (numeric)
          - &#39;average_p_value&#39; (string percentage, e.g. &#34;75%&#34;)
          - &#39;average_a_value&#39; (string percentage)
          - &#39;average_downtime_percentage&#39; (string percentage)
        Optionally, a pre-existing `&#39;line_totals&#39;` entry to read scrap totals.

    Returns
    -------
    dict
        The same `grouped_results` dict, but with each inner operations dict
        updated to include a `&#39;line_totals&#39;` dict containing:
          - total_target (numeric)
          - total_adjusted_target (numeric, recalculated)
          - total_produced (numeric)
          - total_downtime (numeric)
          - total_potential_minutes (numeric)
          - average_downtime_percentage (string, e.g. &#34;12%&#34;)
          - average_p_value (string, e.g. &#34;80%&#34;)
          - average_a_value (string, e.g. &#34;85%&#34;)
          - total_scrap_amount (numeric)
    &#34;&#34;&#34;
    for date_block, operations in grouped_results.items():
        line_totals = {
            &#39;total_target&#39;: 0,
            &#39;total_produced&#39;: 0,
            &#39;total_downtime&#39;: 0,
            &#39;total_potential_minutes&#39;: 0,
            &#39;downtime_percentages&#39;: [],
            &#39;p_values&#39;: [],
            &#39;a_values&#39;: [],
            &#39;total_scrap_amount&#39;: 0
        }

        # Collect P and A values from operations
        for operation, operation_data in operations.items():
            operation_totals = operation_data.get(&#39;totals&#39;, {})
            line_totals[&#39;total_target&#39;] += operation_totals.get(&#39;total_target&#39;, 0)
            line_totals[&#39;total_produced&#39;] += operation_totals.get(&#39;total_produced&#39;, 0)
            line_totals[&#39;total_downtime&#39;] += operation_totals.get(&#39;total_downtime&#39;, 0)
            line_totals[&#39;total_potential_minutes&#39;] += operation_totals.get(&#39;total_potential_minutes&#39;, 0)

            # Extract P values
            average_p_value = operation_totals.get(&#39;average_p_value&#39;, &#34;0%&#34;).strip(&#39;%&#39;)
            try:
                line_totals[&#39;p_values&#39;].append(int(average_p_value))
            except ValueError:
                pass

            # Extract A values
            average_a_value = operation_totals.get(&#39;average_a_value&#39;, &#34;0%&#34;).strip(&#39;%&#39;)
            try:
                line_totals[&#39;a_values&#39;].append(int(average_a_value))
            except ValueError:
                pass

            downtime_percentage = operation_totals.get(&#39;average_downtime_percentage&#39;, &#34;0%&#34;)
            try:
                line_totals[&#39;downtime_percentages&#39;].append(float(downtime_percentage.strip(&#39;%&#39;)))
            except ValueError:
                pass

            # Scrap totals (line_totals from operations dict)
            if &#39;line_totals&#39; in operations:
                line_totals[&#39;total_scrap_amount&#39;] = operations[&#39;line_totals&#39;].get(&#39;total_scrap_amount&#39;, 0)

        # # Debug: Print raw P and A values
        # print(f&#34;Date Block: {date_block}&#34;)
        # print(f&#34;Raw P Values: {line_totals[&#39;p_values&#39;]}&#34;)
        # print(f&#34;Raw A Values: {line_totals[&#39;a_values&#39;]}&#34;)

        # Calculate averages using the extracted function
        averages = calculate_a_and_p_averages(
            line_totals[&#39;p_values&#39;],
            line_totals[&#39;a_values&#39;],
            line_totals[&#39;downtime_percentages&#39;]
        )
        average_p = averages[&#39;average_p&#39;]
        average_a = averages[&#39;average_a&#39;]
        average_downtime = averages[&#39;average_downtime&#39;]

        # # Debug: Print calculated averages
        # print(f&#34;Calculated Average P: {average_p}%&#34;)
        # print(f&#34;Calculated Average A: {average_a}%&#34;)
        # print(f&#34;Sum of P Values: {sum(line_totals[&#39;p_values&#39;])}&#34;)
        # print(f&#34;Number of P Values: {len(line_totals[&#39;p_values&#39;])}&#34;)
        # print(f&#34;Sum of A Values: {sum(line_totals[&#39;a_values&#39;])}&#34;)
        # print(f&#34;Number of A Values: {len(line_totals[&#39;a_values&#39;])}&#34;)

        # Recalculate adjusted target at the line level using the aggregated downtime
        percentage_downtime_str = f&#34;{average_downtime}%&#34;
        total_adjusted_target = calculate_adjusted_target(line_totals[&#39;total_target&#39;], percentage_downtime_str)

        # Ensure `line_totals` key exists
        if &#39;line_totals&#39; not in operations:
            operations[&#39;line_totals&#39;] = {}

        operations[&#39;line_totals&#39;].update({
            &#39;total_target&#39;: line_totals[&#39;total_target&#39;],
            &#39;total_adjusted_target&#39;: total_adjusted_target,  # Use recalculated adjusted target
            &#39;total_produced&#39;: line_totals[&#39;total_produced&#39;],
            &#39;total_downtime&#39;: line_totals[&#39;total_downtime&#39;],
            &#39;total_potential_minutes&#39;: line_totals[&#39;total_potential_minutes&#39;],
            &#39;average_downtime_percentage&#39;: percentage_downtime_str,
            &#39;average_p_value&#39;: f&#34;{average_p}%&#34;,
            &#39;average_a_value&#39;: f&#34;{average_a}%&#34;,
            &#39;total_scrap_amount&#39;: line_totals[&#39;total_scrap_amount&#39;],
            # q_value will be calculated later in get_line_details after all operations are done
        })

    return grouped_results</code></pre>
</details>
<div class="desc"><p>Aggregate per-operation metrics into line-level totals for each date block.</p>
<p>Iterates through a dictionary of grouped results (keyed by date blocks),
sums up targets, production counts, downtime, potential minutes, and scrap;
collects individual operation P/A/downtime percentages, computes their
averages (dropping the most recent value), and recalculates the line-level
adjusted target. Inserts or updates a <code>line_totals</code> entry in each operations
dict with these aggregated metrics.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>grouped_results</code></strong> :&ensp;<code>dict</code></dt>
<dd>A mapping where each key is a date block (e.g., a string or date) and
each value is another dict of operations. Each operation dict must
include a <code>"totals"</code> sub-dict with:
- 'total_target' (numeric)
- 'total_produced' (numeric)
- 'total_downtime' (numeric)
- 'total_potential_minutes' (numeric)
- 'average_p_value' (string percentage, e.g. "75%")
- 'average_a_value' (string percentage)
- 'average_downtime_percentage' (string percentage)
Optionally, a pre-existing <code>'line_totals'</code> entry to read scrap totals.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>The same <code>grouped_results</code> dict, but with each inner operations dict
updated to include a <code>'line_totals'</code> dict containing:
- total_target (numeric)
- total_adjusted_target (numeric, recalculated)
- total_produced (numeric)
- total_downtime (numeric)
- total_potential_minutes (numeric)
- average_downtime_percentage (string, e.g. "12%")
- average_p_value (string, e.g. "80%")
- average_a_value (string, e.g. "85%")
- total_scrap_amount (numeric)</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_monthly_totals"><code class="name flex">
<span>def <span class="ident">calculate_monthly_totals</span></span>(<span>grouped_results)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_monthly_totals(grouped_results):
    &#34;&#34;&#34;
    Aggregate line-level totals into a single monthly summary with recalculated averages.

    Iterates through a mapping of date blocks to their `line_totals` dict (as populated by
    `calculate_line_totals`), summing raw metrics (target, produced, downtime, potential minutes,
    scrap) and collecting percentage values for downtime, P, A, and Q. Computes:
      - `average_downtime_percentage`, `average_p_value`, `average_a_value`, `average_q_value`
        as rounded means of their respective lists.
      - `total_adjusted_target` by applying `calculate_adjusted_target` to the summed
        `total_target` with the monthly average downtime percentage.

    Parameters
    ----------
    grouped_results : dict
        A mapping where each key is a date block and each value is an operations-dict
        containing a `line_totals` sub-dict with keys:
          - total_target (numeric)
          - total_produced (numeric)
          - total_downtime (numeric)
          - total_potential_minutes (numeric)
          - average_downtime_percentage (string, e.g. &#34;12%&#34;)
          - average_p_value (string, e.g. &#34;80%&#34;)
          - average_a_value (string, e.g. &#34;85%&#34;)
          - q_value (string, e.g. &#34;95%&#34;)
          - total_scrap_amount (numeric, optional)

    Returns
    -------
    dict
        A dictionary with keys:
          - total_target (numeric)
          - total_produced (numeric)
          - total_downtime (numeric)
          - total_potential_minutes (numeric)
          - total_scrap_amount (numeric)
          - average_downtime_percentage (string, e.g. &#34;10%&#34;)
          - average_p_value (string, e.g. &#34;75%&#34;)
          - average_a_value (string, e.g. &#34;80%&#34;)
          - average_q_value (string, e.g. &#34;92.50%&#34;)
          - total_adjusted_target (numeric)
    &#34;&#34;&#34;
    monthly_totals = {
        &#39;total_target&#39;: 0,
        # Remove direct summation of adjusted targets here as well
        &#39;total_produced&#39;: 0,
        &#39;total_downtime&#39;: 0,
        &#39;total_potential_minutes&#39;: 0,
        &#39;downtime_percentages&#39;: [],
        &#39;a_values&#39;: [],  # Track A values for monthly totals
        &#39;p_values&#39;: [],  # Track P values for monthly totals
        &#39;total_scrap_amount&#39;: 0,
        &#39;q_values&#39;: []
    }

    for date_block, operations in grouped_results.items():
        if &#39;line_totals&#39; in operations:
            line_totals = operations[&#39;line_totals&#39;]
            monthly_totals[&#39;total_target&#39;] += line_totals[&#39;total_target&#39;]
            # Do NOT sum total_adjusted_target from line level, recalculate after
            monthly_totals[&#39;total_produced&#39;] += line_totals[&#39;total_produced&#39;]
            monthly_totals[&#39;total_downtime&#39;] += line_totals[&#39;total_downtime&#39;]
            monthly_totals[&#39;total_potential_minutes&#39;] += line_totals[&#39;total_potential_minutes&#39;]
            monthly_totals[&#39;total_scrap_amount&#39;] += line_totals.get(&#39;total_scrap_amount&#39;, 0)

            # Collect Q values
            q_value = line_totals.get(&#39;q_value&#39;, &#34;0%&#34;).strip(&#39;%&#39;)
            try:
                monthly_totals[&#39;q_values&#39;].append(float(q_value))
            except ValueError:
                pass

            # Track average P values
            try:
                p_value = float(line_totals.get(&#39;average_p_value&#39;, &#34;0%&#34;).strip(&#39;%&#39;))
                monthly_totals[&#39;p_values&#39;].append(p_value)
            except ValueError:
                pass

            # Track average A values
            try:
                a_value = float(line_totals.get(&#39;average_a_value&#39;, &#34;0%&#34;).strip(&#39;%&#39;))
                monthly_totals[&#39;a_values&#39;].append(a_value)
            except ValueError:
                pass

            # Track downtime percentages
            try:
                downtime_percentage = float(line_totals.get(&#39;average_downtime_percentage&#39;, &#34;0%&#34;).strip(&#39;%&#39;))
                monthly_totals[&#39;downtime_percentages&#39;].append(downtime_percentage)
            except ValueError:
                pass

    # Calculate averages
    average_downtime = round(sum(monthly_totals[&#39;downtime_percentages&#39;]) / len(monthly_totals[&#39;downtime_percentages&#39;])) if monthly_totals[&#39;downtime_percentages&#39;] else 0
    monthly_totals[&#39;average_downtime_percentage&#39;] = f&#34;{average_downtime}%&#34;

    if monthly_totals[&#39;p_values&#39;]:
        average_p = round(sum(monthly_totals[&#39;p_values&#39;]) / len(monthly_totals[&#39;p_values&#39;]))
    else:
        average_p = 0
    monthly_totals[&#39;average_p_value&#39;] = f&#34;{average_p}%&#34;

    if monthly_totals[&#39;a_values&#39;]:
        average_a = round(sum(monthly_totals[&#39;a_values&#39;]) / len(monthly_totals[&#39;a_values&#39;]))
    else:
        average_a = 0
    monthly_totals[&#39;average_a_value&#39;] = f&#34;{average_a}%&#34;

    # Calculate average Q
    if monthly_totals[&#39;q_values&#39;]:
        average_q = round(sum(monthly_totals[&#39;q_values&#39;]) / len(monthly_totals[&#39;q_values&#39;]), 2)
    else:
        average_q = 0
    monthly_totals[&#39;average_q_value&#39;] = f&#34;{average_q}%&#34;

    # Recalculate the monthly adjusted target using the monthly average downtime
    percentage_downtime_str = f&#34;{average_downtime}%&#34;
    monthly_adjusted_target = calculate_adjusted_target(monthly_totals[&#39;total_target&#39;], percentage_downtime_str)

    # Update monthly_totals to include recalculated adjusted target
    monthly_totals[&#39;total_adjusted_target&#39;] = monthly_adjusted_target

    return monthly_totals</code></pre>
</details>
<div class="desc"><p>Aggregate line-level totals into a single monthly summary with recalculated averages.</p>
<p>Iterates through a mapping of date blocks to their <code>line_totals</code> dict (as populated by
<code><a title="prod_query.views.calculate_line_totals" href="#prod_query.views.calculate_line_totals">calculate_line_totals()</a></code>), summing raw metrics (target, produced, downtime, potential minutes,
scrap) and collecting percentage values for downtime, P, A, and Q. Computes:
- <code>average_downtime_percentage</code>, <code>average_p_value</code>, <code>average_a_value</code>, <code>average_q_value</code>
as rounded means of their respective lists.
- <code>total_adjusted_target</code> by applying <code><a title="prod_query.views.calculate_adjusted_target" href="#prod_query.views.calculate_adjusted_target">calculate_adjusted_target()</a></code> to the summed
<code>total_target</code> with the monthly average downtime percentage.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>grouped_results</code></strong> :&ensp;<code>dict</code></dt>
<dd>A mapping where each key is a date block and each value is an operations-dict
containing a <code>line_totals</code> sub-dict with keys:
- total_target (numeric)
- total_produced (numeric)
- total_downtime (numeric)
- total_potential_minutes (numeric)
- average_downtime_percentage (string, e.g. "12%")
- average_p_value (string, e.g. "80%")
- average_a_value (string, e.g. "85%")
- q_value (string, e.g. "95%")
- total_scrap_amount (numeric, optional)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary with keys:
- total_target (numeric)
- total_produced (numeric)
- total_downtime (numeric)
- total_potential_minutes (numeric)
- total_scrap_amount (numeric)
- average_downtime_percentage (string, e.g. "10%")
- average_p_value (string, e.g. "75%")
- average_a_value (string, e.g. "80%")
- average_q_value (string, e.g. "92.50%")
- total_adjusted_target (numeric)</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_oa"><code class="name flex">
<span>def <span class="ident">calculate_oa</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@csrf_exempt
def calculate_oa(request):
    &#34;&#34;&#34;
    Handle OA metric calculations via a JSON POST request.

    This view accepts POST requests with a JSON body containing the input data
    required by the `calculate_oa_metrics` utility function. It returns the
    computed metrics as a JSON response.

    Workflow
    --------
    1. Ensure the request method is POST; otherwise return HTTP 405.
    2. Read and parse `request.body` as JSON; on parse error, return HTTP 400.
    3. Pass the parsed data dict to `calculate_oa_metrics`; on validation error
       (ValueError), return HTTP 400 with the error message.
    4. On success, log and return the resulting metrics dict as JSON (HTTP 200).
    5. Catch any other exceptions and return HTTP 500 with an error message.

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request. For POST, expects a JSON payload in the body
        matching the input schema for `calculate_oa_metrics`.

    Returns
    -------
    django.http.JsonResponse
        - On success: the metrics dict returned by `calculate_oa_metrics`.
        - On JSON decode error: `{&#39;error&#39;: &#39;Invalid JSON format&#39;}`, HTTP 400.
        - On validation error: `{&#39;error&#39;: &lt;message&gt;}`, HTTP 400.
        - On unexpected error: `{&#39;error&#39;: &lt;message&gt;}`, HTTP 500.
        - On non-POST method: `{&#39;error&#39;: &#39;Invalid request method&#39;}`, HTTP 405.
    &#34;&#34;&#34;
    if request.method == &#39;POST&#39;:
        try:
            # Parse input data
            raw_body = request.body
            logger.info(&#34;Raw request body: %s&#34;, raw_body)
            data = json.loads(raw_body)
            logger.info(&#34;Parsed request data: %s&#34;, data)

            # Call utility function to calculate OA metrics
            metrics = calculate_oa_metrics(data)

            # Log results
            logger.info(&#34;Calculated OA Metrics: %s&#34;, metrics)

            return JsonResponse(metrics)

        except json.JSONDecodeError as e:
            logger.error(&#34;JSON decode error: %s&#34;, e)
            return JsonResponse({&#39;error&#39;: &#39;Invalid JSON format&#39;}, status=400)
        except ValueError as e:
            logger.error(&#34;Validation error: %s&#34;, e)
            return JsonResponse({&#39;error&#39;: str(e)}, status=400)
        except Exception as e:
            logger.error(&#34;Unexpected error: %s&#34;, e)
            return JsonResponse({&#39;error&#39;: str(e)}, status=500)

    return JsonResponse({&#39;error&#39;: &#39;Invalid request method&#39;}, status=405)</code></pre>
</details>
<div class="desc"><p>Handle OA metric calculations via a JSON POST request.</p>
<p>This view accepts POST requests with a JSON body containing the input data
required by the <code><a title="prod_query.views.calculate_oa_metrics" href="#prod_query.views.calculate_oa_metrics">calculate_oa_metrics()</a></code> utility function. It returns the
computed metrics as a JSON response.</p>
<h2 id="workflow">Workflow</h2>
<ol>
<li>Ensure the request method is POST; otherwise return HTTP 405.</li>
<li>Read and parse <code>request.body</code> as JSON; on parse error, return HTTP 400.</li>
<li>Pass the parsed data dict to <code><a title="prod_query.views.calculate_oa_metrics" href="#prod_query.views.calculate_oa_metrics">calculate_oa_metrics()</a></code>; on validation error
(ValueError), return HTTP 400 with the error message.</li>
<li>On success, log and return the resulting metrics dict as JSON (HTTP 200).</li>
<li>Catch any other exceptions and return HTTP 500 with an error message.</li>
</ol>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request. For POST, expects a JSON payload in the body
matching the input schema for <code><a title="prod_query.views.calculate_oa_metrics" href="#prod_query.views.calculate_oa_metrics">calculate_oa_metrics()</a></code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.JsonResponse</code></dt>
<dd>
<ul>
<li>On success: the metrics dict returned by <code><a title="prod_query.views.calculate_oa_metrics" href="#prod_query.views.calculate_oa_metrics">calculate_oa_metrics()</a></code>.</li>
<li>On JSON decode error: <code>{'error': 'Invalid JSON format'}</code>, HTTP 400.</li>
<li>On validation error: <code>{'error': &lt;message&gt;}</code>, HTTP 400.</li>
<li>On unexpected error: <code>{'error': &lt;message&gt;}</code>, HTTP 500.</li>
<li>On non-POST method: <code>{'error': 'Invalid request method'}</code>, HTTP 405.</li>
</ul>
</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_oa_metrics"><code class="name flex">
<span>def <span class="ident">calculate_oa_metrics</span></span>(<span>data)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_oa_metrics(data):
    &#34;&#34;&#34;
    Calculate OA, P, A, and Q metrics from the provided data.

    :param data: Dictionary containing input data for calculation
    :return: Dictionary with OA, P, A, Q metrics or raises an exception for invalid input
    &#34;&#34;&#34;
    try:
        # Extract variables
        total_downtime = int(data.get(&#39;totalDowntime&#39;, 0))
        total_produced = int(data.get(&#39;totalProduced&#39;, 0))
        total_target = int(data.get(&#39;totalTarget&#39;, 0))
        total_potential = int(data.get(&#39;totalPotentialMinutes&#39;, 0))
        total_scrap = int(data.get(&#39;totalScrap&#39;, 0))

        # Validate inputs
        if total_target &lt;= 0:
            raise ValueError(&#39;Total target must be greater than 0&#39;)
        if total_potential &lt;= 0:
            raise ValueError(&#39;Total potential must be greater than 0&#39;)

        # Calculate P, A, Q
        P = total_produced / total_target
        A = (total_potential - total_downtime) / total_potential
        Q = total_produced / (total_produced + total_scrap) if (total_produced + total_scrap) &gt; 0 else 0

        # Calculate OA
        OA = P * A * Q

        return {&#39;OA&#39;: OA, &#39;P&#39;: P, &#39;A&#39;: A, &#39;Q&#39;: Q}

    except KeyError as e:
        raise ValueError(f&#34;Missing key in input data: {e}&#34;)
    except ValueError as e:
        raise ValueError(f&#34;Invalid input: {e}&#34;)</code></pre>
</details>
<div class="desc"><p>Calculate OA, P, A, and Q metrics from the provided data.</p>
<p>:param data: Dictionary containing input data for calculation
:return: Dictionary with OA, P, A, Q metrics or raises an exception for invalid input</p></div>
</dd>
<dt id="prod_query.views.calculate_operaton_P_and_A_from_totals"><code class="name flex">
<span>def <span class="ident">calculate_operaton_P_and_A_from_totals</span></span>(<span>line_name,<br>op_name,<br>produced_parts,<br>target,<br>downtime_minutes,<br>planned_downtime,<br>unplanned_downtime,<br>total_queried_minutes)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_operaton_P_and_A_from_totals(
        line_name, op_name, produced_parts, target, downtime_minutes,
        planned_downtime, unplanned_downtime, total_queried_minutes):
    &#34;&#34;&#34;
    Calculate the Availability (A) and Performance (P) for an operation,
    using aggregated totals for all machines in the operation.
    
    Assumptions:
      - The operation&#39;s potential minutes equals the total queried minutes.
      - Downtime values are aggregated from all machines.
    
    Parameters:
      line_name (str): Identifier for the production line.
      op_name (str): The operation name or number.
      produced_parts (int or float): Total produced parts for the operation.
      target (int or float): Total target for the operation.
      downtime_minutes (int or float): Total downtime minutes (aggregated, not used directly).
      planned_downtime (int or float): Aggregated planned downtime minutes.
      unplanned_downtime (int or float): Aggregated unplanned downtime minutes.
      total_queried_minutes (int or float): Total potential minutes for the operation.
    
    Formulas:
      potential = total_queried_minutes
      Planned Production Time (PPT) = potential - planned_downtime
      Run Time = PPT - unplanned_downtime
      If potential &gt; 0 and total downtime &gt; 0, then:
          uptime_ratio = (potential - (planned_downtime + unplanned_downtime)) / potential
          adjusted_target = target * uptime_ratio
      Else:
          adjusted_target = target
      Availability (A) = Run Time / PPT    (if PPT &gt; 0)
      Performance (P) = produced_parts / adjusted_target    (if adjusted_target &gt; 0)
    
    Returns:
      dict: A dictionary with the following keys:
            &#34;line&#34;: line_name,
            &#34;op&#34;: op_name,
            &#34;A&#34;: calculated Availability,
            &#34;P&#34;: calculated Performance
    &#34;&#34;&#34;
    potential = total_queried_minutes
    ppt = potential - planned_downtime
    run_time = ppt - unplanned_downtime
    downtime_total = planned_downtime + unplanned_downtime

    if potential == 0 or downtime_total == 0:
        adjusted_target = target
    else:
        runtime = potential - downtime_total
        uptime_ratio = runtime / potential
        adjusted_target = target * uptime_ratio

    availability = run_time / ppt if ppt &gt; 0 else 0.0
    if adjusted_target == 0:
        performance = 0
    else:
        performance = produced_parts / adjusted_target

    return {
        &#34;line&#34;: line_name,
        &#34;op&#34;: op_name,
        &#34;A&#34;: availability,
        &#34;P&#34;: performance
    }</code></pre>
</details>
<div class="desc"><p>Calculate the Availability (A) and Performance (P) for an operation,
using aggregated totals for all machines in the operation.</p>
<h2 id="assumptions">Assumptions</h2>
<ul>
<li>The operation's potential minutes equals the total queried minutes.</li>
<li>Downtime values are aggregated from all machines.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<p>line_name (str): Identifier for the production line.
op_name (str): The operation name or number.
produced_parts (int or float): Total produced parts for the operation.
target (int or float): Total target for the operation.
downtime_minutes (int or float): Total downtime minutes (aggregated, not used directly).
planned_downtime (int or float): Aggregated planned downtime minutes.
unplanned_downtime (int or float): Aggregated unplanned downtime minutes.
total_queried_minutes (int or float): Total potential minutes for the operation.</p>
<h2 id="formulas">Formulas</h2>
<p>potential = total_queried_minutes
Planned Production Time (PPT) = potential - planned_downtime
Run Time = PPT - unplanned_downtime
If potential &gt; 0 and total downtime &gt; 0, then:
uptime_ratio = (potential - (planned_downtime + unplanned_downtime)) / potential
adjusted_target = target * uptime_ratio
Else:
adjusted_target = target
Availability (A) = Run Time / PPT
(if PPT &gt; 0)
Performance (P) = produced_parts / adjusted_target
(if adjusted_target &gt; 0)</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary with the following keys:
"line": line_name,
"op": op_name,
"A": calculated Availability,
"P": calculated Performance</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_p"><code class="name flex">
<span>def <span class="ident">calculate_p</span></span>(<span>total_produced, total_adjusted_target, downtime_percentage)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_p(total_produced, total_adjusted_target, downtime_percentage):
    &#34;&#34;&#34;
    Compute the performance (P) percentage for a line or operation.

    Special cases:
      - If nothing was produced and downtime is 100%, returns 100 (full downtime).
      - If the adjusted target is zero, returns 0 to avoid division by zero.

    Otherwise, calculates:
      P = (total_produced / total_adjusted_target) * 100, rounded to the nearest integer.

    Parameters
    ----------
    total_produced : numeric
        The actual number of units produced.
    total_adjusted_target : numeric
        The target production adjusted for downtime.
    downtime_percentage : str
        The downtime percentage string (e.g. &#34;25%&#34;).

    Returns
    -------
    int
        The performance percentage as an integer.
    &#34;&#34;&#34;
    if total_produced == 0 and downtime_percentage.strip(&#39;%&#39;) == &#34;100&#34;:
        return 100  # Special case: 100% downtime means P should be 100%
    if total_adjusted_target == 0:
        return 0  # Avoid division by zero
    return round((total_produced / total_adjusted_target) * 100)</code></pre>
</details>
<div class="desc"><p>Compute the performance (P) percentage for a line or operation.</p>
<p>Special cases:
- If nothing was produced and downtime is 100%, returns 100 (full downtime).
- If the adjusted target is zero, returns 0 to avoid division by zero.</p>
<p>Otherwise, calculates:
P = (total_produced / total_adjusted_target) * 100, rounded to the nearest integer.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>total_produced</code></strong> :&ensp;<code>numeric</code></dt>
<dd>The actual number of units produced.</dd>
<dt><strong><code>total_adjusted_target</code></strong> :&ensp;<code>numeric</code></dt>
<dd>The target production adjusted for downtime.</dd>
<dt><strong><code>downtime_percentage</code></strong> :&ensp;<code>str</code></dt>
<dd>The downtime percentage string (e.g. "25%").</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The performance percentage as an integer.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_percentage_downtime"><code class="name flex">
<span>def <span class="ident">calculate_percentage_downtime</span></span>(<span>downtime, potential_minutes)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_percentage_downtime(downtime, potential_minutes):
    &#34;&#34;&#34;
    Calculate and format the downtime percentage relative to potential operating minutes.

    Divides `downtime` by `potential_minutes` to compute the percentage of time the
    machine was down. If `potential_minutes` is zero, returns &#34;0%&#34; to avoid
    division by zero. The resulting percentage is rounded to the nearest integer.

    Parameters
    ----------
    downtime : int or float
        Total downtime in minutes.
    potential_minutes : int or float
        Total potential operating minutes for the period.

    Returns
    -------
    str
        The downtime percentage as a string with a percent sign, e.g. &#34;25%&#34;.
        Returns &#34;0%&#34; if `potential_minutes` is zero.
    &#34;&#34;&#34;
    if potential_minutes == 0:
        return &#34;0%&#34;
    percentage = (downtime / potential_minutes) * 100
    return f&#34;{int(round(percentage))}%&#34;  # Round and convert to an integer</code></pre>
</details>
<div class="desc"><p>Calculate and format the downtime percentage relative to potential operating minutes.</p>
<p>Divides <code>downtime</code> by <code>potential_minutes</code> to compute the percentage of time the
machine was down. If <code>potential_minutes</code> is zero, returns "0%" to avoid
division by zero. The resulting percentage is rounded to the nearest integer.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>downtime</code></strong> :&ensp;<code>int</code> or <code>float</code></dt>
<dd>Total downtime in minutes.</dd>
<dt><strong><code>potential_minutes</code></strong> :&ensp;<code>int</code> or <code>float</code></dt>
<dd>Total potential operating minutes for the period.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The downtime percentage as a string with a percent sign, e.g. "25%".
Returns "0%" if <code>potential_minutes</code> is zero.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_percentage_week"><code class="name flex">
<span>def <span class="ident">calculate_percentage_week</span></span>(<span>potential_minutes)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_percentage_week(potential_minutes):
    &#34;&#34;&#34;
    Format a duration in minutes as a percentage of a full work week.

    If the provided `potential_minutes` equals a full week (7200 minutes),
    returns a string indicating “Full Week.” Otherwise, computes the percentage
    of the full week that `potential_minutes` represents, rounded to the nearest
    whole percent, and returns it alongside the original minute count.

    Parameters
    ----------
    potential_minutes : int
        The number of minutes to compare against a full work week (7200 minutes).

    Returns
    -------
    str
        A formatted string in one of two forms:
          - &#34;{potential_minutes} (Full Week)&#34; if equal to 7200.
          - &#34;{potential_minutes} ({percentage}%)&#34; otherwise, where
            `percentage` is the integer percentage of 7200.
    &#34;&#34;&#34;
    full_week_minutes = 7200
    if potential_minutes == full_week_minutes:
        return f&#34;{potential_minutes} (Full Week)&#34;
    percentage = round((potential_minutes / full_week_minutes) * 100)
    return f&#34;{potential_minutes} ({percentage}%)&#34;</code></pre>
</details>
<div class="desc"><p>Format a duration in minutes as a percentage of a full work week.</p>
<p>If the provided <code>potential_minutes</code> equals a full week (7200 minutes),
returns a string indicating “Full Week.” Otherwise, computes the percentage
of the full week that <code>potential_minutes</code> represents, rounded to the nearest
whole percent, and returns it alongside the original minute count.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>potential_minutes</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of minutes to compare against a full work week (7200 minutes).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>A formatted string in one of two forms:
- "{potential_minutes} (Full Week)" if equal to 7200.
- "{potential_minutes} ({percentage}%)" otherwise, where
<code>percentage</code> is the integer percentage of 7200.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_planned_downtime"><code class="name flex">
<span>def <span class="ident">calculate_planned_downtime</span></span>(<span>downtime_events, pr_downtime_entries)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_planned_downtime(downtime_events, pr_downtime_entries):
    import datetime, os, importlib, json
    &#34;&#34;&#34;
    Calculates planned downtime as the sum of downtime event minutes
    that do not overlap any PR downtime entry and are longer than 240 minutes.
    &#34;&#34;&#34;
    planned_downtime_minutes = 0
    pr_intervals = []
    for pr in pr_downtime_entries:
        if pr[&#34;start_time&#34;] and pr[&#34;end_time&#34;]:
            pr_intervals.append((pr[&#34;start_time&#34;], pr[&#34;end_time&#34;]))
    
    for event in downtime_events:
        dt_event_start = datetime.datetime.strptime(event[&#34;start&#34;], &#34;%Y-%m-%d %H:%M&#34;)
        dt_event_end = datetime.datetime.strptime(event[&#34;end&#34;], &#34;%Y-%m-%d %H:%M&#34;)
        overlap_found = any(dt_event_start &lt; pr_end and pr_start &lt; dt_event_end for pr_start, pr_end in pr_intervals)
        if not overlap_found and event[&#34;minutes_down&#34;] &gt; 240:
            planned_downtime_minutes += event[&#34;minutes_down&#34;]
    return planned_downtime_minutes</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.calculate_potential_minutes"><code class="name flex">
<span>def <span class="ident">calculate_potential_minutes</span></span>(<span>start, end)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_potential_minutes(start, end):
    return int((end - start).total_seconds() / 60)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.calculate_runtime_press"><code class="name flex">
<span>def <span class="ident">calculate_runtime_press</span></span>(<span>machine, cursor, start_timestamp, end_timestamp, running_threshold=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_runtime_press(machine, cursor, start_timestamp, end_timestamp, running_threshold=5):
    &#34;&#34;&#34;
    Calculate the running intervals for a specific machine over a given time period.
    A running interval is defined as a contiguous series of production timestamps where
    the gap between consecutive timestamps does not exceed the running_threshold (in minutes).

    Args:
        machine (str): The machine/asset number.
        cursor: Database cursor.
        start_timestamp (int): The starting timestamp (in seconds).
        end_timestamp (int): The ending timestamp (in seconds).
        running_threshold (int): Maximum gap (in minutes) to consider production as continuous.

    Returns:
        list of dict: Each dictionary contains:
                      - &#39;start&#39;: start time of the running interval (timestamp)
                      - &#39;end&#39;: end time of the running interval (timestamp)
                      - &#39;duration&#39;: duration in minutes (rounded)
    &#34;&#34;&#34;
    query = &#34;&#34;&#34;
        SELECT TimeStamp
        FROM GFxPRoduction
        WHERE Machine = %s AND TimeStamp BETWEEN %s AND %s
        ORDER BY TimeStamp ASC;
    &#34;&#34;&#34;
    cursor.execute(query, (machine, start_timestamp, end_timestamp))
    rows = cursor.fetchall()
    
    if not rows:
        # If there are no production timestamps, there are no running intervals.
        return []
    
    running_intervals = []
    # Start the first running interval at the first production timestamp.
    run_start = rows[0][0]
    previous_ts = run_start

    for row in rows[1:]:
        current_ts = row[0]
        # If the gap between the current and previous production timestamp is larger than threshold,
        # finish the current running interval.
        if (current_ts - previous_ts) / 60 &gt; running_threshold:
            run_end = previous_ts
            duration = round((run_end - run_start) / 60)
            if duration &gt; 0:
                running_intervals.append({
                    &#39;start&#39;: run_start,
                    &#39;end&#39;: run_end,
                    &#39;duration&#39;: duration
                })
            # Start a new running interval.
            run_start = current_ts
        previous_ts = current_ts

    # Add the final running interval.
    run_end = previous_ts
    duration = round((run_end - run_start) / 60)
    if duration &gt; 0:
        running_intervals.append({
            &#39;start&#39;: run_start,
            &#39;end&#39;: run_end,
            &#39;duration&#39;: duration
        })
    
    return running_intervals</code></pre>
</details>
<div class="desc"><p>Calculate the running intervals for a specific machine over a given time period.
A running interval is defined as a contiguous series of production timestamps where
the gap between consecutive timestamps does not exceed the running_threshold (in minutes).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>The machine/asset number.</dd>
<dt><strong><code>cursor</code></strong></dt>
<dd>Database cursor.</dd>
<dt><strong><code>start_timestamp</code></strong> :&ensp;<code>int</code></dt>
<dd>The starting timestamp (in seconds).</dd>
<dt><strong><code>end_timestamp</code></strong> :&ensp;<code>int</code></dt>
<dd>The ending timestamp (in seconds).</dd>
<dt><strong><code>running_threshold</code></strong> :&ensp;<code>int</code></dt>
<dd>Maximum gap (in minutes) to consider production as continuous.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>dict</code></dt>
<dd>Each dictionary contains:
- 'start': start time of the running interval (timestamp)
- 'end': end time of the running interval (timestamp)
- 'duration': duration in minutes (rounded)</dd>
</dl></div>
</dd>
<dt id="prod_query.views.calculate_totals"><code class="name flex">
<span>def <span class="ident">calculate_totals</span></span>(<span>grouped_results)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_totals(grouped_results):
    for date_block, operations in grouped_results.items():
        for operation, operation_data in operations.items():
            machines = operation_data.get(&#39;machines&#39;, [])
            if not isinstance(machines, list):
                continue

            total_target = 0
            total_adjusted_target = 0
            total_produced = 0
            total_downtime = 0
            total_potential_minutes = 0
            downtime_percentages = []
            a_values = []
            p_values = []

            for machine in machines:
                target = machine.get(&#39;target&#39;, 0)
                adjusted_target = machine.get(&#39;adjusted_target&#39;, 0)
                produced = machine.get(&#39;produced&#39;, 0)
                downtime = machine.get(&#39;downtime&#39;, 0)
                potential_minutes_str = machine.get(&#39;potential_minutes&#39;, &#34;0 (0%)&#34;)
                percentage_downtime_str = machine.get(&#39;percentage_downtime&#39;, &#34;0%&#34;)
                p_str = machine.get(&#39;p_value&#39;, &#34;0%&#34;).strip(&#39;%&#39;)

                try:
                    percentage_downtime_val = float(percentage_downtime_str.strip(&#39;%&#39;))
                    downtime_percentages.append(percentage_downtime_val)

                    total_target += target
                    total_adjusted_target += adjusted_target
                    total_produced += produced
                    total_downtime += downtime

                    pm_value = int(potential_minutes_str.split()[0])
                    total_potential_minutes += pm_value

                    p_val = int(p_str) if p_str.isdigit() else 0
                    if p_val &gt; 0:
                        p_values.append(p_val)

                    # Calculate A value for this machine
                    a_value = calculate_A(pm_value, downtime)
                    machine[&#39;a_value&#39;] = a_value  # Store A value back to the machine dict
                    
                    a_values.append(int(a_value.strip(&#39;%&#39;)))
                except ValueError as ve:
                    print(f&#34;[DEBUG] Error processing machine data in calculate_totals: {ve}&#34;)

            average_downtime = round(sum(downtime_percentages) / len(downtime_percentages)) if downtime_percentages else 0
            average_a = round(sum(a_values) / len(a_values)) if a_values else 0
            average_p = round(sum(p_values) / len(p_values)) if p_values else 0

            # Add the operation&#39;s aggregated totals to operation_data
            operation_data[&#39;totals&#39;] = {
                &#39;total_target&#39;: total_target,
                &#39;total_adjusted_target&#39;: total_adjusted_target,
                &#39;total_produced&#39;: total_produced,
                &#39;total_downtime&#39;: total_downtime,
                &#39;total_potential_minutes&#39;: total_potential_minutes,
                &#39;average_downtime_percentage&#39;: f&#34;{average_downtime}%&#34;,
                &#39;average_a_value&#39;: f&#34;{average_a}%&#34;,
                &#39;average_p_value&#39;: f&#34;{average_p}%&#34;
            }


    return grouped_results</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.calculate_unplanned_downtime"><code class="name flex">
<span>def <span class="ident">calculate_unplanned_downtime</span></span>(<span>total_downtime_minutes, planned_downtime_minutes)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_unplanned_downtime(total_downtime_minutes, planned_downtime_minutes):
    &#34;&#34;&#34;
    Calculates unplanned downtime as the difference between total downtime
    and planned downtime.
    &#34;&#34;&#34;
    return total_downtime_minutes - planned_downtime_minutes</code></pre>
</details>
<div class="desc"><p>Calculates unplanned downtime as the difference between total downtime
and planned downtime.</p></div>
</dd>
<dt id="prod_query.views.compute_cycle_time"><code class="name flex">
<span>def <span class="ident">compute_cycle_time</span></span>(<span>timestamps)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_cycle_time(timestamps):
    &#34;&#34;&#34;
    Computes the cycle time based on the differences between sorted timestamps.
    Uses a weighted average of the top 3 most frequent cycle times.
    &#34;&#34;&#34;
    if len(timestamps) &lt; 2:
        return 0  # No production, cycle time should be 0

    timestamps = np.sort(timestamps)  # Ensure timestamps are sorted
    time_diffs = np.diff(timestamps)  # Compute time differences
    time_diffs = np.round(time_diffs).astype(int)  # Round to nearest second

    unique_times, counts = np.unique(time_diffs, return_counts=True)  # Find unique cycle times and occurrences
    sorted_indices = np.argsort(counts)[::-1]  # Sort occurrences in descending order

    # Get top 3 cycle times
    top_3_times = unique_times[sorted_indices[:5]]
    top_3_counts = counts[sorted_indices[:5]]

    print(f&#39;Top 3 times:  {top_3_times}&#39;)
    print(f&#39;Top 3 counts: {top_3_counts}&#39;)

    # Compute weighted average cycle time
    weighted_cycle_time = np.sum(top_3_times * top_3_counts) / np.sum(top_3_counts)

    return weighted_cycle_time</code></pre>
</details>
<div class="desc"><p>Computes the cycle time based on the differences between sorted timestamps.
Uses a weighted average of the top 3 most frequent cycle times.</p></div>
</dd>
<dt id="prod_query.views.compute_downtime_percentage"><code class="name flex">
<span>def <span class="ident">compute_downtime_percentage</span></span>(<span>totals)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_downtime_percentage(totals):
    &#34;&#34;&#34;
    Example calculation for downtime percentage. You might need to adjust this
    based on how you determine potential runtime. For instance, if each operation
    is expected to have 7200 minutes of production:
    &#34;&#34;&#34;
    potential_minutes = 7200
    if potential_minutes:
        return (totals[&#34;total_downtime&#34;] / potential_minutes) * 100
    return 0</code></pre>
</details>
<div class="desc"><p>Example calculation for downtime percentage. You might need to adjust this
based on how you determine potential runtime. For instance, if each operation
is expected to have 7200 minutes of production:</p></div>
</dd>
<dt id="prod_query.views.compute_machine_downtime_percentage"><code class="name flex">
<span>def <span class="ident">compute_machine_downtime_percentage</span></span>(<span>machine_data)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_machine_downtime_percentage(machine_data):
    &#34;&#34;&#34;
    Calculate the downtime percentage for a given machine.
    
    The downtime percentage is computed as the ratio of downtime minutes to the total queried minutes,
    multiplied by 100 to yield a percentage value. If total queried minutes is zero, the percentage will be zero.
    
    Parameters:
      machine_data (dict): Dictionary containing machine performance data. Expected keys include:
                           - &#34;downtime_minutes&#34; (int): The machine&#39;s downtime in minutes.
                           - &#34;total_queried_minutes&#34; (int): The total minutes that were queried for the machine.
    
    Returns:
      dict: A dictionary with the key &#34;downtime_percentage&#34; and the computed percentage as its value.
    &#34;&#34;&#34;
    total_minutes = machine_data.get(&#34;total_queried_minutes&#34;, 0)
    downtime_minutes = machine_data.get(&#34;downtime_minutes&#34;, 0)
    if total_minutes &gt; 0:
        percentage = (downtime_minutes / total_minutes) * 100
    else:
        percentage = 0
    return {&#34;downtime_percentage&#34;: percentage}</code></pre>
</details>
<div class="desc"><p>Calculate the downtime percentage for a given machine.</p>
<p>The downtime percentage is computed as the ratio of downtime minutes to the total queried minutes,
multiplied by 100 to yield a percentage value. If total queried minutes is zero, the percentage will be zero.</p>
<h2 id="parameters">Parameters</h2>
<p>machine_data (dict): Dictionary containing machine performance data. Expected keys include:
- "downtime_minutes" (int): The machine's downtime in minutes.
- "total_queried_minutes" (int): The total minutes that were queried for the machine.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary with the key "downtime_percentage" and the computed percentage as its value.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.compute_machine_oee"><code class="name flex">
<span>def <span class="ident">compute_machine_oee</span></span>(<span>machine_data, queried_minutes)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_machine_oee(machine_data, queried_minutes):
    &#34;&#34;&#34;
    Calculate Availability (A) and Performance (P) for a single machine.
    
    Assumptions:
      - Each machine&#39;s potential minutes equals the queried_minutes.
      - Planned downtime and unplanned downtime are provided in minutes.
    
    Formulas:
      PPT (Planned Production Time) = potential_minutes - planned_downtime
      Run Time = PPT - (unplanned_downtime)
      Ideal Cycle Time = PPT / target  (if target &gt; 0)
      Availability = Run Time / PPT   (if PPT &gt; 0)
      Performance = (Ideal Cycle Time * produced_parts) / Run Time   (if Run Time &gt; 0)
    &#34;&#34;&#34;
    produced = float(machine_data.get(&#34;produced_parts&#34;, 0))
    target = float(machine_data.get(&#34;target&#34;, 0))
    planned_downtime = float(machine_data.get(&#34;planned_downtime_minutes&#34;, 0))
    unplanned_downtime = float(machine_data.get(&#34;unplanned_downtime_minutes&#34;, 0))

    # produced = 500
    # target = 1000
    # planned_downtime = 0
    # unplanned_downtime = 3600
    
    # For each machine, potential minutes is simply the queried minutes.
    potential = queried_minutes
    ppt = potential - planned_downtime
    run_time = ppt - (unplanned_downtime)

    downtime_total = planned_downtime + unplanned_downtime

    if potential == 0 or downtime_total == 0:
        adjusted_target = target
    else:
        runtime = potential - unplanned_downtime - planned_downtime
        uptime_ratio = runtime /potential     
        # adjusted_target = target * uptime_ratio
        # adjusted_target = target / ((unplanned_downtime + planned_downtime) / potential)

    ideal_cycle_time = ppt / target if target &gt; 0 else 0.0
    adjusted_target = run_time / ideal_cycle_time if ideal_cycle_time &gt; 0 else 0.0
    availability = run_time / ppt if ppt &gt; 0 else 1.0
    # performance = (ideal_cycle_time * produced) / run_time if run_time &gt; 0 else 0.0
    if adjusted_target == 0:
        performance = 0
    else:
        performance = produced / adjusted_target

    if potential - (planned_downtime + unplanned_downtime) == 0:
        availaibility = 0
        performance = 1
    
    return {&#34;A&#34;: availability, &#34;P&#34;: performance}</code></pre>
</details>
<div class="desc"><p>Calculate Availability (A) and Performance (P) for a single machine.</p>
<h2 id="assumptions">Assumptions</h2>
<ul>
<li>Each machine's potential minutes equals the queried_minutes.</li>
<li>Planned downtime and unplanned downtime are provided in minutes.</li>
</ul>
<h2 id="formulas">Formulas</h2>
<p>PPT (Planned Production Time) = potential_minutes - planned_downtime
Run Time = PPT - (unplanned_downtime)
Ideal Cycle Time = PPT / target
(if target &gt; 0)
Availability = Run Time / PPT
(if PPT &gt; 0)
Performance = (Ideal Cycle Time * produced_parts) / Run Time
(if Run Time &gt; 0)</p></div>
</dd>
<dt id="prod_query.views.compute_oee_metrics"><code class="name flex">
<span>def <span class="ident">compute_oee_metrics</span></span>(<span>totals_by_line,<br>overall_total_produced,<br>overall_total_target,<br>overall_total_potential_minutes,<br>overall_unplanned_downtime_minutes,<br>overall_planned_downtime_minutes,<br>overall_scrap_total,<br>scrap_totals_by_line,<br>potential_minutes_by_line,<br>planned_downtime_totals_by_line,<br>unplanned_downtime_totals_by_line)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_oee_metrics(
    totals_by_line,
    overall_total_produced,
    overall_total_target,
    overall_total_potential_minutes,
    overall_unplanned_downtime_minutes,
    overall_planned_downtime_minutes,
    overall_scrap_total,
    scrap_totals_by_line,
    potential_minutes_by_line,
    planned_downtime_totals_by_line,
    unplanned_downtime_totals_by_line
):
    &#34;&#34;&#34;
    Compute OEE metrics overall and by line using the following formulas:
    
      1. Planned Production Time (PPT) = total_potential_minutes - planned_downtime
      2. Run Time = PPT - (unplanned_downtime)
      3. ideal_cycle_time = PPT / target_parts  (target_parts is overall_total_target or per-line target)
      4. Availability = run_time / PPT
      5. Performance = (ideal_cycle_time * actual_parts) / run_time
      6. Quality = (total produced - scrap) / total produced
      7. OEE = Availability * Performance * Quality
    &#34;&#34;&#34;
    # Convert overall parameters to floats to avoid type issues
    overall_total_produced = float(overall_total_produced)
    overall_total_target = float(overall_total_target)
    overall_total_potential_minutes = float(overall_total_potential_minutes)
    overall_unplanned_downtime_minutes = float(overall_unplanned_downtime_minutes)
    overall_planned_downtime_minutes = float(overall_planned_downtime_minutes)
    overall_scrap_total = float(overall_scrap_total)

    # overall_total_produced = 500
    # overall_total_target = 1000
    # overall_total_potential_minutes = 480
    # overall_unplanned_downtime_minutes = 120
    # overall_planned_downtime_minutes = 120
    # overall_scrap_total = 0
    
    # Overall metrics calculations
    overall_ppt = overall_total_potential_minutes - overall_planned_downtime_minutes
    overall_run_time = overall_ppt - (overall_unplanned_downtime_minutes)
    overall_ideal_cycle_time = overall_ppt / overall_total_target if overall_total_target &gt; 0 else 0.0


    overall_runtime = overall_total_potential_minutes - overall_planned_downtime_minutes - overall_unplanned_downtime_minutes
    overall_uptime_ratio = overall_runtime / overall_total_potential_minutes


    # overall_adjusted_target = overall_total_target * overall_uptime_ratio
    overall_adjusted_target = overall_run_time / overall_ideal_cycle_time if overall_ideal_cycle_time &gt; 0 else 0.0


    overall_availability = overall_run_time / overall_ppt if overall_ppt &gt; 0 else 1.0
    # overall_performance = (overall_ideal_cycle_time * overall_total_produced) / overall_run_time if overall_run_time &gt; 0 else 0.0

    if overall_adjusted_target == 0:
        overall_performance = 0
    else:
        overall_performance = overall_total_produced / overall_adjusted_target
    
    overall_quality = (overall_total_produced - overall_scrap_total) / overall_total_produced if overall_total_produced &gt; 0 else 0.0
    overall_oee = overall_availability * overall_performance * overall_quality

    lines_metrics = {}
    # By-line metrics calculations
    for line, totals in totals_by_line.items():
        produced = float(totals.get(&#34;total_produced&#34;, 0))
        target = float(totals.get(&#34;total_target&#34;, 0))
        potential = float(potential_minutes_by_line.get(line, 0))
        planned_downtime = float(planned_downtime_totals_by_line.get(line, 0))
        unplanned_downtime = float(unplanned_downtime_totals_by_line.get(line, 0))
        scrap = float(scrap_totals_by_line.get(line, 0))

        # produced = 500
        # target = 1000
        # potential = 7200
        # planned_downtime = 1800
        # unplanned_downtime = 1800
        # scrap = 0
        
        ppt = potential - planned_downtime
        run_time = ppt - (unplanned_downtime)
        ideal_cycle_time = ppt / target if target &gt; 0 else 0.0
        

        runtime = potential - unplanned_downtime - planned_downtime
        uptime_ratio = runtime / potential


        # adjusted_target = target * uptime_ratio
        adjusted_target = run_time / ideal_cycle_time if ideal_cycle_time &gt; 0 else 0.0

        availability = run_time / ppt if ppt &gt; 0 else 1.0
        # performance = (ideal_cycle_time * produced) / run_time if run_time &gt; 0 else 0.0
        if adjusted_target == 0:
            performance = 0
        else:
            performance = produced / adjusted_target
        quality = (produced - scrap) / produced if produced &gt; 0 else 0.0
        oee = availability * performance * quality
        
        lines_metrics[line] = {
            &#34;ppt&#34;: ppt,
            &#34;run_time&#34;: run_time,
            &#34;ideal_cycle_time&#34;: ideal_cycle_time,
            &#34;A&#34;: availability,
            &#34;P&#34;: performance,
            &#34;Q&#34;: quality,
            &#34;OEE&#34;: oee
        }
        
    overall_metrics = {
        &#34;ppt&#34;: overall_ppt,
        &#34;run_time&#34;: overall_run_time,
        &#34;ideal_cycle_time&#34;: overall_ideal_cycle_time,
        &#34;A&#34;: overall_availability,
        &#34;P&#34;: overall_performance,
        &#34;Q&#34;: overall_quality,
        &#34;OEE&#34;: overall_oee
    }
    
    return {&#34;overall&#34;: overall_metrics, &#34;lines&#34;: lines_metrics}</code></pre>
</details>
<div class="desc"><p>Compute OEE metrics overall and by line using the following formulas:</p>
<ol>
<li>Planned Production Time (PPT) = total_potential_minutes - planned_downtime</li>
<li>Run Time = PPT - (unplanned_downtime)</li>
<li>ideal_cycle_time = PPT / target_parts
(target_parts is overall_total_target or per-line target)</li>
<li>Availability = run_time / PPT</li>
<li>Performance = (ideal_cycle_time * actual_parts) / run_time</li>
<li>Quality = (total produced - scrap) / total produced</li>
<li>OEE = Availability * Performance * Quality</li>
</ol></div>
</dd>
<dt id="prod_query.views.compute_overlap_label"><code class="name flex">
<span>def <span class="ident">compute_overlap_label</span></span>(<span>detail_start, detail_end, pr_entries)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_overlap_label(detail_start, detail_end, pr_entries):
    &#34;&#34;&#34;
    Identify how a given detail interval overlaps with any PR entry interval.

    Iterates through a list of PR entries (each with `start_time`, optional `end_time`,
    and `idnumber`), and determines if the detail interval [detail_start, detail_end)
    overlaps with a PR interval. The first matching overlap type is returned along
    with the corresponding PR’s ID.

    Overlap types:
      - &#34;WITHIN PR&#34;:   detail interval is entirely inside the PR interval.
      - &#34;CONTAINS PR&#34;: detail interval entirely encompasses the PR interval.
      - &#34;OVERLAP LEFT&#34;: detail starts before the PR and ends inside it.
      - &#34;OVERLAP RIGHT&#34;: detail starts inside the PR and ends after it.
      - &#34;No Overlap&#34;:  no overlap with any PR interval.

    Parameters
    ----------
    detail_start : datetime.datetime
        Start timestamp of the detail interval.
    detail_end : datetime.datetime
        End timestamp of the detail interval.
    pr_entries : list of dict
        Each dict represents a PR event and must contain:
          - &#39;start_time&#39; (datetime.datetime): PR start.
          - &#39;end_time&#39; (datetime.datetime or None): PR end (None treated as ongoing).
          - &#39;idnumber&#39; (any, optional): identifier for the PR.

    Returns
    -------
    dict
        A dictionary with:
          - &#39;overlap&#39; (str): one of the overlap type strings.
          - &#39;pr_id&#39;    (same type as idnumber or None): the matched PR’s idnumber, or None
                         if there is no overlap.
    &#34;&#34;&#34;
    for pr in pr_entries:
        pr_start = pr[&#39;start_time&#39;]
        # If pr_end is None, treat it as an ongoing event by using datetime.max
        pr_end = pr[&#39;end_time&#39;] or datetime.max
        pr_id = pr.get(&#39;idnumber&#39;)
        
        # Check for no overlap
        if detail_end &lt;= pr_start or detail_start &gt;= pr_end:
            continue

        # Determine the type of overlap and return along with the idnumber
        if detail_start &gt;= pr_start and detail_end &lt;= pr_end:
            return {&#34;overlap&#34;: &#34;WITHIN PR&#34;, &#34;pr_id&#34;: pr_id}
        elif detail_start &lt;= pr_start and detail_end &gt;= pr_end:
            return {&#34;overlap&#34;: &#34;CONTAINS PR&#34;, &#34;pr_id&#34;: pr_id}
        elif detail_start &lt; pr_start and detail_end &gt; pr_start and detail_end &lt; pr_end:
            return {&#34;overlap&#34;: &#34;OVERLAP LEFT&#34;, &#34;pr_id&#34;: pr_id}
        elif detail_start &gt; pr_start and detail_start &lt; pr_end and detail_end &gt; pr_end:
            return {&#34;overlap&#34;: &#34;OVERLAP RIGHT&#34;, &#34;pr_id&#34;: pr_id}
    return {&#34;overlap&#34;: &#34;No Overlap&#34;, &#34;pr_id&#34;: None}</code></pre>
</details>
<div class="desc"><p>Identify how a given detail interval overlaps with any PR entry interval.</p>
<p>Iterates through a list of PR entries (each with <code>start_time</code>, optional <code>end_time</code>,
and <code>idnumber</code>), and determines if the detail interval [detail_start, detail_end)
overlaps with a PR interval. The first matching overlap type is returned along
with the corresponding PR’s ID.</p>
<p>Overlap types:
- "WITHIN PR":
detail interval is entirely inside the PR interval.
- "CONTAINS PR": detail interval entirely encompasses the PR interval.
- "OVERLAP LEFT": detail starts before the PR and ends inside it.
- "OVERLAP RIGHT": detail starts inside the PR and ends after it.
- "No Overlap":
no overlap with any PR interval.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>detail_start</code></strong> :&ensp;<code>datetime.datetime</code></dt>
<dd>Start timestamp of the detail interval.</dd>
<dt><strong><code>detail_end</code></strong> :&ensp;<code>datetime.datetime</code></dt>
<dd>End timestamp of the detail interval.</dd>
<dt><strong><code>pr_entries</code></strong> :&ensp;<code>list</code> of <code>dict</code></dt>
<dd>Each dict represents a PR event and must contain:
- 'start_time' (datetime.datetime): PR start.
- 'end_time' (datetime.datetime or None): PR end (None treated as ongoing).
- 'idnumber' (any, optional): identifier for the PR.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary with:
- 'overlap' (str): one of the overlap type strings.
- 'pr_id'
(same type as idnumber or None): the matched PR’s idnumber, or None
if there is no overlap.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.compute_press_pa_oee"><code class="name flex">
<span>def <span class="ident">compute_press_pa_oee</span></span>(<span>total_potential_minutes,<br>planned_minutes_down,<br>unplanned_minutes_down,<br>total_minutes_up,<br>cycle_time,<br>actual_parts,<br>total_target)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_press_pa_oee(total_potential_minutes, planned_minutes_down, unplanned_minutes_down, total_minutes_up, cycle_time, actual_parts, total_target):
    &#34;&#34;&#34;
    Calculates production effectiveness metrics for a press using the following formulas:

      1. Planned Production Time (PPT):
         PPT = total_potential_minutes - planned_minutes_down

      2. Total Downtime:
         total_downtime = planned_minutes_down + unplanned_minutes_down

      3. Run Time:
         run_time = PPT - total_downtime

      4. Target Parts:
         target_parts = PPT / cycle_time

      5. Availability:
         availability = run_time / PPT

      6. Performance:
         performance = (cycle_time * actual_parts) / run_time

      7. Quality:
         quality = 1.0  (assumed)

      8. Overall Equipment Effectiveness (OEE):
         oee = availability * performance * quality

    Args:
      total_potential_minutes (float): e.g., 7200 minutes (theoretical full-time)
      planned_minutes_down (float): Planned downtime in minutes (y)
      unplanned_minutes_down (float): Unplanned downtime in minutes (the rest of total downtime)
      total_minutes_up (float): Total minutes running (not used directly in these calculations)
      cycle_time (float): Ideal cycle time (in seconds) for one part (b)
      actual_parts (float): Actual parts produced (a)
      total_target (float): Provided target parts (will be recalculated)

    Returns:
      dict: A dictionary with keys:
         - planned_production_time (PPT)
         - run_time
         - target_parts
         - availability
         - performance
         - quality
         - oee
    &#34;&#34;&#34;
    try:
        total_potential_minutes = float(total_potential_minutes)
    except:
        total_potential_minutes = 0.0
    try:
        planned_minutes_down = float(planned_minutes_down)
    except:
        planned_minutes_down = 0.0
    try:
        unplanned_minutes_down = float(unplanned_minutes_down)
    except:
        unplanned_minutes_down = 0.0
    try:
        total_minutes_up = float(total_minutes_up)
    except:
        total_minutes_up = 0.0
    try:
        cycle_time = float(cycle_time)
    except:
        cycle_time = 0.0
    try:
        actual_parts = float(actual_parts)
    except:
        actual_parts = 0.0

    # 1. Planned Production Time (PPT)
    planned_production_time = total_potential_minutes - planned_minutes_down

    # 2. Total downtime and Run Time
    total_downtime = planned_minutes_down + unplanned_minutes_down
    run_time = planned_production_time - total_downtime

    # Check if run_time is less than 0, and adjust if necessary
    if run_time &lt; 0:
        run_time = total_minutes_up


    # 3. Target Parts (recalculated)
    target_parts = ((planned_production_time * 60)  / cycle_time) if cycle_time &gt; 0 else 0.0

    # Calculate availability
    availability = (run_time / planned_production_time) if planned_production_time &gt; 0 else 0.0

   

    # 5. Performance
    performance = ((cycle_time * actual_parts) / (run_time * 60)) if run_time &gt; 0 else 0.0

    # 6. Quality is assumed to be 100%
    quality = 1.0

    # 7. Overall Equipment Effectiveness (OEE)
    oee = availability * performance * quality

    return {
        &#34;planned_production_time&#34;: planned_production_time,
        &#34;run_time&#34;: run_time,
        &#34;target_parts&#34;: target_parts,
        &#34;availability&#34;: availability,
        &#34;performance&#34;: performance,
        &#34;quality&#34;: quality,
        &#34;oee&#34;: oee
    }</code></pre>
</details>
<div class="desc"><p>Calculates production effectiveness metrics for a press using the following formulas:</p>
<ol>
<li>
<p>Planned Production Time (PPT):
PPT = total_potential_minutes - planned_minutes_down</p>
</li>
<li>
<p>Total Downtime:
total_downtime = planned_minutes_down + unplanned_minutes_down</p>
</li>
<li>
<p>Run Time:
run_time = PPT - total_downtime</p>
</li>
<li>
<p>Target Parts:
target_parts = PPT / cycle_time</p>
</li>
<li>
<p>Availability:
availability = run_time / PPT</p>
</li>
<li>
<p>Performance:
performance = (cycle_time * actual_parts) / run_time</p>
</li>
<li>
<p>Quality:
quality = 1.0
(assumed)</p>
</li>
<li>
<p>Overall Equipment Effectiveness (OEE):
oee = availability * performance * quality</p>
</li>
</ol>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>total_potential_minutes</code></strong> :&ensp;<code>float</code></dt>
<dd>e.g., 7200 minutes (theoretical full-time)</dd>
<dt><strong><code>planned_minutes_down</code></strong> :&ensp;<code>float</code></dt>
<dd>Planned downtime in minutes (y)</dd>
<dt><strong><code>unplanned_minutes_down</code></strong> :&ensp;<code>float</code></dt>
<dd>Unplanned downtime in minutes (the rest of total downtime)</dd>
<dt><strong><code>total_minutes_up</code></strong> :&ensp;<code>float</code></dt>
<dd>Total minutes running (not used directly in these calculations)</dd>
<dt><strong><code>cycle_time</code></strong> :&ensp;<code>float</code></dt>
<dd>Ideal cycle time (in seconds) for one part (b)</dd>
<dt><strong><code>actual_parts</code></strong> :&ensp;<code>float</code></dt>
<dd>Actual parts produced (a)</dd>
<dt><strong><code>total_target</code></strong> :&ensp;<code>float</code></dt>
<dd>Provided target parts (will be recalculated)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary with keys:
- planned_production_time (PPT)
- run_time
- target_parts
- availability
- performance
- quality
- oee</dd>
</dl></div>
</dd>
<dt id="prod_query.views.cycle_times"><code class="name flex">
<span>def <span class="ident">cycle_times</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cycle_times(request):
    &#34;&#34;&#34;
    Render and process cycle-time queries for a specified machine and time range.

    On GET:
      - Simply renders the &#39;prod_query/cycle_query.html&#39; template with an empty context.

    On POST:
      1. Reads form data:
         - `machine` (str): machine identifier
         - `start_datetime` (str): start of shift, format &#34;YYYY-MM-DD HH:MM&#34;
         - `end_datetime` (str): end of shift, format &#34;YYYY-MM-DD HH:MM&#34;
         - `part_number` (str, optional): filter for a specific part
      2. Parses datetimes to Unix timestamps.
      3. Invokes `fetch_cycle_data(machine, start_ts, end_ts, include_zeros, part_number)`
         to retrieve a list of `(cycle_time_seconds, frequency)` tuples.
      4. Computes cycle metrics via `get_cycle_metrics`.
      5. Prepares histogram data (cycles ≤ 900 s) for a Chart.js bar chart (`chartdata`).
      6. Iterates over each day in the past year to:
         - Fetch daily cycle data
         - Compute the daily weighted cycle time
         - Include days with ≥ 300 total occurrences
         - Build a Chart.js line chart dataset (`yearly_chartdata`).
      7. Populates the template context with:
         - `result`: raw cycle-data list
         - `machine`, `part_number`
         - `start_datetime_str`, `end_datetime_str`
         - `cycle_metrics`: dict or None
         - `chartdata`: bar-chart config dict
         - `yearly_chartdata`: line-chart config dict
         - `error`: error message if inputs were missing

    Parameters
    ----------
    request : django.http.HttpRequest
        The HTTP request object. On POST, expects form fields as described above.

    Returns
    -------
    django.http.HttpResponse
        The rendered &#39;prod_query/cycle_query.html&#39; template with the context keys:
        - `result`, `machine`, `part_number`
        - `start_datetime_str`, `end_datetime_str`
        - `cycle_metrics`
        - `chartdata`
        - `yearly_chartdata`
        - `error` (optional)
    &#34;&#34;&#34;
    context = {}
    if request.method == &#39;POST&#39;:
        # Capture the machine and datetime values from the request
        machine = request.POST.get(&#39;machine&#39;)
        start_datetime_str = request.POST.get(&#39;start_datetime&#39;)
        end_datetime_str = request.POST.get(&#39;end_datetime&#39;)
        part_number = request.POST.get(&#39;part_number&#39;)
        include_zeros = True  # Adjust as needed

        # Check that all required values are present
        if machine and start_datetime_str and end_datetime_str:
            # Parse the datetime strings (assuming &#34;Y-m-d H:i&#34; format)
            shift_start = datetime.strptime(start_datetime_str, &#34;%Y-%m-%d %H:%M&#34;)
            shift_end = datetime.strptime(end_datetime_str, &#34;%Y-%m-%d %H:%M&#34;)
            start_ts = int(shift_start.timestamp())
            end_ts = int(shift_end.timestamp())

            # Fetch cycle data for the shift
            res = fetch_cycle_data(machine, start_ts, end_ts, include_zeros, part_number)
            context[&#39;result&#39;] = res
            context[&#39;machine&#39;] = machine
            context[&#39;part_number&#39;] = part_number
            # Pass the submitted datetime strings to the template for display
            context[&#39;start_datetime_str&#39;] = start_datetime_str
            context[&#39;end_datetime_str&#39;] = end_datetime_str

            # Compute cycle metrics for the shift if data exists
            if res:
                cycle_metrics = get_cycle_metrics(res)
                context[&#39;cycle_metrics&#39;] = cycle_metrics
            else:
                context[&#39;cycle_metrics&#39;] = None

            # Prepare ChartJS data for the histogram (bar chart)
            # Filter out cycles longer than 15 minutes (900 seconds)
            filtered_chart_data = [(ct, freq) for ct, freq in res if ct &lt;= 900]
            chart_labels = [ct for ct, freq in filtered_chart_data]
            chart_values = [freq for ct, freq in filtered_chart_data]
            context[&#39;chartdata&#39;] = {
                &#39;labels&#39;: chart_labels,
                &#39;dataset&#39;: {
                    &#39;label&#39;: &#39;Cycle Occurrences&#39;,
                    &#39;data&#39;: chart_values,
                    &#39;backgroundColor&#39;: &#39;rgba(75, 192, 192, 0.2)&#39;,
                    &#39;borderColor&#39;: &#39;rgba(75, 192, 192, 1)&#39;,
                    &#39;borderWidth&#39;: 1,
                }
            }

            # --- Now fetch data for the past year ---
            today = datetime.today().date()
            one_year_ago = today - timedelta(days=365)
            daily_dates = []
            daily_weighted_cycle = []

            # Iterate day by day over the last year
            current_day = one_year_ago
            while current_day &lt;= today:
                day_start = datetime.combine(current_day, datetime.min.time())
                day_end = datetime.combine(current_day, datetime.max.time())
                day_start_ts = int(day_start.timestamp())
                day_end_ts = int(day_end.timestamp())

                # Fetch daily cycle data and compute metrics
                daily_data = fetch_cycle_data(machine, day_start_ts, day_end_ts, include_zeros, part_number)
                daily_metrics = get_cycle_metrics(daily_data)
                daily_wct = daily_metrics[&#39;weighted_cycle_time&#39;]

                # Compute the total occurrences for the day
                total_occurrences = sum(freq for _, freq in daily_data)
                # Include the day only if it has at least 300 total cycle occurrences
                if total_occurrences &gt;= 300:
                    daily_dates.append(current_day.strftime(&#34;%Y-%m-%d&#34;))
                    daily_weighted_cycle.append(daily_wct)

                current_day += timedelta(days=1)

            # Prepare ChartJS data for the yearly line chart
            context[&#39;yearly_chartdata&#39;] = {
                &#39;labels&#39;: daily_dates,
                &#39;datasets&#39;: [
                    {
                        &#39;label&#39;: &#39;Daily Weighted Cycle Time&#39;,
                        &#39;data&#39;: daily_weighted_cycle,
                        &#39;fill&#39;: False,
                        &#39;borderColor&#39;: &#39;rgba(255, 99, 132, 1)&#39;,
                        &#39;tension&#39;: 0.1,
                    },
                ]
            }
        else:
            context[&#39;error&#39;] = &#34;Missing machine or datetime values.&#34;

    return render(request, &#39;prod_query/cycle_query.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Render and process cycle-time queries for a specified machine and time range.</p>
<p>On GET:
- Simply renders the 'prod_query/cycle_query.html' template with an empty context.</p>
<p>On POST:
1. Reads form data:
- <code>machine</code> (str): machine identifier
- <code>start_datetime</code> (str): start of shift, format "YYYY-MM-DD HH:MM"
- <code>end_datetime</code> (str): end of shift, format "YYYY-MM-DD HH:MM"
- <code>part_number</code> (str, optional): filter for a specific part
2. Parses datetimes to Unix timestamps.
3. Invokes <code><a title="prod_query.views.fetch_cycle_data" href="#prod_query.views.fetch_cycle_data">fetch_cycle_data()</a>(machine, start_ts, end_ts, include_zeros, part_number)</code>
to retrieve a list of <code>(cycle_time_seconds, frequency)</code> tuples.
4. Computes cycle metrics via <code><a title="prod_query.views.get_cycle_metrics" href="#prod_query.views.get_cycle_metrics">get_cycle_metrics()</a></code>.
5. Prepares histogram data (cycles ≤ 900 s) for a Chart.js bar chart (<code>chartdata</code>).
6. Iterates over each day in the past year to:
- Fetch daily cycle data
- Compute the daily weighted cycle time
- Include days with ≥ 300 total occurrences
- Build a Chart.js line chart dataset (<code>yearly_chartdata</code>).
7. Populates the template context with:
- <code>result</code>: raw cycle-data list
- <code>machine</code>, <code>part_number</code>
- <code>start_datetime_str</code>, <code>end_datetime_str</code>
- <code>cycle_metrics</code>: dict or None
- <code>chartdata</code>: bar-chart config dict
- <code>yearly_chartdata</code>: line-chart config dict
- <code>error</code>: error message if inputs were missing</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The HTTP request object. On POST, expects form fields as described above.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>The rendered 'prod_query/cycle_query.html' template with the context keys:
- <code>result</code>, <code>machine</code>, <code>part_number</code>
- <code>start_datetime_str</code>, <code>end_datetime_str</code>
- <code>cycle_metrics</code>
- <code>chartdata</code>
- <code>yearly_chartdata</code>
- <code>error</code> (optional)</dd>
</dl></div>
</dd>
<dt id="prod_query.views.deep_dive"><code class="name flex">
<span>def <span class="ident">deep_dive</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def deep_dive(request):
    &#34;&#34;&#34;
    View to handle detailed downtime data sent from the frontend.
    It receives machine_id, start_date, and end_date, fetches entries, calculates downtime, and returns them as JSON.
    &#34;&#34;&#34;
    if request.method == &#39;POST&#39;:
        try:
            # Parse the incoming JSON data
            data = json.loads(request.body)
            
            # Extract the required fields
            machine_id = data.get(&#39;machine_id&#39;)
            start_date = data.get(&#39;start_date&#39;)
            end_date = data.get(&#39;end_date&#39;)

            # Determine the machine to query
            query_machine_id = MACHINE_MAP.get(machine_id, machine_id)

            # Fetch entries using the mapped machine_id
            raw_entries = fetch_prdowntime1_entries(query_machine_id, start_date, end_date)

            # Process entries to calculate downtime
            processed_entries = []
            for entry in raw_entries:
                problem = entry[0]
                called4helptime = entry[1]
                completedtime = entry[2]

                # Calculate downtime in minutes
                if completedtime:
                    downtime_minutes = round((completedtime - called4helptime).total_seconds() / 60)
                else:
                    downtime_minutes = &#34;In Progress&#34;

                processed_entries.append({
                    &#34;problem&#34;: problem,
                    &#34;called4helptime&#34;: called4helptime.isoformat(),
                    &#34;completedtime&#34;: completedtime.isoformat() if completedtime else None,
                    &#34;downtime_minutes&#34;: downtime_minutes
                })

            # Print the start and end times in timestamp format
            start_timestamp = datetime.fromisoformat(start_date).timestamp()
            end_timestamp = datetime.fromisoformat(end_date).timestamp()
            # print(f&#34;[INFO] Start Date (Timestamp): {int(start_timestamp)}, End Date (Timestamp): {int(end_timestamp)}&#34;)

            # Fetch chart data with machine hardcoded to &#39;1703&#39;
            labels, *data_series = fetch_chart_data(
                machine=machine_id,
                start=int(start_timestamp),
                end=int(end_timestamp),
                interval=5,
                group_by_shift=False
            )

            # Print the first 10 datapoints from the function
            # print(f&#34;[INFO] First 10 Datapoints from fetch_chart_data:&#34;)
            # for label, *data in zip(labels[:10], *[series[:10] for series in data_series]):
            #     print(f&#34;Label: {label}, Data: {data}&#34;)

            # Return the processed entries and chart data in the JSON response
            return JsonResponse({
                &#39;message&#39;: &#39;Data received successfully&#39;,
                &#39;entries&#39;: processed_entries,
                &#39;chart_data&#39;: {
                    &#39;labels&#39;: labels,
                    &#39;data_series&#39;: data_series
                }
            }, status=200)
        
        except json.JSONDecodeError as e:
            # Handle JSON parsing errors
            print(f&#34;[ERROR] Failed to decode JSON: {e}&#34;)
            return JsonResponse({&#39;error&#39;: &#39;Invalid JSON data&#39;}, status=400)
        except Exception as e:
            # Handle other exceptions
            print(f&#34;[ERROR] Exception in deep_dive: {e}&#34;)
            return JsonResponse({&#39;error&#39;: str(e)}, status=500)
    
    # If the request method is not POST, return a 405 Method Not Allowed response
    print(&#34;[ERROR] Invalid request method received. Only POST is allowed.&#34;)
    return JsonResponse({&#39;error&#39;: &#39;Invalid request method&#39;}, status=405)</code></pre>
</details>
<div class="desc"><p>View to handle detailed downtime data sent from the frontend.
It receives machine_id, start_date, and end_date, fetches entries, calculates downtime, and returns them as JSON.</p></div>
</dd>
<dt id="prod_query.views.downtime_frequency_view"><code class="name flex">
<span>def <span class="ident">downtime_frequency_view</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def downtime_frequency_view(request):
    &#34;&#34;&#34;
    View to render the downtime frequency page with debugging to trace discrepancies.
    Updated to handle downtime thresholds in seconds.
    &#34;&#34;&#34;
    machine_numbers = get_distinct_machines(lines)
    downtime_result = None
    threshold_breach_count = None
    interval_results = []  # Store results for each interval

    if request.method == &#34;GET&#34;:
        # Get form inputs
        start_date = request.GET.get(&#39;start_date&#39;)
        end_date = request.GET.get(&#39;end_date&#39;)
        selected_machine = request.GET.get(&#39;machine&#39;)
        downtime_threshold = request.GET.get(&#39;downtime_threshold&#39;, 0)  # Threshold in seconds
        view_interval = request.GET.get(&#39;view_interval&#39;, 60)  # Default interval is 60 minutes

        if start_date and end_date and selected_machine:
            # Parse inputs
            start_timestamp, end_timestamp = parse_dates(start_date, end_date)
            downtime_threshold = int(downtime_threshold)  # Already in seconds

            try:
                view_interval = int(view_interval) * 60  # Convert minutes to seconds
            except ValueError:
                view_interval = 3600  # Default to 1 hour (3600 seconds)

            if start_timestamp and end_timestamp:
                # Calculate total downtime for the full range
                downtime_result, threshold_breach_count = fetch_downtime_results(
                    selected_machine, start_timestamp, end_timestamp, downtime_threshold
                )

                # Split the time range into intervals and calculate for each
                interval_count = ceil((end_timestamp - start_timestamp) / view_interval)
                current_start = start_timestamp

                for i in range(interval_count):
                    current_end = min(current_start + view_interval, end_timestamp)
                    interval_downtime, interval_breaches = fetch_downtime_results(
                        selected_machine, current_start, current_end, downtime_threshold
                    )
                    # Append only if downtime or breaches &gt; 0
                    if interval_downtime &gt; 0 or interval_breaches &gt; 0:
                        interval_results.append({
                            &#39;start_time&#39;: datetime.fromtimestamp(current_start).strftime(&#39;%Y-%m-%d %H:%M:%S&#39;),
                            &#39;end_time&#39;: datetime.fromtimestamp(current_end).strftime(&#39;%Y-%m-%d %H:%M:%S&#39;),
                            &#39;downtime&#39;: interval_downtime,  # Downtime is in minutes
                            &#39;breaches&#39;: interval_breaches
                        })
                    current_start = current_end  # Move to the next interval

    return render(request, &#39;prod_query/downtime_frequency.html&#39;, {
        &#39;machines&#39;: machine_numbers,
        &#39;downtime_result&#39;: downtime_result,
        &#39;threshold_breach_count&#39;: threshold_breach_count,
        &#39;interval_results&#39;: interval_results,  # Pass filtered interval data to the template
    })</code></pre>
</details>
<div class="desc"><p>View to render the downtime frequency page with debugging to trace discrepancies.
Updated to handle downtime thresholds in seconds.</p></div>
</dd>
<dt id="prod_query.views.drilldown_calculate_P"><code class="name flex">
<span>def <span class="ident">drilldown_calculate_P</span></span>(<span>total_produced, total_adjusted_target, downtime)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drilldown_calculate_P(total_produced, total_adjusted_target, downtime):
    &#34;&#34;&#34;
    Calculate the P value (percentage) for a machine.

    Args:
        total_produced (int): Total items produced by the machine.
        total_adjusted_target (int): Total adjusted target for the machine.
        downtime (str): Downtime percentage as a string (e.g., &#34;85%&#34;).

    Returns:
        str: P value as a percentage (e.g., &#34;85%&#34;).
    &#34;&#34;&#34;
    # Convert downtime to numeric value for comparison
    downtime_percentage = float(downtime.strip(&#39;%&#39;))

    # If downtime is 100%, return P as 100%
    if downtime_percentage == 100.0:
        return &#34;100%&#34;

    # Avoid division by zero
    if total_adjusted_target == 0:
        return &#34;0%&#34;

    # Calculate P value
    p_value = round((total_produced / total_adjusted_target) * 100)
    return f&#34;{p_value}%&#34;</code></pre>
</details>
<div class="desc"><p>Calculate the P value (percentage) for a machine.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>total_produced</code></strong> :&ensp;<code>int</code></dt>
<dd>Total items produced by the machine.</dd>
<dt><strong><code>total_adjusted_target</code></strong> :&ensp;<code>int</code></dt>
<dd>Total adjusted target for the machine.</dd>
<dt><strong><code>downtime</code></strong> :&ensp;<code>str</code></dt>
<dd>Downtime percentage as a string (e.g., "85%").</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>P value as a percentage (e.g., "85%").</dd>
</dl></div>
</dd>
<dt id="prod_query.views.fetch_chart_data"><code class="name flex">
<span>def <span class="ident">fetch_chart_data</span></span>(<span>machine, start, end, interval=5, group_by_shift=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_chart_data(machine, start, end, interval=5, group_by_shift=False):
    &#34;&#34;&#34;
    Fetch chart data for a specific machine between start and end times.
    
    Parameters:
    - machine: str, identifier of the machine
    - start: int, start of the period (Unix timestamp)
    - end: int, end of the period (Unix timestamp)
    - interval: int, time interval in minutes for strokes per minute data (default is 5)
    - group_by_shift: bool, whether to group data by shift (default is False)
    
    Returns:
    - labels: list of timestamps or dates
    - data: list of counts or lists of counts for each shift
    &#34;&#34;&#34;
    
    # Construct the SQL query based on whether data should be grouped by shift or by time intervals
    if group_by_shift:
        sql = f&#39;SELECT DATE(FROM_UNIXTIME(TimeStamp)) as event_date, &#39;
        sql += f&#39;CASE &#39;
        sql += f&#39;WHEN HOUR(FROM_UNIXTIME(TimeStamp)) &gt;= 7 AND HOUR(FROM_UNIXTIME(TimeStamp)) &lt; 15 THEN &#34;Day&#34; &#39;
        sql += f&#39;WHEN HOUR(FROM_UNIXTIME(TimeStamp)) &gt;= 15 AND HOUR(FROM_UNIXTIME(TimeStamp)) &lt; 23 THEN &#34;Afternoon&#34; &#39;
        sql += f&#39;ELSE &#34;Night&#34; &#39;
        sql += f&#39;END AS Shift, &#39;
        sql += f&#39;count(*) &#39;
        sql += f&#39;FROM GFxPRoduction &#39;
        sql += f&#39;WHERE TimeStamp BETWEEN {start} AND {end} &#39;
        sql += f&#39;AND Machine = &#34;{machine}&#34; &#39;
        sql += f&#39;GROUP BY event_date, Shift &#39;
        sql += f&#39;ORDER BY event_date, Shift;&#39;
    else:
        sql = f&#39;SELECT DATE_ADD(&#39;
        sql += f&#39;FROM_UNIXTIME({start}), &#39;
        sql += f&#39;Interval CEILING(TIMESTAMPDIFF(MINUTE, FROM_UNIXTIME({start}), &#39;
        sql += f&#39;FROM_UNIXTIME(TimeStamp))/{interval})*{interval} minute) as event_datetime_interval, &#39;
        sql += f&#39;count(*) &#39;
        sql += f&#39;FROM GFxPRoduction &#39;
        sql += f&#39;WHERE TimeStamp BETWEEN {start} AND {end} AND Machine = &#34;{machine}&#34; &#39;
        sql += f&#39;GROUP BY event_datetime_interval &#39;
        sql += f&#39;ORDER BY event_datetime_interval;&#39;

    # Execute the SQL query and fetch the results
    with connections[&#39;prodrpt-md&#39;].cursor() as c:
        c.execute(sql)
        data = c.fetchall()

    labels = []
    counts = []
    
    if group_by_shift:
        # Initialize lists for each shift
        day_counts = []
        afternoon_counts = []
        night_counts = []

        # Create an iterator for the fetched data
        data_iter = iter(data)
        row = next(data_iter, None)

        interval = 24 * 60 * 60  # Interval of 1 day

        # Iterate over each day in the specified period
        for timestamp in range(start, end, interval):
            dt = datetime.fromtimestamp(timestamp).date()

            # Initialize counts for each shift
            day_count = 0
            afternoon_count = 0
            night_count = 0

            # Accumulate counts for each shift within the current date interval
            while row and row[0] == dt:
                if row[1] == &#39;Day&#39;:
                    day_count = row[2]
                elif row[1] == &#39;Afternoon&#39;:
                    afternoon_count = row[2]
                elif row[1] == &#39;Night&#39;:
                    night_count = row[2]
                row = next(data_iter, None)

            # Append the results for the current date to the lists
            labels.append(dt)
            day_counts.append(day_count)
            afternoon_counts.append(afternoon_count)
            night_counts.append(night_count)
            counts.append(day_count + afternoon_count + night_count)

        return labels, day_counts, afternoon_counts, night_counts, counts
    else:
        # Create an iterator for the fetched data
        data_iter = iter(data)
        row = next(data_iter, None)
        
        # Iterate over each time interval in the specified period
        for time in range(int(start), int(end), interval * 60):
            dt = datetime.fromtimestamp(time)

            # Initialize count for the current interval
            if not row:
                row = (dt, 0)
            if row and row[0] &gt; dt:
                labels.append(dt)
                counts.append(0)
                continue
            while row and row[0] &lt; dt:
                row = next(data_iter, None)
            if row and row[0] == dt:
                labels.append(dt)
                counts.append(row[1] / interval)
                row = next(data_iter, None)

        return labels, counts</code></pre>
</details>
<div class="desc"><p>Fetch chart data for a specific machine between start and end times.</p>
<p>Parameters:
- machine: str, identifier of the machine
- start: int, start of the period (Unix timestamp)
- end: int, end of the period (Unix timestamp)
- interval: int, time interval in minutes for strokes per minute data (default is 5)
- group_by_shift: bool, whether to group data by shift (default is False)</p>
<p>Returns:
- labels: list of timestamps or dates
- data: list of counts or lists of counts for each shift</p></div>
</dd>
<dt id="prod_query.views.fetch_combined_oee_production_data"><code class="name flex">
<span>def <span class="ident">fetch_combined_oee_production_data</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_combined_oee_production_data(request):
    &#34;&#34;&#34;
    A unified view that always excludes weekends from the production data.
    Processes production and downtime information at the machine level, aggregates totals per line,
    and then computes operation-level OEE metrics for display.
    &#34;&#34;&#34;
    from django.http import JsonResponse
    import datetime, os, importlib
    from datetime import timedelta

    # Get date range from GET parameters.
    start_date_str = request.GET.get(&#39;start_date&#39;)
    end_date_str = request.GET.get(&#39;end_date&#39;)
    if not start_date_str or not end_date_str:
        return JsonResponse({&#34;error&#34;: &#34;start_date and end_date must be provided in GET parameters.&#34;})
    
    try:
        start_date_obj = datetime.datetime.strptime(start_date_str, &#34;%Y-%m-%d %H:%M&#34;)
    except ValueError:
        start_date_obj = datetime.datetime.strptime(start_date_str, &#34;%Y-%m-%d&#34;)
    previous_day_str = (start_date_obj.date() - timedelta(days=1)).strftime(&#34;%Y-%m-%d&#34;)

    # Set up the database connection.
    settings_path = os.path.join(os.path.dirname(__file__), &#39;../pms/settings.py&#39;)
    spec = importlib.util.spec_from_file_location(&#34;settings&#34;, settings_path)
    settings = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(settings)
    get_db_connection = settings.get_db_connection_new
    conn = get_db_connection()
    cursor = conn.cursor()

    # Initialize accumulators and data structures.
    production_data = {}   # { line_name: { machine_number: { ... } } }
    downtime_totals_by_line = {}
    planned_downtime_totals_by_line = {}
    unplanned_downtime_totals_by_line = {}
    totals_by_line = {}
    scrap_totals_by_line = {}
    potential_minutes_by_line = {}

    overall_total_produced = 0
    overall_total_target = 0
    overall_planned_downtime_minutes = 0
    overall_unplanned_downtime_minutes = 0
    overall_downtime_seconds = 0
    overall_scrap_total = 0
    overall_total_potential_minutes = 0

    # Data structure to store per-operation metrics.
    operation_oee_metrics = []

    # Global &#39;lines&#39; is assumed to be defined elsewhere.
    global lines
    for line in lines:
        line_name = line[&#34;line&#34;]
        production_data.setdefault(line_name, {})
        downtime_totals_by_line.setdefault(line_name, 0)
        planned_downtime_totals_by_line.setdefault(line_name, 0)
        unplanned_downtime_totals_by_line.setdefault(line_name, 0)
        totals_by_line.setdefault(line_name, {&#34;total_produced&#34;: 0, &#34;total_target&#34;: 0})
        scrap_totals_by_line.setdefault(line_name, 0)
        potential_minutes_by_line.setdefault(line_name, 0)

    # Always exclude weekends: split the date range into valid intervals.
    intervals = stip_weekends(start_date_str, end_date_str)
    if not intervals:
        cursor.close()
        conn.close()
        return JsonResponse({&#34;error&#34;: &#34;No valid time blocks remain after excluding weekends.&#34;})
    
    # Process each non-weekend interval.
    for block_start, block_end in intervals:
        block_queried_minutes = int((block_end - block_start).total_seconds() / 60)
        block_start_timestamp = int(block_start.timestamp())
        block_end_timestamp = int(block_end.timestamp())
        
        # Update potential minutes per line.
        for line in lines:
            line_name = line[&#34;line&#34;]
            machine_count = sum(len(op.get(&#34;machines&#34;, [])) for op in line.get(&#34;operations&#34;, []))
            potential_minutes_by_line[line_name] += machine_count * block_queried_minutes

        # Process production and downtime per machine for this interval.
        for line in lines:
            line_name = line[&#34;line&#34;]

            # Initialize line-level accumulators.
            line_total_parts = 0
            line_total_target = 0
            line_total_downtime_minutes = 0
            line_total_planned_downtime = 0
            line_total_unplanned_downtime = 0
            line_total_queried_minutes = 0

            # Loop through each operation on the current line.
            for operation in line.get(&#34;operations&#34;, []):
                op_name = operation[&#34;op&#34;]
                # print(f&#34;[DEBUG] Processing Operation: {op_name} on Line: {line_name}&#34;)
                
                # Initialize operation-level accumulators.
                op_total_parts = 0
                op_total_target = 0
                op_total_downtime_minutes = 0
                op_total_planned_downtime = 0
                op_total_unplanned_downtime = 0
                op_total_queried_minutes = 0

                # Process each machine within the operation.
                for machine in operation.get(&#34;machines&#34;, []):
                    machine_number = machine[&#34;number&#34;]
                    # print(f&#34;[DEBUG] -- Processing Machine: {machine_number} in Operation: {op_name}&#34;)
                    
                    # Initialize machine data if not already present.
                    machine_data = production_data[line_name].setdefault(
                        machine_number, {
                            &#34;produced_parts&#34;: 0,
                            &#34;target&#34;: 0,
                            &#34;downtime_seconds&#34;: 0,
                            &#34;downtime_minutes&#34;: 0,
                            &#34;pr_downtime_entries&#34;: [],
                            &#34;downtime_events&#34;: [],
                            &#34;planned_downtime_minutes&#34;: 0,
                            &#34;unplanned_downtime_minutes&#34;: 0,
                            &#34;total_queried_minutes&#34;: 0,
                        }
                    )

                    # Increment total queried minutes.
                    machine_data[&#34;total_queried_minutes&#34;] += block_queried_minutes
                    op_total_queried_minutes += block_queried_minutes
                    line_total_queried_minutes += block_queried_minutes
                    # print(f&#34;[DEBUG] ---- Added {block_queried_minutes} queried minutes to Machine: {machine_number}&#34;)

                    # Fetch production data.
                    prod_data = get_production_data_for_machine(
                        cursor, machine, machine_number,
                        block_start_timestamp, block_end_timestamp,
                        op_name, block_queried_minutes, line_name
                    )
                    produced = prod_data.get(&#34;produced_parts&#34;, 0)
                    target = prod_data.get(&#34;target&#34;, 0)

                    # Update machine&#39;s production values.
                    machine_data[&#34;produced_parts&#34;] += produced
                    machine_data[&#34;target&#34;] += target
                    # print(f&#34;[DEBUG] ---- Machine {machine_number}: Produced = {produced}, Target = {target}&#34;)

                    # Accumulate production data for operation and line.
                    op_total_parts += produced
                    op_total_target += target
                    line_total_parts += produced
                    line_total_target += target

                    # Calculate downtime events.
                    downtime_seconds, downtime_events = calculate_downtime_events(
                        cursor, machine_number, block_start_timestamp, block_end_timestamp
                    )
                    downtime_minutes = int(downtime_seconds / 60)
                    machine_data[&#34;downtime_seconds&#34;] += downtime_seconds
                    machine_data[&#34;downtime_minutes&#34;] += downtime_minutes
                    op_total_downtime_minutes += downtime_minutes
                    line_total_downtime_minutes += downtime_minutes
                    # print(f&#34;[DEBUG] ---- Machine {machine_number}: Downtime seconds = {downtime_seconds}, minutes = {downtime_minutes}&#34;)

                    downtime_totals_by_line[line_name] += downtime_seconds

                    # Retrieve PR downtime entries.
                    pr_entries = get_pr_downtime_entries(machine_number, block_start, block_end)
                    machine_data[&#34;pr_downtime_entries&#34;].extend(pr_entries)
                    # print(f&#34;[DEBUG] ---- Machine {machine_number}: Retrieved {len(pr_entries)} PR downtime entries&#34;)

                    # Annotate downtime events with overlap info.
                    for event in downtime_events:
                        try:
                            detail_start = datetime.datetime.strptime(event[&#34;start&#34;], &#34;%Y-%m-%d %H:%M&#34;)
                            detail_end = datetime.datetime.strptime(event[&#34;end&#34;], &#34;%Y-%m-%d %H:%M&#34;)
                            overlap_info = compute_overlap_label(detail_start, detail_end, pr_entries)
                            event[&#34;overlap&#34;] = overlap_info[&#34;overlap&#34;]
                            event[&#34;pr_id&#34;] = overlap_info[&#34;pr_id&#34;]
                        except Exception as e:
                            print(f&#34;[ERROR] Error annotating downtime event {event}: {e}&#34;)
                    machine_data[&#34;downtime_events&#34;].extend(downtime_events)
                    # print(f&#34;[DEBUG] ---- Machine {machine_number}: Added {len(downtime_events)} downtime events&#34;)

                    # Calculate planned downtime.
                    planned = calculate_planned_downtime(downtime_events, pr_entries)
                    machine_data[&#34;planned_downtime_minutes&#34;] += planned
                    op_total_planned_downtime += planned
                    line_total_planned_downtime += planned
                    # print(f&#34;[DEBUG] ---- Machine {machine_number}: Planned downtime = {planned} minutes&#34;)

                    # Calculate unplanned downtime.
                    total_downtime = downtime_minutes
                    unplanned = calculate_unplanned_downtime(total_downtime, planned)
                    machine_data[&#34;unplanned_downtime_minutes&#34;] += unplanned
                    op_total_unplanned_downtime += unplanned
                    line_total_unplanned_downtime += unplanned
                    # print(f&#34;[DEBUG] ---- Machine {machine_number}: Unplanned downtime = {unplanned} minutes&#34;)

                    # Update overall downtime accumulators.
                    planned_downtime_totals_by_line[line_name] += planned
                    unplanned_downtime_totals_by_line[line_name] += unplanned
                    overall_planned_downtime_minutes += planned
                    overall_unplanned_downtime_minutes += unplanned

                # End of machines loop; print operation-level aggregated values.
                # print(f&#34;[DEBUG] Aggregated Operation {op_name} Totals: Produced = {op_total_parts}, Target = {op_total_target}, Downtime = {op_total_downtime_minutes} minutes, Planned = {op_total_planned_downtime} minutes, Unplanned = {op_total_unplanned_downtime} minutes, Queried Minutes = {op_total_queried_minutes}&#34;)

            # End of operations for this line.
         
        
        # Fetch and accumulate scrap data for the interval.
        scrap_by_line, scrap_total = fetch_daily_scrap_data(cursor, block_start, block_end)
        for line_name, scrap_val in scrap_by_line.items():
            scrap_totals_by_line[line_name] += scrap_val
        overall_scrap_total += scrap_total

    # Aggregate production totals per line.
    for line_name, machines in production_data.items():
        for machine_number, machine_data in machines.items():
            totals_by_line[line_name][&#34;total_produced&#34;] += machine_data.get(&#34;produced_parts&#34;, 0)
            totals_by_line[line_name][&#34;total_target&#34;] += machine_data.get(&#34;target&#34;, 0)
            overall_total_produced += machine_data.get(&#34;produced_parts&#34;, 0)
            overall_total_target += machine_data.get(&#34;target&#34;, 0)

    overall_downtime_minutes = int(overall_downtime_seconds + sum(downtime_totals_by_line.values()) / 60)
    overall_total_potential_minutes = sum(potential_minutes_by_line.values())

    # --- Compute machine-level OEE metrics and P×A for each machine. ---
    for line_name, machines in production_data.items():
        for machine_number, machine_data in machines.items():
                potential = machine_data.get(&#34;total_queried_minutes&#34;, 0)
                planned   = machine_data.get(&#34;planned_downtime_minutes&#34;, 0)
                unplanned = machine_data.get(&#34;unplanned_downtime_minutes&#34;, 0)
                target    = machine_data.get(&#34;target&#34;, 0)

                # 1) PPT = potential – planned
                ppt = max(0, potential - planned)
                machine_data[&#34;ppt&#34;] = ppt
        
                # **NEW**: if there’s no planned production time, drop its target to zero
                if ppt == 0:
                    machine_data[&#34;target&#34;] = 0

                # 2) Runtime = PPT – unplanned
                machine_data[&#34;runtime&#34;] = max(0, ppt - unplanned)

                # 3) Ideal Cycle Time = minutes of PPT per part
                if target &gt; 0:
                    machine_data[&#34;ideal_cycle_time&#34;] = ppt / target
                else:
                    machine_data[&#34;ideal_cycle_time&#34;] = 0.0

                # existing A &amp; P calculation
                machine_metrics = compute_machine_oee(
                    machine_data,
                    machine_data.get(&#34;total_queried_minutes&#34;, 0)
                )
                machine_data.update(machine_metrics)

                # new: calculate the P×A metric
                machine_data[&#34;PA&#34;] = machine_data.get(&#34;P&#34;, 0.0) * machine_data.get(&#34;A&#34;, 0.0)


    # --- Compute machine downtime percentage for each machine. ---
    for line_name, machines in production_data.items():
        for machine_number, machine_data in machines.items():
            downtime_metrics = compute_machine_downtime_percentage(machine_data)
            machine_data.update(downtime_metrics)
            machine_data[&#34;adjusted_downtime_percentage&#34;] = 100 - machine_data.get(&#34;downtime_percentage&#34;, 0)


    # --- Apply color gradients (now including P×A) ---
    for line_name, machines in production_data.items():
        apply_color_gradient_to_line(machines, &#34;P&#34;,  &#34;P_color&#34;)
        apply_color_gradient_to_line(machines, &#34;A&#34;,  &#34;A_color&#34;)
        apply_color_gradient_to_line(machines, &#34;adjusted_downtime_percentage&#34;, &#34;downtime_percentage_color&#34;)
        # new: color for P×A
        apply_color_gradient_to_line(machines, &#34;PA&#34;, &#34;PA_color&#34;)


    # Compute the overall OEE metrics.
    oee_metrics = compute_oee_metrics(
        totals_by_line,
        overall_total_produced,
        overall_total_target,
        overall_total_potential_minutes,
        overall_unplanned_downtime_minutes,
        overall_planned_downtime_minutes,
        overall_scrap_total,
        scrap_totals_by_line,
        potential_minutes_by_line,
        planned_downtime_totals_by_line,
        unplanned_downtime_totals_by_line
    )

    # --- Final pass: Aggregate operation-level totals and compute A, P, P×A, plus PPT, Runtime, SCT ---
    for line in lines:
        line_name = line[&#34;line&#34;]
        for operation in line.get(&#34;operations&#34;, []):
            # 1) Build per-op raw totals
            op_totals = {
                &#34;total_parts&#34;:             0,
                &#34;total_target&#34;:            0,
                &#34;total_downtime&#34;:          0,
                &#34;total_planned_downtime&#34;:  0,
                &#34;total_unplanned_downtime&#34;:0,
                &#34;total_queried_minutes&#34;:   0,
            }
            for machine in operation.get(&#34;machines&#34;, []):
                data = production_data[line_name][machine[&#34;number&#34;]]

                # Always accumulate parts &amp; target (target is already zero if ppt==0)
                op_totals[&#34;total_parts&#34;]  += data.get(&#34;produced_parts&#34;, 0)
                op_totals[&#34;total_target&#34;] += data.get(&#34;target&#34;, 0)

                # Only include downtime &amp; queried minutes if machine actually had PPT &gt; 0
                if data.get(&#34;ppt&#34;, 0) &gt; 0:
                    op_totals[&#34;total_downtime&#34;]           += data.get(&#34;downtime_minutes&#34;, 0)
                    op_totals[&#34;total_planned_downtime&#34;]   += data.get(&#34;planned_downtime_minutes&#34;, 0)
                    op_totals[&#34;total_unplanned_downtime&#34;] += data.get(&#34;unplanned_downtime_minutes&#34;, 0)
                    op_totals[&#34;total_queried_minutes&#34;]    += data.get(&#34;total_queried_minutes&#34;, 0)

            # 2) Compute PPT, Runtime, and SCT
            potential    = op_totals[&#34;total_queried_minutes&#34;]
            planned      = op_totals[&#34;total_planned_downtime&#34;]
            unplanned    = op_totals[&#34;total_unplanned_downtime&#34;]
            total_target = op_totals[&#34;total_target&#34;]

            ppt     = max(0, potential - planned)
            runtime = max(0, ppt - unplanned)
            sct     = (ppt / total_target) if total_target &gt; 0 else 0.0

            # 3) Compute A &amp; P via your existing helper
            op_data = {
                &#34;produced_parts&#34;:            op_totals[&#34;total_parts&#34;],
                &#34;target&#34;:                    total_target,
                &#34;planned_downtime_minutes&#34;:  planned,
                &#34;unplanned_downtime_minutes&#34;:unplanned,
            }
            op_oee = compute_machine_oee(op_data, potential)

            # 4) Compute P×A
            op_pa = op_oee.get(&#34;P&#34;, 0.0) * op_oee.get(&#34;A&#34;, 0.0)

            # 5) Assemble final metrics dict
            op_metrics = {
                &#34;line&#34;:                 line_name,
                &#34;op&#34;:                   operation[&#34;op&#34;],
                &#34;ppt&#34;:                  ppt,
                &#34;runtime&#34;:              runtime,
                &#34;standard_cycle_time&#34;:  sct,
                **op_oee,   # adds &#34;A&#34; and &#34;P&#34;
                &#34;PA&#34;:                   op_pa,
                **op_totals,
            }

            # 6) Downtime percentage (aggregate)
            if potential &gt; 0:
                op_metrics[&#34;downtime_percentage&#34;] = (op_totals[&#34;total_downtime&#34;] / potential) * 100
            else:
                op_metrics[&#34;downtime_percentage&#34;] = 0

            # 7) Attach and collect
            operation[&#34;totals&#34;] = op_metrics
            operation_oee_metrics.append(op_metrics)





    # --- After you&#39;ve built operation_oee_metrics but before you build response_data ---

    from collections import defaultdict

    # 1) Group all ops by line
    ops_by_line = defaultdict(list)
    for op in operation_oee_metrics:
        ops_by_line[op[&#34;line&#34;]].append(op)

    # 2) For each line, build a dict of op → metrics and apply gradients
    for line_name, ops in ops_by_line.items():
        # map operation name to its metrics dict
        op_map = { op[&#34;op&#34;]: op for op in ops }

        # apply your color helper to each metric
        apply_color_gradient_to_line_reversed(op_map, &#34;downtime_percentage&#34;, &#34;downtime_percentage_color&#34;)
        apply_color_gradient_to_line(op_map, &#34;P&#34;,                      &#34;P_color&#34;)
        apply_color_gradient_to_line(op_map, &#34;A&#34;,                      &#34;A_color&#34;)
        apply_color_gradient_to_line(op_map, &#34;PA&#34;,                     &#34;PA_color&#34;)



    # Build the response payload.
    response_data = {
        &#34;production_data&#34;: production_data,
        &#34;totals_by_line&#34;: totals_by_line,
        &#34;overall_totals&#34;: {
            &#34;total_produced&#34;: overall_total_produced,
            &#34;total_target&#34;: overall_total_target,
        },
        &#34;downtime_totals_by_line&#34;: downtime_totals_by_line,
        &#34;overall_downtime&#34;: {
            &#34;downtime_minutes&#34;: overall_downtime_minutes,
            &#34;planned_downtime_minutes&#34;: overall_planned_downtime_minutes,
            &#34;unplanned_downtime_minutes&#34;: overall_unplanned_downtime_minutes,
        },
        &#34;potential_minutes_by_line&#34;: potential_minutes_by_line,
        &#34;overall_potential_minutes&#34;: overall_total_potential_minutes,
        &#34;scrap_totals_by_line&#34;: scrap_totals_by_line,
        &#34;overall_scrap_total&#34;: overall_scrap_total,
        &#34;previous_day&#34;: previous_day_str,
        &#34;planned_downtime_totals_by_line&#34;: planned_downtime_totals_by_line,
        &#34;unplanned_downtime_totals_by_line&#34;: unplanned_downtime_totals_by_line,
        &#34;oee_metrics&#34;: oee_metrics,
        &#34;operation_oee_metrics&#34;: operation_oee_metrics,
    }
    cursor.close()
    conn.close()
    return JsonResponse(response_data)</code></pre>
</details>
<div class="desc"><p>A unified view that always excludes weekends from the production data.
Processes production and downtime information at the machine level, aggregates totals per line,
and then computes operation-level OEE metrics for display.</p></div>
</dd>
<dt id="prod_query.views.fetch_cycle_data"><code class="name flex">
<span>def <span class="ident">fetch_cycle_data</span></span>(<span>machine, start_ts, end_ts, include_zeros, part_number)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_cycle_data(machine, start_ts, end_ts, include_zeros, part_number):
    &#34;&#34;&#34;
    Fetch cycle records for a machine between two timestamps and build a sorted
    list of (adjusted_cycle_time, frequency) tuples. The adjustment divides the raw
    cycle time (difference between groups of records) by the mode of the observed
    batch sizes (i.e. how many rows have the same timestamp), thereby converting the
    cycle time to a per-part value.

    Args:
        machine (str): Machine identifier.
        start_ts (int): Start timestamp.
        end_ts (int): End timestamp.
        include_zeros (bool): Whether to include cycles of 0 seconds.

    Returns:
        List[Tuple[int, int]]: Sorted list of (adjusted_cycle_time, frequency) tuples.
    &#34;&#34;&#34;
    # Build SQL query
    if part_number:
        sql = (
            f&#34;SELECT * &#34;
            f&#34;FROM GFxPRoduction &#34;
            f&#34;WHERE Machine = &#39;{machine}&#39; &#34;
            f&#34;AND Part = &#39;{part_number}&#39; &#34;
            f&#34;AND TimeStamp BETWEEN {start_ts} AND {end_ts} &#34;
            f&#34;ORDER BY TimeStamp&#34;
    )
    else:
        sql = (
            f&#34;SELECT * &#34;
            f&#34;FROM GFxPRoduction &#34;
            f&#34;WHERE Machine = &#39;{machine}&#39; &#34;
            f&#34;AND TimeStamp BETWEEN {start_ts} AND {end_ts} &#34;
            f&#34;ORDER BY TimeStamp&#34;
        )

    # Execute the query
    cursor = connections[&#39;prodrpt-md&#39;].cursor()
    cursor.execute(sql)
    rows = cursor.fetchall()
    cursor.close()

    # Group rows by timestamp and record the batch size for each group.
    # Each group is a tuple: (timestamp, count)
    groups = []
    if rows:
        current_group_ts = rows[0][4]  # Assuming TimeStamp is at index 4
        current_group_count = 1
        for row in rows[1:]:
            ts = row[4]
            if ts == current_group_ts:
                current_group_count += 1
            else:
                groups.append((current_group_ts, current_group_count))
                # Reset for the new group.
                current_group_ts = ts
                current_group_count = 1
        # Append the final group.
        groups.append((current_group_ts, current_group_count))

    # Build a list of all batch sizes from the groups.
    batch_sizes = [count for (_, count) in groups]
    # Determine the mode (most common value) of the batch sizes.
    # This represents the typical number of parts produced per cycle.
    mode_value = Counter(batch_sizes).most_common(1)[0][0] if batch_sizes else 1

    # Compute raw cycle times from consecutive unique groups and adjust by dividing
    # by the mode_value. This gives the cycle time per part.
    times_dict = {}
    for i in range(1, len(groups)):
        # Raw cycle time is the difference between consecutive unique timestamps.
        raw_cycle = groups[i][0] - groups[i - 1][0]
        # Adjust the cycle time by the typical number of parts.
        adjusted_cycle = round(raw_cycle / mode_value)
        if include_zeros:
            if adjusted_cycle &gt;= 0:
                times_dict[adjusted_cycle] = times_dict.get(adjusted_cycle, 0) + 1
        else:
            if adjusted_cycle &gt; 0:
                times_dict[adjusted_cycle] = times_dict.get(adjusted_cycle, 0) + 1

    # Return the sorted list of (adjusted_cycle_time, frequency) tuples.
    return sorted(times_dict.items(), key=lambda x: x[0])</code></pre>
</details>
<div class="desc"><p>Fetch cycle records for a machine between two timestamps and build a sorted
list of (adjusted_cycle_time, frequency) tuples. The adjustment divides the raw
cycle time (difference between groups of records) by the mode of the observed
batch sizes (i.e. how many rows have the same timestamp), thereby converting the
cycle time to a per-part value.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>Machine identifier.</dd>
<dt><strong><code>start_ts</code></strong> :&ensp;<code>int</code></dt>
<dd>Start timestamp.</dd>
<dt><strong><code>end_ts</code></strong> :&ensp;<code>int</code></dt>
<dd>End timestamp.</dd>
<dt><strong><code>include_zeros</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to include cycles of 0 seconds.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Tuple[int, int]]</code></dt>
<dd>Sorted list of (adjusted_cycle_time, frequency) tuples.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.fetch_daily_scrap_data"><code class="name flex">
<span>def <span class="ident">fetch_daily_scrap_data</span></span>(<span>cursor, start_time, end_time)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_daily_scrap_data(cursor, start_time, end_time):
    &#34;&#34;&#34;
    Fetches scrap totals from the tkb_scrap table for the given time window.
    Aggregates scrap_amount by production line using line_scrap_mapping.
    
    Assumes that the `date_current` column is stored as a datetime.
    &#34;&#34;&#34;
    start_time_str = start_time.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)
    end_time_str = end_time.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)
    
    query = &#34;&#34;&#34;
        SELECT scrap_line, SUM(scrap_amount)
        FROM tkb_scrap
        WHERE date_current BETWEEN %s AND %s
        GROUP BY scrap_line;
    &#34;&#34;&#34;
    cursor.execute(query, [start_time_str, end_time_str])
    rows = cursor.fetchall()

    # Initialize totals for each production line defined in our mapping.
    scrap_totals_by_line = {line: 0 for line in line_scrap_mapping.keys()}
    for scrap_line, total in rows:
        for prod_line, valid_values in line_scrap_mapping.items():
            if scrap_line in valid_values:
                scrap_totals_by_line[prod_line] += total

    overall_scrap_total = sum(scrap_totals_by_line.values())
    return scrap_totals_by_line, overall_scrap_total</code></pre>
</details>
<div class="desc"><p>Fetches scrap totals from the tkb_scrap table for the given time window.
Aggregates scrap_amount by production line using line_scrap_mapping.</p>
<p>Assumes that the <code>date_current</code> column is stored as a datetime.</p></div>
</dd>
<dt id="prod_query.views.fetch_downtime_by_date_ranges"><code class="name flex">
<span>def <span class="ident">fetch_downtime_by_date_ranges</span></span>(<span>machine, date_ranges, downtime_threshold=5, machine_parts=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_downtime_by_date_ranges(machine, date_ranges, downtime_threshold=5, machine_parts=None):
    &#34;&#34;&#34;
    Retrieve downtime metrics for a machine over specified time windows.

    Iterates over each (start, end) datetime pair in `date_ranges`, converts them
    to epoch timestamps, and calls `calculate_downtime` to compute total downtime
    (in minutes) exceeding the given threshold. Also computes the total potential
    operating minutes for each interval.

    Parameters
    ----------
    machine : str
        Identifier of the machine to analyze.
    date_ranges : list of tuple(datetime.datetime, datetime.datetime)
        List of (start, end) intervals over which to fetch downtime data.
    downtime_threshold : int, optional
        Minimum contiguous minutes of inactivity to count as downtime.
        Defaults to 5 minutes.
    machine_parts : Any, optional
        Additional machine-part configuration to pass through to
        `calculate_downtime`. Defaults to None.

    Returns
    -------
    list of dict
        A list of results, one per interval, each containing:
          - &#39;start&#39; (datetime.datetime): interval start
          - &#39;end&#39; (datetime.datetime): interval end
          - &#39;downtime&#39; (float): total downtime in minutes
          - &#39;potential_minutes&#39; (int): total possible operating minutes in the interval

    Raises
    ------
    RuntimeError
        If any database or calculation error occurs during processing. The
        original exception message will be included.
    &#34;&#34;&#34;
    downtime_results = []
    try:
        with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
            for start, end in date_ranges:
                start_timestamp = int(start.timestamp())
                end_timestamp = int(end.timestamp())
                downtime = calculate_downtime(
                    machine=machine,
                    cursor=cursor,
                    start_timestamp=start_timestamp,
                    end_timestamp=end_timestamp,
                    downtime_threshold=downtime_threshold,
                    machine_parts=machine_parts
                )
                potential_minutes = calculate_potential_minutes(start, end)
                downtime_results.append({
                    &#39;start&#39;: start,
                    &#39;end&#39;: end,
                    &#39;downtime&#39;: downtime,
                    &#39;potential_minutes&#39;: potential_minutes
                })
        return downtime_results
    except Exception as e:
        print(f&#34;Error in fetch_downtime_by_date_ranges: {e}&#34;)  # Log the error to the console
        raise RuntimeError(f&#34;Error fetching downtime data: {str(e)}&#34;)  # Re-raise the exception</code></pre>
</details>
<div class="desc"><p>Retrieve downtime metrics for a machine over specified time windows.</p>
<p>Iterates over each (start, end) datetime pair in <code>date_ranges</code>, converts them
to epoch timestamps, and calls <code>calculate_downtime</code> to compute total downtime
(in minutes) exceeding the given threshold. Also computes the total potential
operating minutes for each interval.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>Identifier of the machine to analyze.</dd>
<dt><strong><code>date_ranges</code></strong> :&ensp;<code>list</code> of <code>tuple(datetime.datetime, datetime.datetime)</code></dt>
<dd>List of (start, end) intervals over which to fetch downtime data.</dd>
<dt><strong><code>downtime_threshold</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Minimum contiguous minutes of inactivity to count as downtime.
Defaults to 5 minutes.</dd>
<dt><strong><code>machine_parts</code></strong> :&ensp;<code>Any</code>, optional</dt>
<dd>Additional machine-part configuration to pass through to
<code>calculate_downtime</code>. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>dict</code></dt>
<dd>A list of results, one per interval, each containing:
- 'start' (datetime.datetime): interval start
- 'end' (datetime.datetime): interval end
- 'downtime' (float): total downtime in minutes
- 'potential_minutes' (int): total possible operating minutes in the interval</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If any database or calculation error occurs during processing. The
original exception message will be included.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.fetch_downtime_results"><code class="name flex">
<span>def <span class="ident">fetch_downtime_results</span></span>(<span>machine, start_timestamp, end_timestamp, downtime_threshold)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_downtime_results(machine, start_timestamp, end_timestamp, downtime_threshold):
    &#34;&#34;&#34;
    Calculate downtime and threshold breach count for the given parameters.
    The threshold is in seconds, while results return downtime in minutes.
    &#34;&#34;&#34;
    try:
        with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
            return calculate_downtime_and_threshold_count(
                machine=machine,
                cursor=cursor,
                start_timestamp=start_timestamp,
                end_timestamp=end_timestamp,
                downtime_threshold=downtime_threshold
            )
    except Exception as e:
        print(f&#34;[ERROR] Failed to calculate downtime: {e}&#34;)
        return &#34;Error: Could not retrieve downtime data.&#34;, &#34;Error&#34;</code></pre>
</details>
<div class="desc"><p>Calculate downtime and threshold breach count for the given parameters.
The threshold is in seconds, while results return downtime in minutes.</p></div>
</dd>
<dt id="prod_query.views.fetch_line_metrics"><code class="name flex">
<span>def <span class="ident">fetch_line_metrics</span></span>(<span>line_name, time_blocks, lines)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_line_metrics(line_name, time_blocks, lines):
    &#34;&#34;&#34;
    Fetch metrics for a line and time blocks, including total produced, target, adjusted target,
    potential minutes, downtime, percentage downtime, P value, and A value.
    &#34;&#34;&#34;
    aggregated_metrics = {
        &#39;total_produced&#39;: 0,
        &#39;total_target&#39;: 0,
        &#39;total_adjusted_target&#39;: 0,
        &#39;total_potential_minutes&#39;: 0,
        &#39;total_downtime&#39;: 0,
        &#39;details&#39;: []  # Detailed breakdown per block and machine
    }

    try:
        # Find the line data
        line_data = next((line for line in lines if line[&#39;line&#39;] == line_name), None)
        if not line_data:
            print(f&#34;[ERROR] Line not found: {line_name}&#34;)
            raise ValueError(f&#34;Invalid line selected: {line_name}&#34;)

        with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
            # Iterate over time blocks
            for block_start, block_end in time_blocks:
                # print(f&#34;[INFO] Processing time block: {block_start} to {block_end}&#34;)
                block_metrics = {
                    &#39;block_start&#39;: block_start,
                    &#39;block_end&#39;: block_end,
                    &#39;machines&#39;: []
                }

                # Iterate over operations in the line
                for operation in line_data[&#39;operations&#39;]:
                    for machine in operation[&#39;machines&#39;]:
                        machine_id = machine[&#39;number&#39;]
                        machine_parts = get_machine_part_numbers(machine_id, line_name, lines)

                        try:
                            # Fetch downtime data
                            downtime_data = fetch_downtime_by_date_ranges(
                                machine=machine_id,
                                date_ranges=[(block_start, block_end)],
                                machine_parts=machine_parts
                            )
                            if not downtime_data or &#39;downtime&#39; not in downtime_data[0]:
                                print(f&#34;[WARNING] Missing downtime data for machine {machine_id}&#34;)
                            downtime_entry = downtime_data[0] if downtime_data else {}
                            downtime = downtime_entry.get(&#39;downtime&#39;, 0)
                            potential_minutes = downtime_entry.get(&#39;potential_minutes&#39;, 0)

                            # Calculate percentage downtime
                            percentage_downtime = calculate_percentage_downtime(
                                downtime=downtime,
                                potential_minutes=potential_minutes
                            )

                            # Fetch production data
                            produced = fetch_production_by_date_ranges(
                                machine=machine_id,
                                machine_parts=machine_parts,
                                date_ranges=[(block_start, block_end)]
                            )

                            # Fetch target data
                            target = get_machine_target(
                                machine_id=machine_id,
                                selected_date_unix=int(block_start.timestamp()),
                                line_name=line_name
                            )

                            # Highlight potential issues in fetched data
                            if produced is None or target is None:
                                print(f&#34;[WARNING] Produced or target is None for machine {machine_id}&#34;)

                            # Calculate metrics
                            adjusted_target = calculate_adjusted_target(
                                target=target if target else 0,
                                percentage_downtime=percentage_downtime
                            )
                            p_value = calculate_p(
                                total_produced=produced or 0,
                                total_adjusted_target=adjusted_target,
                                downtime_percentage=percentage_downtime
                            )
                            a_value = calculate_A(
                                total_potential_minutes=potential_minutes or 0,
                                downtime_minutes=downtime or 0
                            )

                            # Update aggregated metrics
                            aggregated_metrics[&#39;total_produced&#39;] += produced or 0
                            aggregated_metrics[&#39;total_target&#39;] += target or 0
                            aggregated_metrics[&#39;total_adjusted_target&#39;] += adjusted_target or 0
                            aggregated_metrics[&#39;total_potential_minutes&#39;] += potential_minutes or 0
                            aggregated_metrics[&#39;total_downtime&#39;] += downtime or 0

                            # Add machine metrics
                            machine_metrics = {
                                &#39;machine_id&#39;: machine_id,
                                &#39;produced&#39;: produced,
                                &#39;target&#39;: target,
                                &#39;adjusted_target&#39;: adjusted_target,
                                &#39;total_downtime&#39;: downtime,
                                &#39;total_potential_minutes&#39;: potential_minutes,
                                &#39;percentage_downtime&#39;: percentage_downtime,
                                &#39;p_value&#39;: f&#34;{p_value}%&#34;,
                                &#39;a_value&#39;: a_value
                            }
                            block_metrics[&#39;machines&#39;].append(machine_metrics)

                        except Exception as machine_error:
                            print(f&#34;[ERROR] Error processing machine {machine_id}: {machine_error}&#34;)

                aggregated_metrics[&#39;details&#39;].append(block_metrics)

        return aggregated_metrics

    except Exception as e:
        print(f&#34;[ERROR] Error in fetch_line_metrics: {e}&#34;)
        raise RuntimeError(f&#34;Error fetching line metrics: {str(e)}&#34;)</code></pre>
</details>
<div class="desc"><p>Fetch metrics for a line and time blocks, including total produced, target, adjusted target,
potential minutes, downtime, percentage downtime, P value, and A value.</p></div>
</dd>
<dt id="prod_query.views.fetch_machine_target"><code class="name flex">
<span>def <span class="ident">fetch_machine_target</span></span>(<span>cursor, machine_id, line_name, start_ts, end_ts)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_machine_target(cursor, machine_id, line_name, start_ts, end_ts):
    &#34;&#34;&#34;
    If the machine has *any* part_numbers, always uses the above
    fetch_part_timeline logic (even for a single part). Otherwise
    falls back to a pure machine-level target (with its own
    mid-window target–change weighting).
    &#34;&#34;&#34;
    # invalid window?
    if end_ts &lt;= start_ts:
        print(f&#34;ERROR: end_ts ({end_ts}) ≤ start_ts ({start_ts}) → returning 0&#34;)
        return 0

    # first, see if this machine has parts configured
    parts = get_parts_for_machine(lines, line_name, machine_id)
    if parts:
        return fetch_part_timeline(cursor, machine_id, line_name, start_ts, end_ts, parts)

    # no parts → fall back to machine-level targets
    TOTAL_SECONDS = 7200 * 60
    window_secs   = end_ts - start_ts

    recs = (
        OAMachineTargets.objects
        .filter(
            machine_id=machine_id,
            line=line_name,
            effective_date_unix__lte=end_ts,
            isDeleted=False
        )
        .order_by(&#39;effective_date_unix&#39;)
    )

    if not recs:
        print(
            f&#34;[DEBUG] fetch_machine_target: no stored machine-level target for &#34;
            f&#34;machine_id={machine_id!r}, line={line_name!r}, parts={parts!r} → returning 0&#34;
        )
        return 0   # ← was None before

    # build time‐breakpoints and weight each interval by rec.target
    times = [start_ts] + [
        r.effective_date_unix
        for r in recs
        if start_ts &lt; r.effective_date_unix &lt; end_ts
    ] + [end_ts]
    times = sorted(set(times))

    total_expected = 0.0
    for t0, t1 in zip(times, times[1:]):
        rec = next(
            (r for r in reversed(recs) if r.effective_date_unix &lt;= t0),
            None
        )
        if not rec:
            print(f&#34;[DEBUG] no machine-level target at ts={t0} → skipping&#34;)
            continue
        total_expected += (t1 - t0) * (rec.target / TOTAL_SECONDS)

    # normalize back to a 2-hour (7,200-min) window
    normalized = int(round(total_expected * (TOTAL_SECONDS / window_secs))) if window_secs else 0
    return normalized</code></pre>
</details>
<div class="desc"><p>If the machine has <em>any</em> part_numbers, always uses the above
fetch_part_timeline logic (even for a single part). Otherwise
falls back to a pure machine-level target (with its own
mid-window target–change weighting).</p></div>
</dd>
<dt id="prod_query.views.fetch_part_timeline"><code class="name flex">
<span>def <span class="ident">fetch_part_timeline</span></span>(<span>cursor, machine_id, line_name, start_ts, end_ts, parts)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_part_timeline(cursor, machine_id, line_name, start_ts, end_ts, parts):
    &#34;&#34;&#34;
    Build a time-weighted “expected count” across all parts over a given time window,
    with console output of part/target changes, per-slice contributions, and totals.
    &#34;&#34;&#34;
    # ---- STEP 0: Sanity checks ----
    if end_ts &lt;= start_ts:
        print(f&#34;ERROR: end_ts ({end_ts}) ≤ start_ts ({start_ts}) → returning 0&#34;)
        return 0
    if not parts:
        print(&#34;DEBUG: no parts defined → returning 0&#34;)
        return 0

    # Constants
    MINUTES_IN_REFERENCE = 7200
    SECONDS_PER_MINUTE   = 60
    TOTAL_SECONDS        = MINUTES_IN_REFERENCE * SECONDS_PER_MINUTE
    window_seconds       = end_ts - start_ts

    # ---- STEP 1: Pull part-change events ----
    ph = &#34;, &#34;.join([&#34;%s&#34;] * len(parts))
    sql_events = f&#34;&#34;&#34;
        SELECT TimeStamp, Part
        FROM GFxPRoduction
        WHERE Machine     = %s
          AND TimeStamp BETWEEN %s AND %s
          AND Part        IN ({ph})
        ORDER BY TimeStamp ASC
    &#34;&#34;&#34;
    cursor.execute(sql_events, [machine_id, start_ts, end_ts] + parts)
    raw_rows = list(cursor.fetchall())

    # ---- STEP 1a: Seed virtual event if needed ----
    if not raw_rows or raw_rows[0][0] &gt; start_ts:
        sql_prev = f&#34;&#34;&#34;
            SELECT TimeStamp, Part
            FROM GFxPRoduction
            WHERE Machine = %s
              AND TimeStamp &lt; %s
              AND Part IN ({ph})
            ORDER BY TimeStamp DESC
            LIMIT 1
        &#34;&#34;&#34;
        cursor.execute(sql_prev, [machine_id, start_ts] + parts)
        prev = cursor.fetchone()
        if prev:
            raw_rows.insert(0, (start_ts, prev[1]))

    if not raw_rows:
        print(&#34;DEBUG: still no rows → returning 0&#34;)
        return 0

    # ---- STEP 2: Load &amp; group all target-rate records ----
    all_target_recs = (
        OAMachineTargets.objects
        .filter(
            machine_id=machine_id,
            line=line_name,
            part__in=parts,
            effective_date_unix__lte=end_ts,
            isDeleted=False
        )
        .order_by(&#39;part&#39;, &#39;effective_date_unix&#39;)
    )
    targets_by_part = defaultdict(list)
    for rec in all_target_recs:
        targets_by_part[rec.part].append(rec)

    # ---- PRINT: intra-window target changes for same part ----
    for part, recs in targets_by_part.items():
        in_window = [r for r in recs if start_ts &lt; r.effective_date_unix &lt; end_ts]
        # for old, new in zip(in_window, in_window[1:]):
        #     # print(
        #     #     f&#34;Part {part} target changed &#34;
        #     #     f&#34;from {old.target} to {new.target} at {new.effective_date_unix}&#34;
        #     # )

    # ---- PRINT: part-change events with old/new targets ----
    for (ts, part), (next_ts, next_part) in zip(raw_rows, raw_rows[1:]):
        if part != next_part:
            old_recs = [r for r in targets_by_part.get(part, []) if r.effective_date_unix &lt;= next_ts]
            new_recs = [r for r in targets_by_part.get(next_part, []) if r.effective_date_unix &lt;= next_ts]
            old_target = max(old_recs, key=lambda r: r.effective_date_unix).target if old_recs else &#39;N/A&#39;
            new_target = max(new_recs, key=lambda r: r.effective_date_unix).target if new_recs else &#39;N/A&#39;
            # print(
            #     f&#34;Machine changed part from {part} (target {old_target}) &#34;
            #     f&#34;to {next_part} (target {new_target}) at {next_ts}&#34;
            # )

    # ---- STEP 3: Collapse raw events into contiguous segments ----
    part_segments = []
    curr_part, seg_start = raw_rows[0][1], raw_rows[0][0]
    for ts, part in raw_rows[1:]:
        if part != curr_part:
            part_segments.append({&#34;part&#34;: curr_part, &#34;start&#34;: seg_start, &#34;end&#34;: ts})
            curr_part, seg_start = part, ts
    part_segments.append({&#34;part&#34;: curr_part, &#34;start&#34;: seg_start, &#34;end&#34;: end_ts})

    # ---- STEP 4: Accumulate time-weighted expected count ----
    total_expected = 0.0

    for seg in part_segments:
        part      = seg[&#34;part&#34;]
        seg_start = max(seg[&#34;start&#34;], start_ts)
        seg_end   = min(seg[&#34;end&#34;],   end_ts)
        if seg_end &lt;= seg_start:
            continue

        part_recs = targets_by_part.get(part, [])
        if not part_recs:
            continue

        # find record index effective at seg_start
        idx0 = None
        for i, r in enumerate(part_recs):
            if r.effective_date_unix &lt;= seg_start:
                idx0 = i
            else:
                break
        if idx0 is None:
            continue

        # build breakpoints for rate changes
        breakpoints = [seg_start]
        for r in part_recs[idx0+1:]:
            if seg_start &lt; r.effective_date_unix &lt; seg_end:
                breakpoints.append(r.effective_date_unix)
        breakpoints.append(seg_end)
        breakpoints.sort()

        # sum contributions, printing each slice
        for i in range(len(breakpoints) - 1):
            t0, t1 = breakpoints[i], breakpoints[i+1]
            duration_secs = t1 - t0
            duration_min  = duration_secs / SECONDS_PER_MINUTE

            # get active record at t0
            active = next((r for r in reversed(part_recs) if r.effective_date_unix &lt;= t0), None)
            if not active:
                continue

            contribution = duration_secs * (active.target / TOTAL_SECONDS)
            total_expected += contribution

            # **Print the slice’s details and running total**
            # print(
            #     f&#34;  + Part {part}: {duration_min:.2f} min at rate {active.target} &#34;
            #     f&#34;→ slice contrib {contribution:.2f}, running raw total {total_expected:.2f}&#34;
            # )

    # ---- STEP 5: Show raw window total then normalize ----
    queried_minutes = window_seconds / SECONDS_PER_MINUTE
    # print(f&#34;This window of {queried_minutes:.2f} minutes gives us a raw expected count of: {total_expected:.2f}&#34;)

    if queried_minutes &gt; 0:
        factor     = MINUTES_IN_REFERENCE / queried_minutes
        normalized = int(round(total_expected * factor))
    else:
        normalized = 0

    # print(f&#34;FINAL normalized target for 7200-min window: {normalized}&#34;)
    return normalized</code></pre>
</details>
<div class="desc"><p>Build a time-weighted “expected count” across all parts over a given time window,
with console output of part/target changes, per-slice contributions, and totals.</p></div>
</dd>
<dt id="prod_query.views.fetch_prdowntime1_entries_with_id"><code class="name flex">
<span>def <span class="ident">fetch_prdowntime1_entries_with_id</span></span>(<span>assetnum, called4helptime, completedtime)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_prdowntime1_entries_with_id(assetnum, called4helptime, completedtime):
    &#34;&#34;&#34;
    A copy of `fetch_prdowntime1_entries` that also fetches the `idnumber` column.
    
    :param assetnum: The asset number of the machine.
    :param called4helptime: The start of the time window (ISO 8601 format).
    :param completedtime: The end of the time window (ISO 8601 format).
    :return: List of rows matching the criteria, each row shaped like:
             [idnumber, problem, called4helptime, completedtime].
    &#34;&#34;&#34;
    import re
    import datetime, os, importlib
    from datetime import datetime

    try:
        # Strip trailing letters from assetnum (e.g., &#34;1703R&#34; or &#34;1703L&#34; becomes &#34;1703&#34;)
        assetnum = re.sub(r&#39;[A-Za-z]+$&#39;, &#39;&#39;, assetnum)

        # Parse the dates to ensure they are in datetime format.
        called4helptime = datetime.fromisoformat(called4helptime)
        completedtime = datetime.fromisoformat(completedtime)

        # Dynamically import `get_db_connection` from settings.py.
        settings_path = os.path.join(os.path.dirname(__file__), &#39;../pms/settings.py&#39;)
        spec = importlib.util.spec_from_file_location(&#34;settings&#34;, settings_path)
        settings = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(settings)
        get_db_connection = settings.get_db_connection

        # Get database connection.
        conn = get_db_connection()
        cursor = conn.cursor()

        # Raw SQL query to fetch the required data, now including `idnumber`.
        query = &#34;&#34;&#34;
        SELECT
            idnumber,
            problem,
            called4helptime,
            completedtime
        FROM pr_downtime1
        WHERE assetnum = %s
          AND (
            -- Entries that start before the window and bleed into the window.
            (called4helptime &lt; %s AND (completedtime &gt;= %s OR completedtime IS NULL))
            -- Entries that start within the window.
            OR (called4helptime &gt;= %s AND called4helptime &lt;= %s)
            -- Entries that start in the window and bleed out.
            OR (called4helptime &gt;= %s AND called4helptime &lt;= %s AND (completedtime &gt; %s OR completedtime IS NULL))
            -- Entries that bleed both before and after the window.
            OR (called4helptime &lt; %s AND (completedtime &gt; %s OR completedtime IS NULL))
          )
        &#34;&#34;&#34;

        # Execute the query.
        cursor.execute(query, (
            assetnum,
            called4helptime, called4helptime,
            called4helptime, completedtime,
            called4helptime, completedtime, completedtime,
            called4helptime, completedtime
        ))

        # Fetch all rows.
        rows = cursor.fetchall()

        # Close the cursor and connection.
        cursor.close()
        conn.close()

        return rows

    except Exception as e:
        return {&#34;error&#34;: str(e)}</code></pre>
</details>
<div class="desc"><p>A copy of <code>fetch_prdowntime1_entries</code> that also fetches the <code>idnumber</code> column.</p>
<p>:param assetnum: The asset number of the machine.
:param called4helptime: The start of the time window (ISO 8601 format).
:param completedtime: The end of the time window (ISO 8601 format).
:return: List of rows matching the criteria, each row shaped like:
[idnumber, problem, called4helptime, completedtime].</p></div>
</dd>
<dt id="prod_query.views.fetch_press_changeovers"><code class="name flex">
<span>def <span class="ident">fetch_press_changeovers</span></span>(<span>machine_id, start_timestamp, end_timestamp)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_press_changeovers(machine_id, start_timestamp, end_timestamp):
    &#34;&#34;&#34;
    Fetch entries from the &#39;Press_Changeovers&#39; table for the given asset (machine_id)
    where called4helptime is between start_timestamp and end_timestamp.

    If no entries are found, the time window is doubled up to 5 times or until 
    the search window reaches a maximum of 1 year.

    Returns:
        A list of tuples:
          (asset, part_no, ideal_cycle_time, called4helptime, completedtime, downtime, code)
        where part_no is the last 9 characters of the problem field and ideal_cycle_time 
        is retrieved from AssetCycleTimes if available.
    &#34;&#34;&#34;
    MAX_DAYS = 365  # Maximum search window in days
    SECONDS_IN_A_DAY = 86400  # Seconds per day
    MAX_EXPANSIONS = 5  # Stop after 5 expansions

    press_changeover_records = []  # This will hold our results

    try:
        connection = mysql.connector.connect(
            host=settings.DAVE_HOST,
            user=settings.DAVE_USER,
            password=settings.DAVE_PASSWORD,
            database=settings.DAVE_DB
        )
        cursor = connection.cursor()

        original_window = end_timestamp - start_timestamp
        max_window = MAX_DAYS * SECONDS_IN_A_DAY
        current_window = original_window
        expansion_count = 0  # Track how many times we expand the window

        # Keep expanding the window until we get at least one record, capped at 5 expansions or 1 year
        while current_window &lt;= max_window and expansion_count &lt; MAX_EXPANSIONS:
            query = &#34;&#34;&#34;
                SELECT asset, problem, called4helptime, completedtime, Downtime, Code
                FROM Press_Changeovers
                WHERE asset = %s
                AND UNIX_TIMESTAMP(called4helptime) BETWEEN %s AND %s
                ORDER BY called4helptime ASC
            &#34;&#34;&#34;
            cursor.execute(query, (machine_id, start_timestamp, end_timestamp))
            records = cursor.fetchall()

            if records:
                for rec in records:
                    asset = rec[0]
                    problem_full = rec[1] if rec[1] is not None else &#34;&#34;
                    part_no = problem_full[-9:] if len(problem_full) &gt;= 9 else problem_full

                    # Query the AssetCycleTimes for the given part number.
                    cycle_record = AssetCycleTimes.objects.filter(
                        part__part_number=part_no
                    ).order_by(&#34;-effective_date&#34;).first()
                    
                    # Use the cycle_time if a record exists, else set a default value.
                    ideal_cycle_time = cycle_record.cycle_time if cycle_record else &#34;N/A&#34;

                    called4helptime = rec[2]
                    completedtime = rec[3] if rec[3] else &#34;na&#34;
                    downtime = rec[4]
                    code = rec[5]

                    # Append the new tuple with the ideal_cycle_time inserted
                    press_changeover_records.append(
                        (asset, part_no, ideal_cycle_time, called4helptime, completedtime, downtime, code)
                    )

                break  # Exit the loop when records are found

            # If no records, double the window (expand search window backward)
            new_window = min(current_window * 2, max_window)
            extension = new_window - current_window
            start_timestamp -= extension
            current_window = new_window
            expansion_count += 1  # Increment expansion counter

            # print(f&#34;[DEBUG] Expansion {expansion_count}: New range: {start_timestamp} - {end_timestamp}&#34;)

        # if expansion_count &gt;= MAX_EXPANSIONS:
        #     print(f&#34;[DEBUG] No records found after {MAX_EXPANSIONS} expansions, stopping search.&#34;)

        return press_changeover_records

    except Exception as e:
        print(f&#34;[ERROR] Error fetching press changeovers: {e}&#34;)
        return []
    finally:
        if &#39;connection&#39; in locals():
            connection.close()</code></pre>
</details>
<div class="desc"><p>Fetch entries from the 'Press_Changeovers' table for the given asset (machine_id)
where called4helptime is between start_timestamp and end_timestamp.</p>
<p>If no entries are found, the time window is doubled up to 5 times or until
the search window reaches a maximum of 1 year.</p>
<h2 id="returns">Returns</h2>
<p>A list of tuples:
(asset, part_no, ideal_cycle_time, called4helptime, completedtime, downtime, code)
where part_no is the last 9 characters of the problem field and ideal_cycle_time
is retrieved from AssetCycleTimes if available.</p></div>
</dd>
<dt id="prod_query.views.fetch_press_prdowntime1_entries"><code class="name flex">
<span>def <span class="ident">fetch_press_prdowntime1_entries</span></span>(<span>assetnum, called4helptime, completedtime)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_press_prdowntime1_entries(assetnum, called4helptime, completedtime):
    &#34;&#34;&#34;
    Fetches downtime entries based on the given parameters using raw SQL.

    :param assetnum: The asset number of the machine.
    :param called4helptime: The start of the time window (ISO 8601 format).
    :param completedtime: The end of the time window (ISO 8601 format).
    :return: List of rows matching the criteria.
    &#34;&#34;&#34;
    try:
        # Parse the dates to ensure they are in datetime format
        called4helptime = datetime.fromisoformat(called4helptime)
        completedtime = datetime.fromisoformat(completedtime)

        # Dynamically import `get_db_connection` from settings.py
        settings_path = os.path.join(
            os.path.dirname(__file__), &#39;../pms/settings.py&#39;
        )
        spec = importlib.util.spec_from_file_location(&#34;settings&#34;, settings_path)
        settings = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(settings)
        get_db_connection = settings.get_db_connection

        # Get database connection
        conn = get_db_connection()
        cursor = conn.cursor()

        # Raw SQL query to fetch the required data
        query = &#34;&#34;&#34;
        SELECT problem, called4helptime, completedtime, idnumber
        FROM pr_downtime1
        WHERE assetnum = %s
        AND down = &#39;Yes_Down&#39;
        AND (
            -- Entries that start before the window and bleed into the window
            (called4helptime &lt; %s AND (completedtime &gt;= %s OR completedtime IS NULL))
            -- Entries that start within the window
            OR (called4helptime &gt;= %s AND called4helptime &lt;= %s)
            -- Entries that start in the window and bleed out
            OR (called4helptime &gt;= %s AND called4helptime &lt;= %s AND (completedtime &gt; %s OR completedtime IS NULL))
            -- Entries that bleed both before and after the window
            OR (called4helptime &lt; %s AND (completedtime &gt; %s OR completedtime IS NULL))
        )
        &#34;&#34;&#34;

        # Execute the query
        cursor.execute(query, (
            assetnum,
            called4helptime, called4helptime,
            called4helptime, completedtime,
            called4helptime, completedtime, completedtime,
            called4helptime, completedtime
        ))

        # Fetch all rows
        rows = cursor.fetchall()

        # Close the cursor and connection
        cursor.close()
        conn.close()

        return rows

    except Exception as e:
        return {&#34;error&#34;: str(e)}</code></pre>
</details>
<div class="desc"><p>Fetches downtime entries based on the given parameters using raw SQL.</p>
<p>:param assetnum: The asset number of the machine.
:param called4helptime: The start of the time window (ISO 8601 format).
:param completedtime: The end of the time window (ISO 8601 format).
:return: List of rows matching the criteria.</p></div>
</dd>
<dt id="prod_query.views.fetch_production_by_date_ranges"><code class="name flex">
<span>def <span class="ident">fetch_production_by_date_ranges</span></span>(<span>machine, machine_parts, date_ranges)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_production_by_date_ranges(machine, machine_parts, date_ranges):
    &#34;&#34;&#34;
    Sum total production for a machine over specified time intervals.

    Iterates through each (start, end) tuple in `date_ranges`, converts them
    to epoch timestamps, and accumulates the production counts returned by
    `calculate_total_produced`.

    Parameters
    ----------
    machine : str
        The identifier of the machine whose production is measured.
    machine_parts : Any
        Configuration or filter details for specific machine parts, passed to
        `calculate_total_produced`.
    date_ranges : list of tuple(datetime.datetime, datetime.datetime)
        A sequence of (start, end) intervals defining the periods to query.

    Returns
    -------
    int or float
        The aggregated production count across all provided intervals.

    Raises
    ------
    RuntimeError
        If a database error or calculation failure occurs, with the original
        exception message included.
    &#34;&#34;&#34;
    total_production = 0
    try:
        with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
            for start, end in date_ranges:
                start_timestamp = int(start.timestamp())
                end_timestamp = int(end.timestamp())
                total_production += calculate_total_produced(
                    machine=machine,
                    machine_parts=machine_parts,
                    start_timestamp=start_timestamp,
                    end_timestamp=end_timestamp,
                    cursor=cursor
                )
        return total_production
    except Exception as e:
        print(f&#34;Error in fetch_production_by_date_ranges: {e}&#34;)  # Log the error to the console
        raise RuntimeError(f&#34;Error fetching production data: {str(e)}&#34;)  # Re-raise the exception</code></pre>
</details>
<div class="desc"><p>Sum total production for a machine over specified time intervals.</p>
<p>Iterates through each (start, end) tuple in <code>date_ranges</code>, converts them
to epoch timestamps, and accumulates the production counts returned by
<code>calculate_total_produced</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>The identifier of the machine whose production is measured.</dd>
<dt><strong><code>machine_parts</code></strong> :&ensp;<code>Any</code></dt>
<dd>Configuration or filter details for specific machine parts, passed to
<code>calculate_total_produced</code>.</dd>
<dt><strong><code>date_ranges</code></strong> :&ensp;<code>list</code> of <code>tuple(datetime.datetime, datetime.datetime)</code></dt>
<dd>A sequence of (start, end) intervals defining the periods to query.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code> or <code>float</code></dt>
<dd>The aggregated production count across all provided intervals.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If a database error or calculation failure occurs, with the original
exception message included.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.fetch_production_count"><code class="name flex">
<span>def <span class="ident">fetch_production_count</span></span>(<span>machine, cursor, start_timestamp, end_timestamp)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_production_count(machine, cursor, start_timestamp, end_timestamp):
    &#34;&#34;&#34;
    Returns the number of production entries for a given machine within the time window.
    
    Args:
        machine (str): The machine/asset number.
        cursor: Database cursor.
        start_timestamp (int): The starting timestamp (in seconds).
        end_timestamp (int): The ending timestamp (in seconds).
    
    Returns:
        int: The number of production entries.
    &#34;&#34;&#34;
    query = &#34;&#34;&#34;
        SELECT COUNT(*) 
        FROM GFxPRoduction
        WHERE Machine = %s AND TimeStamp BETWEEN %s AND %s;
    &#34;&#34;&#34;
    cursor.execute(query, (machine, start_timestamp, end_timestamp))
    result = cursor.fetchone()
    return result[0] if result else 0</code></pre>
</details>
<div class="desc"><p>Returns the number of production entries for a given machine within the time window.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>The machine/asset number.</dd>
<dt><strong><code>cursor</code></strong></dt>
<dd>Database cursor.</dd>
<dt><strong><code>start_timestamp</code></strong> :&ensp;<code>int</code></dt>
<dd>The starting timestamp (in seconds).</dd>
<dt><strong><code>end_timestamp</code></strong> :&ensp;<code>int</code></dt>
<dd>The ending timestamp (in seconds).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The number of production entries.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.fetch_shift_totals_by_day_and_shift"><code class="name flex">
<span>def <span class="ident">fetch_shift_totals_by_day_and_shift</span></span>(<span>machine_number, start_date, end_date)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_shift_totals_by_day_and_shift(machine_number, start_date, end_date):
    &#34;&#34;&#34;
    Fetch production totals by day and shift for a specific machine.
    
    Parameters:
    - machine_number: str, identifier of the machine
    - start_date: datetime, start of the period to fetch data for
    - end_date: datetime, end of the period to fetch data for
    
    Returns:
    - labels: list of dates
    - day_counts: list of counts for day shift
    - afternoon_counts: list of counts for afternoon shift
    - night_counts: list of counts for night shift
    - total_counts: list of total counts per day
    &#34;&#34;&#34;

    # Convert datetime objects to Unix timestamps
    start_stamp = int(time.mktime(start_date.timetuple()))
    end_stamp = int(time.mktime(end_date.timetuple()))

    # SQL query to fetch production counts grouped by date and shift
    sql  = f&#39;SELECT DATE(FROM_UNIXTIME(TimeStamp)) as event_date, &#39;
    sql += f&#39;CASE &#39;
    sql += f&#39;WHEN HOUR(FROM_UNIXTIME(TimeStamp)) &gt;= 7 AND HOUR(FROM_UNIXTIME(TimeStamp)) &lt; 15 THEN &#34;Day&#34; &#39;
    sql += f&#39;WHEN HOUR(FROM_UNIXTIME(TimeStamp)) &gt;= 15 AND HOUR(FROM_UNIXTIME(TimeStamp)) &lt; 23 THEN &#34;Afternoon&#34; &#39;
    sql += f&#39;ELSE &#34;Night&#34; &#39;
    sql += f&#39;END AS Shift, &#39;
    sql += f&#39;count(*) &#39;
    sql += f&#39;FROM GFxPRoduction &#39;
    sql += f&#39;WHERE TimeStamp BETWEEN {start_stamp} AND {end_stamp} &#39;
    sql += f&#39;AND Machine = &#34;{machine_number}&#34; &#39;
    sql += f&#39;GROUP BY event_date, Shift &#39;
    sql += f&#39;ORDER BY event_date, Shift;&#39;

    # Execute the SQL query using the specified database connection
    with connections[&#39;prodrpt-md&#39;].cursor() as c:
        c.execute(sql)
        data = c.fetchall()

    # Initialize lists to store results
    labels = []
    day_counts = []
    afternoon_counts = []
    night_counts = []
    total_counts = []

    # Create an iterator for the fetched data
    data_iter = iter(data)
    row = next(data_iter, None)

    interval = 24 * 60 * 60 # Interval of 1 day

    # Iterate over each day in the specified period
    for timestamp in range(start_stamp, end_stamp, interval):  # Interval of 1 day
        dt = datetime.fromtimestamp(timestamp).date()  # Convert timestamp to date

        # Initialize counts for each shift
        day_count = 0
        afternoon_count = 0
        night_count = 0

        # Accumulate counts for each shift within the current date interval
        while row and row[0] == dt:
            if row[1] == &#39;Day&#39;:
                day_count = row[2]
            elif row[1] == &#39;Afternoon&#39;:
                afternoon_count = row[2]
            elif row[1] == &#39;Night&#39;:
                night_count = row[2]
            row = next(data_iter, None)

        # Append the results for the current date to the lists
        labels.append(dt)
        day_counts.append(day_count)
        afternoon_counts.append(afternoon_count)
        night_counts.append(night_count)
        total_counts.append(day_count + afternoon_count + night_count)

    return labels, day_counts, afternoon_counts, night_counts, total_counts</code></pre>
</details>
<div class="desc"><p>Fetch production totals by day and shift for a specific machine.</p>
<p>Parameters:
- machine_number: str, identifier of the machine
- start_date: datetime, start of the period to fetch data for
- end_date: datetime, end of the period to fetch data for</p>
<p>Returns:
- labels: list of dates
- day_counts: list of counts for day shift
- afternoon_counts: list of counts for afternoon shift
- night_counts: list of counts for night shift
- total_counts: list of total counts per day</p></div>
</dd>
<dt id="prod_query.views.fetch_timestamps_for_timeblocks"><code class="name flex">
<span>def <span class="ident">fetch_timestamps_for_timeblocks</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_timestamps_for_timeblocks():
    &#34;&#34;&#34;
    Fetches timestamps, computes cycle time for every hour, and prints debugging information.
    &#34;&#34;&#34;
    asset_num = &#39;272&#39;
    start_date = datetime(2025, 2, 15)
    end_date = datetime(2025, 3, 1)

    # Get custom time blocks
    time_blocks = get_custom_time_blocks(start_date, end_date)

    if isinstance(time_blocks, str):
        print(&#34;Error:&#34;, time_blocks)
        return

    query = &#34;&#34;&#34;
        SELECT TimeStamp 
        FROM GFxPRoduction
        WHERE Machine = %s AND TimeStamp BETWEEN %s AND %s
        ORDER BY TimeStamp ASC;
    &#34;&#34;&#34;

    all_hourly_timestamps = []

    print(&#34;\n=== DEBUGGING TIMESTAMP COUNT, CYCLE TIME &amp; THEORETICAL PRODUCTION PER HOUR ===&#34;)

    with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
        for block_start, block_end in time_blocks:
            print(f&#34;\nTime Block: {block_start} to {block_end}&#34;)

            current_hour = block_start

            while current_hour &lt; block_end:
                next_hour = current_hour + timedelta(hours=1)
                if next_hour &gt; block_end:
                    next_hour = block_end

                start_timestamp = int(current_hour.timestamp())
                end_timestamp = int(next_hour.timestamp())

                # Fetch all timestamps
                cursor.execute(query, (asset_num, start_timestamp, end_timestamp))
                timestamps = [row[0] for row in cursor.fetchall()]
                
                # Store fetched timestamps
                all_hourly_timestamps.append(timestamps)

                print(f&#34;\n⏳ Hour: {current_hour.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)} - {next_hour.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)}&#34;)
                print(f&#34;  🔍 Raw Timestamps: {timestamps}&#34;)

                # Compute cycle time
                cycle_time = compute_cycle_time(np.array(timestamps))

                # Compute theoretical production
                theoretical_production = int(3600 / cycle_time) if cycle_time &gt; 0 else 0

                # Print summary
                print(f&#34;  ✅ Entries: {len(timestamps)}&#34;)
                print(f&#34;  ⏳ Cycle Time: {cycle_time:.2f} seconds&#34;)
                print(f&#34;  🏭 Theoretical Production: {theoretical_production} parts&#34;)

                current_hour = next_hour

    print(&#34;\n=== END OF DEBUGGING OUTPUT ===&#34;)
    
    return all_hourly_timestamps  # Returning for further processing</code></pre>
</details>
<div class="desc"><p>Fetches timestamps, computes cycle time for every hour, and prints debugging information.</p></div>
</dd>
<dt id="prod_query.views.find_first_sunday"><code class="name flex">
<span>def <span class="ident">find_first_sunday</span></span>(<span>start_date)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_first_sunday(start_date):
    &#34;&#34;&#34;
    Adjust the start date to the first Sunday at 11 PM.
    
    Parameters:
        start_date (datetime): The starting date and time to adjust from.
        
    Returns:
        datetime: The first Sunday after or on the given start_date,
                  adjusted to 11 PM (23:00:00).
                  
    Example:
        If start_date is 2025-01-01 10:00:00 (a Wednesday),
        the function will return 2025-01-05 23:00:00 (the next Sunday at 11 PM).
    &#34;&#34;&#34;
    # Initialize first_sunday with the start_date
    first_sunday = start_date

    # Loop until the day of the week is Sunday (weekday() returns 6 for Sunday)
    while first_sunday.weekday() != 6:
        first_sunday += timedelta(days=1)  # Add one day at a time until Sunday is reached

    # Replace the time part of the datetime to set it to 11 PM
    return first_sunday.replace(hour=23, minute=0, second=0)</code></pre>
</details>
<div class="desc"><p>Adjust the start date to the first Sunday at 11 PM.</p>
<h2 id="parameters">Parameters</h2>
<p>start_date (datetime): The starting date and time to adjust from.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>datetime</code></dt>
<dd>The first Sunday after or on the given start_date,
adjusted to 11 PM (23:00:00).</dd>
</dl>
<h2 id="example">Example</h2>
<p>If start_date is 2025-01-01 10:00:00 (a Wednesday),
the function will return 2025-01-05 23:00:00 (the next Sunday at 11 PM).</p></div>
</dd>
<dt id="prod_query.views.get_active_part"><code class="name flex">
<span>def <span class="ident">get_active_part</span></span>(<span>running_interval, changeover_records, machine)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_active_part(running_interval, changeover_records, machine):
    &#34;&#34;&#34;
    Determines which part is active for a given running interval for a specific machine.
    It first checks changeover records (ensuring the record&#39;s asset matches the machine).
    If no record is found, it falls back to querying the sc_production1 table.
    If the fallback finds a valid part number, it also looks up its cycle time.
    
    Args:
        running_interval (dict): Contains at least the &#39;start&#39; key (timestamp in seconds).
        changeover_records (list of tuples): Each tuple is
            (asset, part_no, ideal_cycle_time, called4helptime, completedtime, downtime, code).
        machine (str): The machine asset identifier.
    
    Returns:
        dict: A dictionary with:
            - &#39;part&#39;: The active part number or &#34;N/A&#34;
            - &#39;cycle_time&#39;: The ideal cycle time for that part or &#34;N/A&#34;
    &#34;&#34;&#34;
    running_start_ts = running_interval[&#39;start&#39;]
    active_record = None
    for record in changeover_records:
        # Only consider records for the specified machine.
        if str(record[0]).strip() != machine.strip():
            continue
        completedtime = record[4]
        if completedtime != &#34;na&#34; and isinstance(completedtime, datetime):
            if completedtime.timestamp() &lt;= running_start_ts:
                if active_record is None or completedtime.timestamp() &gt; active_record[4].timestamp():
                    active_record = record
    if active_record:
        return {&#39;part&#39;: active_record[1], &#39;cycle_time&#39;: active_record[2]}
    else:
        # Fallback: query the sc_production1 table.
        fallback_part = get_fallback_part_from_sc_production(machine, running_start_ts)
        if fallback_part:
            cycle_time = get_cycle_time_for_part(fallback_part)
            return {&#39;part&#39;: fallback_part, &#39;cycle_time&#39;: cycle_time}
        else:
            return {&#39;part&#39;: &#34;N/A&#34;, &#39;cycle_time&#39;: &#34;N/A&#34;}</code></pre>
</details>
<div class="desc"><p>Determines which part is active for a given running interval for a specific machine.
It first checks changeover records (ensuring the record's asset matches the machine).
If no record is found, it falls back to querying the sc_production1 table.
If the fallback finds a valid part number, it also looks up its cycle time.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>running_interval</code></strong> :&ensp;<code>dict</code></dt>
<dd>Contains at least the 'start' key (timestamp in seconds).</dd>
<dt><strong><code>changeover_records</code></strong> :&ensp;<code>list</code> of <code>tuples</code></dt>
<dd>Each tuple is
(asset, part_no, ideal_cycle_time, called4helptime, completedtime, downtime, code).</dd>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>The machine asset identifier.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary with:
- 'part': The active part number or "N/A"
- 'cycle_time': The ideal cycle time for that part or "N/A"</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_all_lines"><code class="name flex">
<span>def <span class="ident">get_all_lines</span></span>(<span>lines)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_all_lines(lines):
    return [line[&#39;line&#39;] for line in lines]</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.get_color_for_ratio"><code class="name flex">
<span>def <span class="ident">get_color_for_ratio</span></span>(<span>ratio)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_color_for_ratio(ratio):
    &#34;&#34;&#34;
    Maps a normalized ratio (0 to 1) to a color in a gradient, then applies a brightness factor:
      0   =&gt; dark red   (darker than full red #FF0000)
      0.5 =&gt; dark yellow
      1   =&gt; dark green
    The brightness factor scales down the computed RGB values.
    &#34;&#34;&#34;
    if ratio &lt;= 0.5:
        # Interpolate from red to yellow.
        factor = ratio / 0.5  # Normalized factor between 0 and 1.
        red = 255
        green = int(255 * factor)
    else:
        # Interpolate from yellow to green.
        factor = (ratio - 0.5) / 0.5  # Normalized factor between 0 and 1.
        red = int(255 * (1 - factor))
        green = 255
    blue = 0

    # Apply brightness factor to darken the color.
    brightness = 0.7  # Adjust this value between 0 and 1 for desired brightness.
    red = int(red * brightness)
    green = int(green * brightness)
    blue = int(blue * brightness)
    color_hex = &#39;#{:02X}{:02X}{:02X}&#39;.format(red, green, blue)
    return color_hex</code></pre>
</details>
<div class="desc"><p>Maps a normalized ratio (0 to 1) to a color in a gradient, then applies a brightness factor:
0
=&gt; dark red
(darker than full red #FF0000)
0.5 =&gt; dark yellow
1
=&gt; dark green
The brightness factor scales down the computed RGB values.</p></div>
</dd>
<dt id="prod_query.views.get_custom_time_blocks"><code class="name flex">
<span>def <span class="ident">get_custom_time_blocks</span></span>(<span>start_date, end_date)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_custom_time_blocks(start_date, end_date):
    &#34;&#34;&#34;
    Generates time blocks based on the given start and end dates.
    
    If the range is a full week or more, it uses Sunday 11 PM to Friday 11 PM logic.
    If the range is shorter, it uses start_date 11 PM to end_date 11 PM.
    It also ensures no future dates are included.

    Args:
        start_date (datetime): The start date selected.
        end_date (datetime): The end date selected.

    Returns:
        list of tuples: Each tuple contains (start_time, end_time) for the block.
        OR
        str: &#34;That&#39;s in the future&#34; if the date range includes future dates.
    &#34;&#34;&#34;
    now = datetime.now()

    # Ensure no future dates
    if start_date &gt; now or end_date &gt; now:
        return &#34;That&#39;s in the future&#34;

    # Adjust start and end times to 11 PM
    start_date = start_date.replace(hour=23, minute=0, second=0, microsecond=0)
    end_date = end_date.replace(hour=23, minute=0, second=0, microsecond=0)

    # If the range is less than a full week, return only that block
    if (end_date - start_date).days &lt; 6:
        return [(start_date, end_date)]

    # Otherwise, use full Sunday-to-Friday blocks
    return get_sunday_to_friday_ranges_custom(start_date, end_date)</code></pre>
</details>
<div class="desc"><p>Generates time blocks based on the given start and end dates.</p>
<p>If the range is a full week or more, it uses Sunday 11 PM to Friday 11 PM logic.
If the range is shorter, it uses start_date 11 PM to end_date 11 PM.
It also ensures no future dates are included.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start_date</code></strong> :&ensp;<code>datetime</code></dt>
<dd>The start date selected.</dd>
<dt><strong><code>end_date</code></strong> :&ensp;<code>datetime</code></dt>
<dd>The end date selected.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>tuples</code></dt>
<dd>Each tuple contains (start_time, end_time) for the block.</dd>
<dt>OR</dt>
<dt><code>str</code></dt>
<dd>"That's in the future" if the date range includes future dates.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_cycle_metrics"><code class="name flex">
<span>def <span class="ident">get_cycle_metrics</span></span>(<span>cycle_data)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cycle_metrics(cycle_data):
    &#34;&#34;&#34;
    Compute key cycle-time statistics from a frequency histogram.

    This function analyzes a list of `(cycle_time_in_seconds, frequency)` tuples
    (sorted by ascending cycle time) to extract the most frequent cycle times,
    calculate a weighted average of those top occurrences, and preserve the
    original histogram data.

    Parameters
    ----------
    cycle_data : list of tuple
        A list of `(cycle_time, frequency)` pairs, where:
          - `cycle_time` is the duration of a cycle in seconds (float or int),
          - `frequency` is the count of occurrences for that cycle time (int).
        The list should be sorted by `cycle_time` in ascending order.

    Returns
    -------
    dict
        A dictionary containing:
          - `top_eight` (list of tuple):
              The eight `(cycle_time, frequency)` entries with the highest frequencies,
              sorted by frequency in descending order.
          - `weighted_cycle_time` (float):
              The weighted average of the `top_eight` cycle times,
              computed as the sum of `(cycle_time * frequency)` divided by the
              total frequency of the top eight, rounded to three decimal places.
              Returns `0` if all top frequencies are zero or `cycle_data` is empty.
          - `histogram` (list of tuple):
              The original `cycle_data` list, unmodified.
    &#34;&#34;&#34;
    &#34;&#34;&#34;
    Compute cycle metrics from a sorted list of (cycle_time, frequency).

    Args:
      cycle_data: A list of tuples (cycle_time_in_seconds, frequency),
                  sorted by ascending cycle_time.


    Returns:
      A dictionary with:
         - &#39;top_eight&#39;: a list of the top 8 tuples (cycle_time, frequency) sorted by frequency descending,
         - &#39;weighted_cycle_time&#39;: the weighted average of the top eight cycle times (rounded to 3 decimals),
         - &#39;histogram&#39;: the original cycle_data list.
    &#34;&#34;&#34;
    if not cycle_data:
        return {&#34;top_eight&#34;: [], &#34;weighted_cycle_time&#34;: 0, &#34;histogram&#34;: []}


    # Sort the cycle_data list by frequency in descending order (highest frequency first)
    # and then take the first 8 entries. Each entry is a tuple: (cycle_time, frequency).
    top_eight = sorted(cycle_data, key=lambda x: x[1], reverse=True)[:8]

    # Calculate the total frequency by summing the frequencies of the top eight cycle times.
    # This gives us the total count of cycles among the top eight.
    total_frequency = sum(freq for ct, freq in top_eight)

    # Calculate the weighted sum by multiplying each cycle time (ct) by its frequency (freq)
    # and then summing all these products. This sum reflects the overall &#39;weight&#39; of the cycle times.
    weighted_sum = sum(ct * freq for ct, freq in top_eight)

    # Compute the weighted cycle time:
    # Divide the weighted sum by the total frequency to get the average cycle time,
    # weighted by how often each cycle time occurred.
    # Round the result to 3 decimal places.
    # If the total_frequency is zero (to avoid division by zero), return 0.
    weighted_cycle_time = round(weighted_sum / total_frequency, 3) if total_frequency else 0



    return {
        &#34;top_eight&#34;: top_eight,
        &#34;weighted_cycle_time&#34;: weighted_cycle_time,
        &#34;histogram&#34;: cycle_data
    }</code></pre>
</details>
<div class="desc"><p>Compute key cycle-time statistics from a frequency histogram.</p>
<p>This function analyzes a list of <code>(cycle_time_in_seconds, frequency)</code> tuples
(sorted by ascending cycle time) to extract the most frequent cycle times,
calculate a weighted average of those top occurrences, and preserve the
original histogram data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cycle_data</code></strong> :&ensp;<code>list</code> of <code>tuple</code></dt>
<dd>A list of <code>(cycle_time, frequency)</code> pairs, where:
- <code>cycle_time</code> is the duration of a cycle in seconds (float or int),
- <code>frequency</code> is the count of occurrences for that cycle time (int).
The list should be sorted by <code>cycle_time</code> in ascending order.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary containing:
- <code>top_eight</code> (list of tuple):
The eight <code>(cycle_time, frequency)</code> entries with the highest frequencies,
sorted by frequency in descending order.
- <code>weighted_cycle_time</code> (float):
The weighted average of the <code>top_eight</code> cycle times,
computed as the sum of <code>(cycle_time * frequency)</code> divided by the
total frequency of the top eight, rounded to three decimal places.
Returns <code>0</code> if all top frequencies are zero or <code>cycle_data</code> is empty.
- <code>histogram</code> (list of tuple):
The original <code>cycle_data</code> list, unmodified.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_cycle_time_for_part"><code class="name flex">
<span>def <span class="ident">get_cycle_time_for_part</span></span>(<span>part_no)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cycle_time_for_part(part_no):
    &#34;&#34;&#34;
    Attempts to look up the ideal cycle time for a given part number
    using the AssetCycleTimes table. Returns the cycle time if found,
    otherwise &#34;N/A&#34;.
    
    Args:
        part_no (str): The part number to look up.
    
    Returns:
        cycle_time (float or str): The ideal cycle time in seconds, or &#34;N/A&#34;.
    &#34;&#34;&#34;
    try:
        cycle_record = AssetCycleTimes.objects.filter(
            part__part_number=part_no
        ).order_by(&#34;-effective_date&#34;).first()
        if cycle_record:
            return cycle_record.cycle_time
    except Exception as e:
        print(f&#34;[ERROR] Looking up cycle time for part {part_no}: {e}&#34;)
    return &#34;N/A&#34;</code></pre>
</details>
<div class="desc"><p>Attempts to look up the ideal cycle time for a given part number
using the AssetCycleTimes table. Returns the cycle time if found,
otherwise "N/A".</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>part_no</code></strong> :&ensp;<code>str</code></dt>
<dd>The part number to look up.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>cycle_time (float or str): The ideal cycle time in seconds, or "N/A".</p></div>
</dd>
<dt id="prod_query.views.get_distinct_machines"><code class="name flex">
<span>def <span class="ident">get_distinct_machines</span></span>(<span>lines)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_distinct_machines(lines):
    &#34;&#34;&#34;
    Extract all distinct machine numbers from the lines object.
    &#34;&#34;&#34;
    machines = set()  # Use a set to ensure uniqueness
    for line in lines:
        for operation in line.get(&#34;operations&#34;, []):
            for machine in operation.get(&#34;machines&#34;, []):
                machines.add(machine[&#34;number&#34;])
    return sorted(machines)  # Return sorted list of machine numbers</code></pre>
</details>
<div class="desc"><p>Extract all distinct machine numbers from the lines object.</p></div>
</dd>
<dt id="prod_query.views.get_fallback_part_from_sc_production"><code class="name flex">
<span>def <span class="ident">get_fallback_part_from_sc_production</span></span>(<span>machine, running_start_ts)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_fallback_part_from_sc_production(machine, running_start_ts):
    &#34;&#34;&#34;
    Fallback lookup for an active part from the sc_production1 table.
    It returns the last record (before the running interval starts) for the given asset,
    but only if the part number is exactly 9 characters long.
    
    Args:
        machine (str): The asset number.
        running_start_ts (int): The running interval start timestamp.
        
    Returns:
        str or None: The part number if found and valid, otherwise None.
    &#34;&#34;&#34;
    running_start_dt = datetime.fromtimestamp(running_start_ts)
    query = &#34;&#34;&#34;
        SELECT partno, updatedtime FROM sc_production1
        WHERE asset_num = %s AND updatedtime &lt; %s
        ORDER BY updatedtime DESC
        LIMIT 1;
    &#34;&#34;&#34;
    with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
        cursor.execute(query, (machine, running_start_dt))
        row = cursor.fetchone()
        if row:
            partno = row[0]
            if partno and len(partno.strip()) == 9:
                return partno.strip()
    return None</code></pre>
</details>
<div class="desc"><p>Fallback lookup for an active part from the sc_production1 table.
It returns the last record (before the running interval starts) for the given asset,
but only if the part number is exactly 9 characters long.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>The asset number.</dd>
<dt><strong><code>running_start_ts</code></strong> :&ensp;<code>int</code></dt>
<dd>The running interval start timestamp.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code> or <code>None</code></dt>
<dd>The part number if found and valid, otherwise None.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_line_details"><code class="name flex">
<span>def <span class="ident">get_line_details</span></span>(<span>selected_date, selected_line, lines)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_line_details(selected_date, selected_line, lines):
    &#34;&#34;&#34;
    Fetch detailed data for a line on a given date, including adjusted targets
    based on the percentage downtime.
    &#34;&#34;&#34;
    try:
        selected_date_unix = int(selected_date.timestamp())
        line_data = next((line for line in lines if line[&#39;line&#39;] == selected_line), None)
        if not line_data:
            raise ValueError(f&#34;Invalid line selected: {selected_line}&#34;)

        grouped_results = {}
        for operation in line_data[&#39;operations&#39;]:
            for machine in operation[&#39;machines&#39;]:
                machine_number = machine[&#39;number&#39;]
                machine_target = get_machine_target(machine_number, selected_date_unix, selected_line)
                if machine_target is None:
                    continue

                machine_details = get_month_details(selected_date, machine_number, selected_line, lines)
                for block in machine_details[&#39;ranges&#39;]:
                    date_block = (block[&#39;start&#39;], block[&#39;end&#39;])
                    if date_block not in grouped_results:
                        grouped_results[date_block] = {}
                    if operation[&#39;op&#39;] not in grouped_results[date_block]:
                        grouped_results[date_block][operation[&#39;op&#39;]] = {&#39;machines&#39;: []}

                    # Calculate adjusted target using percentage_downtime from block
                    # block[&#39;percentage_downtime&#39;] should be something like &#34;24%&#34;
                    adjusted_target = calculate_adjusted_target(
                        target=machine_target,
                        percentage_downtime=block[&#39;percentage_downtime&#39;]
                    )

                    p_value = f&#34;{calculate_p(block[&#39;produced&#39;], adjusted_target, block[&#39;percentage_downtime&#39;])}%&#34;
                    machine_data = {
                        &#39;machine_number&#39;: machine_number,
                        &#39;target&#39;: machine_target,
                        &#39;adjusted_target&#39;: adjusted_target,
                        &#39;produced&#39;: block[&#39;produced&#39;],
                        &#39;downtime&#39;: block[&#39;downtime&#39;],
                        &#39;potential_minutes&#39;: block[&#39;potential_minutes&#39;],
                        &#39;percentage_downtime&#39;: block[&#39;percentage_downtime&#39;],
                        &#39;p_value&#39;: p_value
                    }
                    grouped_results[date_block][operation[&#39;op&#39;]][&#39;machines&#39;].append(machine_data)

        grouped_results = calculate_totals(grouped_results)

        # Add scrap info and line totals
        for date_block, operations in grouped_results.items():
            start_date, end_date = date_block
            scrap_data = total_scrap_for_line(scrap_line=selected_line, start_date=start_date, end_date=end_date)
            total_scrap_amount = scrap_data[&#39;total_scrap_amount&#39;]
            if &#39;line_totals&#39; not in operations:
                operations[&#39;line_totals&#39;] = {}
            operations[&#39;line_totals&#39;][&#39;total_scrap_amount&#39;] = total_scrap_amount

        grouped_results = calculate_line_totals(grouped_results)
        for date_block, operations in grouped_results.items():
            if &#39;line_totals&#39; in operations:
                scrap_total = operations[&#39;line_totals&#39;].get(&#39;total_scrap_amount&#39;, 0)
                total_produced_last_op = get_total_produced_last_op_for_block(operations)
                operations[&#39;line_totals&#39;][&#39;q_value&#39;] = calculate_Q(total_produced_last_op, scrap_total)

        monthly_totals = calculate_monthly_totals(grouped_results)
        return {
            &#39;line_name&#39;: selected_line,
            &#39;grouped_results&#39;: grouped_results,
            &#39;monthly_totals&#39;: monthly_totals
        }
    except Exception as e:
        print(f&#34;Error in get_line_details: {e}&#34;)
        raise</code></pre>
</details>
<div class="desc"><p>Fetch detailed data for a line on a given date, including adjusted targets
based on the percentage downtime.</p></div>
</dd>
<dt id="prod_query.views.get_machine_data"><code class="name flex">
<span>def <span class="ident">get_machine_data</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_machine_data(request):
    &#34;&#34;&#34;
    Provide JSON mappings of machine targets and production line assignments.

    Iterates over the global `lines` structure (each containing a `line` name,
    a list of `operations`, and for each operation, a list of `machines`
    with `number` and `target`), and builds two dictionaries:
      - `machine_targets`: maps each machine number (str/int) to its target value.
      - `line_mapping`: maps each production line name (str) to the list of machine numbers on that line.

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request (unused in this view).

    Returns
    -------
    django.http.JsonResponse
        A JSON response with keys:
          - `machine_targets`: dict of `{ machine_number: target }`
          - `line_mapping`: dict of `{ line_name: [machine_number, ...] }`
    &#34;&#34;&#34;
    # Prepare machine targets and line-to-machine mapping dynamically
    machine_targets = {}
    line_mapping = {}

    for line in lines:
        line_name = line[&#34;line&#34;]
        line_mapping[line_name] = []
        for operation in line[&#34;operations&#34;]:
            for machine in operation[&#34;machines&#34;]:
                machine_number = machine[&#34;number&#34;]
                target = machine[&#34;target&#34;]
                machine_targets[machine_number] = target
                line_mapping[line_name].append(machine_number)

    return JsonResponse({
        &#39;machine_targets&#39;: machine_targets,
        &#39;line_mapping&#39;: line_mapping
    })</code></pre>
</details>
<div class="desc"><p>Provide JSON mappings of machine targets and production line assignments.</p>
<p>Iterates over the global <code>lines</code> structure (each containing a <code>line</code> name,
a list of <code>operations</code>, and for each operation, a list of <code>machines</code>
with <code>number</code> and <code>target</code>), and builds two dictionaries:
- <code>machine_targets</code>: maps each machine number (str/int) to its target value.
- <code>line_mapping</code>: maps each production line name (str) to the list of machine numbers on that line.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request (unused in this view).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.JsonResponse</code></dt>
<dd>A JSON response with keys:
- <code>machine_targets</code>: dict of <code>{ machine_number: target }</code>
- <code>line_mapping</code>: dict of <code>{ line_name: [machine_number, ...] }</code></dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_machine_part_numbers"><code class="name flex">
<span>def <span class="ident">get_machine_part_numbers</span></span>(<span>machine_id, line_name, lines)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_machine_part_numbers(machine_id, line_name, lines):
    &#34;&#34;&#34;
    Retrieve the part numbers associated with a specific machine on a given production line.

    Parameters
    ----------
    machine_id : int
        The unique identifier of the machine whose part numbers are being requested.
    line_name : str
        The name of the production line to search.
    lines : list of dict
        A list of line definitions, where each dict has keys:
        - &#39;line&#39; (str): the line name
        - &#39;operations&#39; (list of dict): each with keys:
            • &#39;op&#39; (str)
            • &#39;machines&#39; (list of dict), each machine dict containing:
                - &#39;number&#39; (int)
                - optional &#39;part_numbers&#39; (list)

    Returns
    -------
    list or None
        The list of part numbers for the matching machine if present; otherwise None.
    &#34;&#34;&#34;
    for line in lines:
        if line[&#39;line&#39;] == line_name:  # Match the correct line
            for operation in line[&#39;operations&#39;]:
                for machine in operation[&#39;machines&#39;]:
                    if machine[&#39;number&#39;] == machine_id:
                        # Return part numbers if they exist, otherwise None
                        return machine.get(&#39;part_numbers&#39;, None)
    return None  # Return None if no match is found</code></pre>
</details>
<div class="desc"><p>Retrieve the part numbers associated with a specific machine on a given production line.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>machine_id</code></strong> :&ensp;<code>int</code></dt>
<dd>The unique identifier of the machine whose part numbers are being requested.</dd>
<dt><strong><code>line_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the production line to search.</dd>
<dt><strong><code>lines</code></strong> :&ensp;<code>list</code> of <code>dict</code></dt>
<dd>A list of line definitions, where each dict has keys:
- 'line' (str): the line name
- 'operations' (list of dict): each with keys:
• 'op' (str)
• 'machines' (list of dict), each machine dict containing:
- 'number' (int)
- optional 'part_numbers' (list)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> or <code>None</code></dt>
<dd>The list of part numbers for the matching machine if present; otherwise None.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_machine_target"><code class="name flex">
<span>def <span class="ident">get_machine_target</span></span>(<span>machine_id, selected_date_unix, line_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_machine_target(machine_id, selected_date_unix, line_name):
    &#34;&#34;&#34;
    Retrieve the applicable target value for a machine on a specific line as of a given timestamp.

    This function queries the `OAMachineTargets` model for entries matching
    the provided `machine_id` and `line_name`, ordered by their `effective_date_unix`.
    It then selects the latest entry whose `effective_date_unix` is less than or equal
    to `selected_date_unix`. If a later entry exists after the selected date, it is skipped.

    Parameters
    ----------
    machine_id : int
        The primary key of the machine whose target is requested.
    selected_date_unix : int
        A Unix-epoch timestamp (in seconds) representing the reference date.
    line_name : str
        The production line identifier to filter target entries.

    Returns
    -------
    Any or None
        The `target` value from the matching `OAMachineTargets` entry, or `None`
        if no applicable entry is found or if an error occurs.

    Notes
    -----
    - If multiple entries share the same `effective_date_unix`, the first in
      ascending order is chosen.
    - Errors during database access are caught and logged; in such cases, `None`
      is returned.
    &#34;&#34;&#34;
    try:
        # Fetch all target entries for the given machine and line
        all_targets = OAMachineTargets.objects.filter(
            machine_id=machine_id,
            line=line_name
        ).order_by(&#39;effective_date_unix&#39;)


        # Find the correct target entry based on the selected date
        target_entry = None
        for i, target in enumerate(all_targets):
            # Check if this target falls within the appropriate range
            if target.effective_date_unix &lt;= selected_date_unix:
                # Check if it&#39;s the last entry or if the next entry is after the selected date
                next_entry = all_targets[i + 1] if i + 1 &lt; len(all_targets) else None
                if not next_entry or next_entry.effective_date_unix &gt; selected_date_unix:
                    target_entry = target
                    break


        # Return the target value or None if no valid entry is found
        return target_entry.target if target_entry else None

    except Exception as e:
        print(f&#34;Error in get_machine_target: {e}&#34;)
        return None</code></pre>
</details>
<div class="desc"><p>Retrieve the applicable target value for a machine on a specific line as of a given timestamp.</p>
<p>This function queries the <code>OAMachineTargets</code> model for entries matching
the provided <code>machine_id</code> and <code>line_name</code>, ordered by their <code>effective_date_unix</code>.
It then selects the latest entry whose <code>effective_date_unix</code> is less than or equal
to <code>selected_date_unix</code>. If a later entry exists after the selected date, it is skipped.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>machine_id</code></strong> :&ensp;<code>int</code></dt>
<dd>The primary key of the machine whose target is requested.</dd>
<dt><strong><code>selected_date_unix</code></strong> :&ensp;<code>int</code></dt>
<dd>A Unix-epoch timestamp (in seconds) representing the reference date.</dd>
<dt><strong><code>line_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The production line identifier to filter target entries.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Any</code> or <code>None</code></dt>
<dd>The <code>target</code> value from the matching <code>OAMachineTargets</code> entry, or <code>None</code>
if no applicable entry is found or if an error occurs.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>If multiple entries share the same <code>effective_date_unix</code>, the first in
ascending order is chosen.</li>
<li>Errors during database access are caught and logged; in such cases, <code>None</code>
is returned.</li>
</ul></div>
</dd>
<dt id="prod_query.views.get_month_and_year"><code class="name flex">
<span>def <span class="ident">get_month_and_year</span></span>(<span>date_str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_month_and_year(date_str):
    &#34;&#34;&#34;
    Convert an ISO-formatted date string into a human-readable &#34;Month Year&#34; string.

    Parameters
    ----------
    date_str : str
        A date in &#34;YYYY-MM-DD&#34; format.

    Returns
    -------
    str or None
        The formatted month and year (e.g., &#34;June 2025&#34;) if `date_str` is valid;
        otherwise, returns None for invalid or unparsable dates.
    &#34;&#34;&#34;
    try:
        date = datetime.strptime(date_str, &#39;%Y-%m-%d&#39;)
        return date.strftime(&#39;%B %Y&#39;)  # Format to &#34;Month Year&#34;
    except ValueError:
        return None  # Return None if the date is invalid</code></pre>
</details>
<div class="desc"><p>Convert an ISO-formatted date string into a human-readable "Month Year" string.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>date_str</code></strong> :&ensp;<code>str</code></dt>
<dd>A date in "YYYY-MM-DD" format.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code> or <code>None</code></dt>
<dd>The formatted month and year (e.g., "June 2025") if <code>date_str</code> is valid;
otherwise, returns None for invalid or unparsable dates.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_month_details"><code class="name flex">
<span>def <span class="ident">get_month_details</span></span>(<span>selected_date, machine, line_name, lines)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_month_details(selected_date, machine, line_name, lines):
    &#34;&#34;&#34;
    Gather monthly performance data for a specific machine on a production line.

    This function computes:
      1. The UTC‐based start and end datetimes for the month containing `selected_date`,
         using `get_month_start_and_end`.
      2. A series of Sunday-through-Friday intervals spanning that month,
         via `get_sunday_to_friday_ranges`.
      3. Downtime metrics for each interval (total downtime, potential minutes),
         formatted with `calculate_percentage_week` and `calculate_percentage_downtime`.
      4. Production counts over the same intervals, using part numbers (if any)
         retrieved by `get_machine_part_numbers`.

    Parameters
    ----------
    selected_date : datetime.datetime
        A reference date within the target month.
    machine : str
        Identifier of the machine to analyze.
    line_name : str
        The name of the production line where the machine operates.
    lines : list of dict
        Production-line definitions, each with keys:
          - &#39;line&#39;: line name
          - &#39;operations&#39;: list of {&#39;op&#39;: ..., &#39;machines&#39;: [{&#39;number&#39;: ..., &#39;part_numbers&#39;: [...]}, ...]}

    Returns
    -------
    dict
        A dictionary containing:
          - &#39;first_day&#39; (datetime.datetime): the computed month-start datetime.
          - &#39;last_day&#39;  (datetime.datetime): the computed month-end datetime.
          - &#39;ranges&#39;    (list of dict): each element for an interval with keys:
                • &#39;start&#39;, &#39;end&#39; (datetime.datetime)
                • &#39;downtime&#39; (float): total downtime minutes
                • &#39;potential_minutes&#39; (str): formatted minutes (and percentage of full week)
                • &#39;percentage_downtime&#39; (str): formatted downtime percentage
                • &#39;produced&#39; (int or float): total production count
    &#34;&#34;&#34;
    first_day, last_day = get_month_start_and_end(selected_date)
    ranges = get_sunday_to_friday_ranges(first_day, last_day)

    # Fetch downtime data
    downtime_results = fetch_downtime_by_date_ranges(
        machine=machine,
        date_ranges=ranges
    )
    for result in downtime_results:
        result[&#39;potential_minutes&#39;] = calculate_percentage_week(result[&#39;potential_minutes&#39;])
        result[&#39;percentage_downtime&#39;] = calculate_percentage_downtime(
            downtime=result[&#39;downtime&#39;],
            potential_minutes=int(result[&#39;potential_minutes&#39;].split()[0])
        )
    
    # Fetch part numbers for the machine within the specified line
    part_numbers = get_machine_part_numbers(machine, line_name, lines)

    # Fetch production data, including part numbers if available
    with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
        for result in downtime_results:
            result[&#39;produced&#39;] = calculate_total_produced(
                machine=machine,
                machine_parts=part_numbers,  # Pass part numbers dynamically
                start_timestamp=int(result[&#39;start&#39;].timestamp()),
                end_timestamp=int(result[&#39;end&#39;].timestamp()),
                cursor=cursor
            )
    return {
        &#39;first_day&#39;: first_day,
        &#39;last_day&#39;: last_day,
        &#39;ranges&#39;: downtime_results
    }</code></pre>
</details>
<div class="desc"><p>Gather monthly performance data for a specific machine on a production line.</p>
<p>This function computes:
1. The UTC‐based start and end datetimes for the month containing <code>selected_date</code>,
using <code><a title="prod_query.views.get_month_start_and_end" href="#prod_query.views.get_month_start_and_end">get_month_start_and_end()</a></code>.
2. A series of Sunday-through-Friday intervals spanning that month,
via <code><a title="prod_query.views.get_sunday_to_friday_ranges" href="#prod_query.views.get_sunday_to_friday_ranges">get_sunday_to_friday_ranges()</a></code>.
3. Downtime metrics for each interval (total downtime, potential minutes),
formatted with <code><a title="prod_query.views.calculate_percentage_week" href="#prod_query.views.calculate_percentage_week">calculate_percentage_week()</a></code> and <code><a title="prod_query.views.calculate_percentage_downtime" href="#prod_query.views.calculate_percentage_downtime">calculate_percentage_downtime()</a></code>.
4. Production counts over the same intervals, using part numbers (if any)
retrieved by <code><a title="prod_query.views.get_machine_part_numbers" href="#prod_query.views.get_machine_part_numbers">get_machine_part_numbers()</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>selected_date</code></strong> :&ensp;<code>datetime.datetime</code></dt>
<dd>A reference date within the target month.</dd>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>Identifier of the machine to analyze.</dd>
<dt><strong><code>line_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the production line where the machine operates.</dd>
<dt><strong><code>lines</code></strong> :&ensp;<code>list</code> of <code>dict</code></dt>
<dd>Production-line definitions, each with keys:
- 'line': line name
- 'operations': list of {'op': &hellip;, 'machines': [{'number': &hellip;, 'part_numbers': [&hellip;]}, &hellip;]}</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary containing:
- 'first_day' (datetime.datetime): the computed month-start datetime.
- 'last_day'
(datetime.datetime): the computed month-end datetime.
- 'ranges'
(list of dict): each element for an interval with keys:
• 'start', 'end' (datetime.datetime)
• 'downtime' (float): total downtime minutes
• 'potential_minutes' (str): formatted minutes (and percentage of full week)
• 'percentage_downtime' (str): formatted downtime percentage
• 'produced' (int or float): total production count</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_month_start_and_end"><code class="name flex">
<span>def <span class="ident">get_month_start_and_end</span></span>(<span>selected_date)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_month_start_and_end(selected_date):
    &#34;&#34;&#34;
    Calculate the reporting window start and end datetimes for a given month.

    The start time is set to 11:00 PM local time on the day before the first of the month,
    except when the first of the month falls on a Sunday—in that case, it uses 11:00 PM
    on that Sunday itself.

    The end time is:
      - If `selected_date` is in the current month and year: the current moment
        (with seconds and microseconds zeroed out).
      - Otherwise: 11:00 PM on the last day of the selected month.

    Parameters
    ----------
    selected_date : datetime.datetime
        Any datetime within the month for which the start/end window should be calculated.

    Returns
    -------
    tuple of (datetime.datetime, datetime.datetime)
        - start_date: The lower bound of the reporting window.
        - end_date:   The upper bound of the reporting window.
    &#34;&#34;&#34;
    today = datetime.now()
    first_day_of_month = selected_date.replace(day=1)
    if first_day_of_month.weekday() == 6:
        start_date = first_day_of_month.replace(hour=23, minute=0, second=0)
    else:
        start_date = (first_day_of_month - timedelta(days=1)).replace(hour=23, minute=0, second=0)
    if selected_date.year == today.year and selected_date.month == today.month:
        end_date = today.replace(second=0, microsecond=0)
    else:
        end_date = selected_date.replace(
            day=calendar.monthrange(selected_date.year, selected_date.month)[1]
        ).replace(hour=23, minute=0, second=0)

    return start_date, end_date</code></pre>
</details>
<div class="desc"><p>Calculate the reporting window start and end datetimes for a given month.</p>
<p>The start time is set to 11:00 PM local time on the day before the first of the month,
except when the first of the month falls on a Sunday—in that case, it uses 11:00 PM
on that Sunday itself.</p>
<p>The end time is:
- If <code>selected_date</code> is in the current month and year: the current moment
(with seconds and microseconds zeroed out).
- Otherwise: 11:00 PM on the last day of the selected month.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>selected_date</code></strong> :&ensp;<code>datetime.datetime</code></dt>
<dd>Any datetime within the month for which the start/end window should be calculated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code> of <code>(datetime.datetime, datetime.datetime)</code></dt>
<dd>
<ul>
<li>start_date: The lower bound of the reporting window.</li>
<li>end_date:
The upper bound of the reporting window.</li>
</ul>
</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_parts_for_machine"><code class="name flex">
<span>def <span class="ident">get_parts_for_machine</span></span>(<span>lines, line_name, machine_id)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_parts_for_machine(lines, line_name, machine_id):
    &#34;&#34;&#34;
    Helper to return the list of part_numbers (may be empty) for the given machine.
    &#34;&#34;&#34;
    for ln in lines:
        if ln[&#34;line&#34;] == line_name:
            for op in ln.get(&#34;operations&#34;, []):
                for m in op.get(&#34;machines&#34;, []):
                    if m[&#34;number&#34;] == machine_id:
                        return m.get(&#34;part_numbers&#34;) or []
    return []</code></pre>
</details>
<div class="desc"><p>Helper to return the list of part_numbers (may be empty) for the given machine.</p></div>
</dd>
<dt id="prod_query.views.get_pr_downtime_entries"><code class="name flex">
<span>def <span class="ident">get_pr_downtime_entries</span></span>(<span>machine_number, start_time, end_time)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pr_downtime_entries(machine_number, start_time, end_time):
    import datetime, os, importlib, json
    &#34;&#34;&#34;Fetches and processes PR downtime entries for a machine.&#34;&#34;&#34;
    pr_entries = fetch_prdowntime1_entries_with_id(machine_number, start_time.isoformat(), end_time.isoformat())
    pr_downtime_entries = []
    for entry in pr_entries:
        pr_id = entry[0]
        problem = entry[1]
        called = entry[2]
        completed = entry[3] if len(entry) &gt; 3 else None

        try:
            dt_called = datetime.datetime.fromisoformat(called) if isinstance(called, str) else called
        except Exception:
            dt_called = None
        try:
            dt_completed = datetime.datetime.fromisoformat(completed) if (completed and isinstance(completed, str)) else completed
        except Exception:
            dt_completed = None

        minutes_down = int((dt_completed - dt_called).total_seconds() / 60) if dt_called and dt_completed else &#34;N/A&#34;
        pr_entry = {
            &#34;idnumber&#34;: pr_id,
            &#34;problem&#34;: problem,
            &#34;start_time&#34;: dt_called,
            &#34;end_time&#34;: dt_completed,
            &#34;minutes_down&#34;: minutes_down,
        }
        pr_downtime_entries.append(pr_entry)
    return pr_downtime_entries</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.get_production_data"><code class="name flex">
<span>def <span class="ident">get_production_data</span></span>(<span>machine, start_timestamp, times, part_list)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_production_data(machine, start_timestamp, times, part_list):
    &#34;&#34;&#34;
    Retrieve production counts for a machine over specified time buckets.

    Constructs and executes a SQL query against the `GFxPRoduction` table,
    grouping production events by Part into time buckets determined by `times`.

    Parameters
    ----------
    machine : str
        The machine identifier to filter production records.
    start_timestamp : int
        Unix epoch (seconds) marking the start of the analysis window.
    times : int or str
        A code indicating the desired bucketization:
          - 1–6: eight consecutive 1-hour buckets (hour1…hour8)
          - 7–8: three 8-hour shift buckets (shift1…shift3)
          - 9+: seven daily buckets (mon…sun)
    part_list : str or None
        A comma-separated, quoted list of part numbers for an SQL IN clause
        (e.g. `&#34;A&#34;,&#34;B&#34;,&#34;C&#34;`), or None/empty to include all parts.

    Returns
    -------
    list of list
        Each inner list corresponds to a row in the result set:
          [ Part (str), bucket1 (int), bucket2 (int), …, total (int) ]
        where `total` is the sum of the bucket counts for that Part.

    Notes
    -----
    - The SQL query filters `TimeStamp` between `start_timestamp` and the window end:
        • +8 hours for times 1–6
        • +24 hours for times 7–8
        • +7 days for times 9+
    - A final total-per-row column is appended in Python, summing all bucket values.
    - Requires a Django DB connection alias `&#39;prodrpt-md&#39;`.
    &#34;&#34;&#34;

    if int(times) &lt;= 6:  # 8 hour query
        sql = &#39;SELECT Part, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp) + &#39; AND TimeStamp &lt;= &#39; + \
            str(start_timestamp + 3600) + &#39; THEN 1 ELSE 0 END) as hour1, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 3600) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 7200) + &#39; THEN 1 ELSE 0 END) as hour2, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 7200) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 10800) + &#39; THEN 1 ELSE 0 END) as hour3, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 10800) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 14400) + &#39; THEN 1 ELSE 0 END) as hour4, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 14400) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 18000) + &#39; THEN 1 ELSE 0 END) as hour5, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 18000) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 21600) + &#39; THEN 1 ELSE 0 END) as hour6, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 21600) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 25200) + &#39; THEN 1 ELSE 0 END) as hour7, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp +
                                                   25200) + &#39; THEN 1 ELSE 0 END) AS hour8 &#39;
        sql += &#39;FROM GFxPRoduction &#39;
        sql += &#39;WHERE TimeStamp &gt;= &#39; + \
            str(start_timestamp) + &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 28800) + &#39; &#39;
        sql += &#39;AND Machine = &#34;&#39; + machine + &#39;&#34; &#39;
        if (part_list):
            sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
        sql += &#39;GROUP BY Part &#39;
        sql += &#39;ORDER BY Part ASC;&#39;

    elif int(times) &lt;= 8:  # 24 hour by shift query
        sql = &#39;SELECT Part, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp) + &#39; AND TimeStamp &lt;= &#39; + \
            str(start_timestamp + 28800) + &#39; THEN 1 ELSE 0 END) as shift1, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 28800) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 57600) + &#39; THEN 1 ELSE 0 END) as shift2, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp +
                                                   57600) + &#39; THEN 1 ELSE 0 END) AS shift3 &#39;
        sql += &#39;FROM GFxPRoduction &#39;
        sql += &#39;WHERE TimeStamp &gt;= &#39; + \
            str(start_timestamp) + &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 86400) + &#39; &#39;
        sql += &#39;AND Machine = &#34;&#39; + machine + &#39;&#34; &#39;
        if (part_list):
            sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
        sql += &#39;GROUP BY Part &#39;
        sql += &#39;ORDER BY Part ASC;&#39;

    else:  # week at a time query
        sql = &#39;SELECT Part, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp) + &#39; AND TimeStamp &lt;= &#39; + \
            str(start_timestamp + 86400) + &#39; THEN 1 ELSE 0 END) as mon, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 86400) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 172800) + &#39; THEN 1 ELSE 0 END) as tue, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 172800) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 259200) + &#39; THEN 1 ELSE 0 END) as wed, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 259200) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 345600) + &#39; THEN 1 ELSE 0 END) as thur, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 345600) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 432000) + &#39; THEN 1 ELSE 0 END) as fri, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 432000) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 518400) + &#39; THEN 1 ELSE 0 END) as sat, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + \
            str(start_timestamp + 518400) + &#39; THEN 1 ELSE 0 END) AS sun &#39;
        sql += &#39;FROM GFxPRoduction &#39;
        sql += &#39;WHERE TimeStamp &gt;= &#39; + \
            str(start_timestamp) + &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 604800) + &#39; &#39;
        sql += &#39;AND Machine = &#34;&#39; + machine + &#39;&#34; &#39;
        if (part_list):
            sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
        sql += &#39;GROUP BY Part &#39;
        sql += &#39;ORDER BY Part ASC;&#39;

    results = []
    cursor = connections[&#39;prodrpt-md&#39;].cursor()
    try:
        cursor.execute(sql)
        result = cursor.fetchall()
        for row in result:
            row = list(row)
            row.append(sum(row[1:]))
            results.append(row)

    except Exception as e:
        print(&#34;Oops!&#34;, e, &#34;occurred.&#34;)
    finally:
        cursor.close()

    return results</code></pre>
</details>
<div class="desc"><p>Retrieve production counts for a machine over specified time buckets.</p>
<p>Constructs and executes a SQL query against the <code>GFxPRoduction</code> table,
grouping production events by Part into time buckets determined by <code>times</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>The machine identifier to filter production records.</dd>
<dt><strong><code>start_timestamp</code></strong> :&ensp;<code>int</code></dt>
<dd>Unix epoch (seconds) marking the start of the analysis window.</dd>
<dt><strong><code>times</code></strong> :&ensp;<code>int</code> or <code>str</code></dt>
<dd>A code indicating the desired bucketization:
- 1–6: eight consecutive 1-hour buckets (hour1…hour8)
- 7–8: three 8-hour shift buckets (shift1…shift3)
- 9+: seven daily buckets (mon…sun)</dd>
<dt><strong><code>part_list</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>A comma-separated, quoted list of part numbers for an SQL IN clause
(e.g. <code>"A","B","C"</code>), or None/empty to include all parts.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>list</code></dt>
<dd>Each inner list corresponds to a row in the result set:
[ Part (str), bucket1 (int), bucket2 (int), …, total (int) ]
where <code>total</code> is the sum of the bucket counts for that Part.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>The SQL query filters <code>TimeStamp</code> between <code>start_timestamp</code> and the window end:
• +8 hours for times 1–6
• +24 hours for times 7–8
• +7 days for times 9+</li>
<li>A final total-per-row column is appended in Python, summing all bucket values.</li>
<li>Requires a Django DB connection alias <code>'prodrpt-md'</code>.</li>
</ul></div>
</dd>
<dt id="prod_query.views.get_production_data_for_machine"><code class="name flex">
<span>def <span class="ident">get_production_data_for_machine</span></span>(<span>cursor,<br>machine,<br>machine_number,<br>start_timestamp,<br>end_timestamp,<br>op,<br>queried_minutes,<br>line_name)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_production_data_for_machine(cursor, machine, machine_number, start_timestamp, end_timestamp, op, queried_minutes, line_name):
    import datetime
    &#34;&#34;&#34;Fetches production parts data and target for a given machine.&#34;&#34;&#34;
    target_val = fetch_machine_target(cursor, machine_number, line_name, start_timestamp, end_timestamp)
    target = int(target_val * (queried_minutes / 7200)) if target_val is not None else None

    if machine.get(&#34;part_numbers&#34;) and isinstance(machine.get(&#34;part_numbers&#34;), list) and machine[&#34;part_numbers&#34;]:
        placeholders = &#34;, &#34;.join([&#34;%s&#34;] * len(machine[&#34;part_numbers&#34;]))
        query_str = f&#34;&#34;&#34;
            SELECT Part, COUNT(*)
            FROM GFxPRoduction
            WHERE Machine = %s AND TimeStamp BETWEEN %s AND %s
            AND Part IN ({placeholders})
            GROUP BY Part;
        &#34;&#34;&#34;
        params = [machine_number, start_timestamp, end_timestamp] + machine[&#34;part_numbers&#34;]
        cursor.execute(query_str, params)
        produced_parts_by_part = {}
        row = cursor.fetchone()
        while row is not None:
            produced_parts_by_part[row[0]] = row[1]
            row = cursor.fetchone()
        total_produced = sum(produced_parts_by_part.values())
        production_entry = {
            &#34;operation&#34;: op,
            &#34;target&#34;: target,
            &#34;produced_parts&#34;: total_produced,
            &#34;produced_parts_by_part&#34;: produced_parts_by_part,
            &#34;part_numbers&#34;: machine[&#34;part_numbers&#34;],
        }
    else:
        query_str = &#34;&#34;&#34;
            SELECT COUNT(*)
            FROM GFxPRoduction
            WHERE Machine = %s AND TimeStamp BETWEEN %s AND %s;
        &#34;&#34;&#34;
        cursor.execute(query_str, (machine_number, start_timestamp, end_timestamp))
        # Process the single result row.
        row = cursor.fetchone()
        total_produced = row[0] if row and row[0] is not None else 0
        production_entry = {
            &#34;operation&#34;: op,
            &#34;target&#34;: target,
            &#34;produced_parts&#34;: total_produced,
            &#34;part_numbers&#34;: None,
        }
    return production_entry</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.get_reject_data"><code class="name flex">
<span>def <span class="ident">get_reject_data</span></span>(<span>machine, start_timestamp, times, part_list)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_reject_data(machine, start_timestamp, times, part_list):
    &#34;&#34;&#34;
    Retrieve reject counts for a machine over specified time buckets.

    Constructs and executes a SQL query against the `01_vw_production_rejects` view,
    grouping reject records by Part and Reason into time buckets determined by `times`.

    Parameters
    ----------
    machine : str
        The base machine code; if it does not already end with &#34;REJ&#34;, &#34;REJ&#34; will be appended
        to target the reject-specific data.
    start_timestamp : int
        Unix epoch (seconds) marking the start of the analysis window.
    times : int or str
        A code indicating the desired bucketization:
          - 1–6: eight consecutive 1-hour buckets (hour1…hour8)
          - 7–8: three 8-hour shift buckets (shift1…shift3)
          - 9+: seven daily buckets (mon…sun)
    part_list : str or None
        A comma-separated, quoted list of part numbers for an SQL IN clause (e.g. `&#34;A&#34;,&#34;B&#34;,&#34;C&#34;`),
        or None/empty to include all parts.

    Returns
    -------
    list of list
        Each inner list corresponds to a row in the result set:
          [ Part (str), Reason (str), bucket1 (int), bucket2 (int), …, total (int) ]
        where `total` is the sum of the bucket counts for that Part+Reason.

    Notes
    -----
    - The SQL query filters `TimeStamp` between `start_timestamp` and the window end,
      calculated as:
        • +8 hours for times 1–6
        • +24 hours for times 7–8
        • +7 days for times 9+
    - A final “totals” row (with Part=&#34;Totals&#34;, Reason=&#34;&#34;) is appended, summing each bucket.
    &#34;&#34;&#34;
    if int(times) &lt;= 6:  # 8 hour query
        sql = &#39;SELECT Part, Reason, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp) + &#39; AND TimeStamp &lt;= &#39; + \
            str(start_timestamp + 3600) + &#39; THEN 1 ELSE 0 END) as hour1, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 3600) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 7200) + &#39; THEN 1 ELSE 0 END) as hour2, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 7200) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 10800) + &#39; THEN 1 ELSE 0 END) as hour3, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 10800) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 14400) + &#39; THEN 1 ELSE 0 END) as hour4, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 14400) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 18000) + &#39; THEN 1 ELSE 0 END) as hour5, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 18000) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 21600) + &#39; THEN 1 ELSE 0 END) as hour6, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 21600) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 25200) + &#39; THEN 1 ELSE 0 END) as hour7, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 25200) + &#39; THEN 1 ELSE 0 END) AS hour8 &#39;
        sql += &#39;FROM `01_vw_production_rejects` &#39;
        sql += &#39;WHERE TimeStamp &gt;= &#39; + \
            str(start_timestamp) + &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 28800) + &#39; &#39;
        if not machine.endswith(&#34;REJ&#34;):
            machine_for_query = machine + &#34;REJ&#34;
        else:
            machine_for_query = machine
        sql += &#39;AND Machine = &#34;&#39; + machine_for_query + &#39;&#34; &#39;

        if (part_list):
            sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
        sql += &#39;GROUP BY Part, Reason &#39;
        sql += &#39;ORDER BY Part ASC, Reason ASC;&#39;

    elif int(times) &lt;= 8:  # 24 hour by shift query
        sql = &#39;SELECT Part, Reason, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp) + &#39; AND TimeStamp &lt;= &#39; + \
            str(start_timestamp + 28800) + &#39; THEN 1 ELSE 0 END) as shift1, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 28800) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 57600) + &#39; THEN 1 ELSE 0 END) as shift2, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 57600) + &#39; THEN 1 ELSE 0 END) AS shift3 &#39;
        sql += &#39;FROM `01_vw_production_rejects` &#39;
        sql += &#39;WHERE TimeStamp &gt;= &#39; + \
            str(start_timestamp) + &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 86400) + &#39; &#39;
        if not machine.endswith(&#34;REJ&#34;):
            machine_for_query = machine + &#34;REJ&#34;
        else:
            machine_for_query = machine
        sql += &#39;AND Machine = &#34;&#39; + machine_for_query + &#39;&#34; &#39;

        if (part_list):
            sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
        sql += &#39;GROUP BY Part, Reason &#39;
        sql += &#39;ORDER BY Part ASC, Reason ASC;&#39;

    else:  # week at a time query
        sql = &#39;SELECT Part, Reason, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp) + &#39; AND TimeStamp &lt;= &#39; + \
            str(start_timestamp + 86400) + &#39; THEN 1 ELSE 0 END) as mon, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 86400) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 172800) + &#39; THEN 1 ELSE 0 END) as tue, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 172800) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 259200) + &#39; THEN 1 ELSE 0 END) as wed, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 259200) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 345600) + &#39; THEN 1 ELSE 0 END) as thur, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 345600) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 432000) + &#39; THEN 1 ELSE 0 END) as fri, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(start_timestamp + 432000) + \
            &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 518400) + &#39; THEN 1 ELSE 0 END) as sat, &#39;
        sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + \
            str(start_timestamp + 518400) + &#39; THEN 1 ELSE 0 END) AS sun &#39;
        sql += &#39;FROM `01_vw_production_rejects` &#39;
        sql += &#39;WHERE TimeStamp &gt;= &#39; + \
            str(start_timestamp) + &#39; AND TimeStamp &lt; &#39; + \
            str(start_timestamp + 604800) + &#39; &#39;
        if not machine.endswith(&#34;REJ&#34;):
            machine_for_query = machine + &#34;REJ&#34;
        else:
            machine_for_query = machine
        sql += &#39;AND Machine = &#34;&#39; + machine_for_query + &#39;&#34; &#39;

        if (part_list):
            sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
        sql += &#39;GROUP BY Part, Reason &#39;
        sql += &#39;ORDER BY Part ASC, Reason ASC;&#39;

    cursor = connections[&#39;prodrpt-md&#39;].cursor()
    # print(sql)
    try:
        cursor.execute(sql)
        result = cursor.fetchall()
        results = []
        for row in result:
            row = list(row)
            row.append(sum(row[2:]))
            results.append(row)

        if len(results):
            result_length = len(results[0])
            totals = [0] * result_length

            for row in results:
                for idx in range(2, result_length):
                    totals[idx] += row[idx]
            totals[0] = &#39;Totals&#39;
            totals[1] = &#39;&#39;
            results.append(totals)

    except Exception as e:
        print(&#34;Oops!&#34;, e, &#34;occurred.&#34;)
    finally:
        cursor.close()
    return results</code></pre>
</details>
<div class="desc"><p>Retrieve reject counts for a machine over specified time buckets.</p>
<p>Constructs and executes a SQL query against the <code>01_vw_production_rejects</code> view,
grouping reject records by Part and Reason into time buckets determined by <code>times</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>The base machine code; if it does not already end with "REJ", "REJ" will be appended
to target the reject-specific data.</dd>
<dt><strong><code>start_timestamp</code></strong> :&ensp;<code>int</code></dt>
<dd>Unix epoch (seconds) marking the start of the analysis window.</dd>
<dt><strong><code>times</code></strong> :&ensp;<code>int</code> or <code>str</code></dt>
<dd>A code indicating the desired bucketization:
- 1–6: eight consecutive 1-hour buckets (hour1…hour8)
- 7–8: three 8-hour shift buckets (shift1…shift3)
- 9+: seven daily buckets (mon…sun)</dd>
<dt><strong><code>part_list</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>A comma-separated, quoted list of part numbers for an SQL IN clause (e.g. <code>"A","B","C"</code>),
or None/empty to include all parts.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>list</code></dt>
<dd>Each inner list corresponds to a row in the result set:
[ Part (str), Reason (str), bucket1 (int), bucket2 (int), …, total (int) ]
where <code>total</code> is the sum of the bucket counts for that Part+Reason.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>The SQL query filters <code>TimeStamp</code> between <code>start_timestamp</code> and the window end,
calculated as:
• +8 hours for times 1–6
• +24 hours for times 7–8
• +7 days for times 9+</li>
<li>A final “totals” row (with Part="Totals", Reason="") is appended, summing each bucket.</li>
</ul></div>
</dd>
<dt id="prod_query.views.get_sc_production_data"><code class="name flex">
<span>def <span class="ident">get_sc_production_data</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sc_production_data(request):
    &#34;&#34;&#34;
    Handle SC production data queries and prepare Chart.js context.

    On GET:
      - Renders the &#39;prod_query/sc_production.html&#39; template with no chart.

    On POST:
      1. Reads form fields from `request.POST`:
         - `asset_num` (str/int): the asset number to query.
         - `start_date` (str, &#34;YYYY-MM-DD&#34;): start of date range.
         - `end_date` (str, &#34;YYYY-MM-DD&#34;): end of date range.
      2. Parses `start_date` and `end_date` into `datetime.date`.
      3. Connects to the MySQL database `prodrptdb` (host 10.4.1.224) using MySQLdb.
      4. Executes a query against `sc_production1` to select daily production:
           `SELECT pdate, actual_produced, shift
            FROM sc_production1
            WHERE asset_num = &lt;asset_num&gt;
              AND pdate BETWEEN &#39;&lt;start_date&gt;&#39; AND &#39;&lt;end_date&gt;&#39;
            ORDER BY pdate ASC;`
      5. Aggregates results into a dictionary keyed by date, accumulating:
         - `&#39;7am-3pm&#39;`, `&#39;3pm-11pm&#39;`, `&#39;11pm-7am&#39;` shift totals
         - `&#39;grand_total&#39;` across all shifts.
      6. Prepares Chart.js data structures:
         - `labels`: list of date strings (&#34;YYYY-MM-DD&#34;)
         - `data_by_shift`: dict mapping each shift (and grand_total) to its list of daily totals.
      7. Populates `context` with:
         - `labels`, `data_by_shift`
         - `asset_num`, `start_date`, `end_date`
         - `show_chart`: True to signal the template to render the chart.

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request. Expects POST form fields as described above.

    Returns
    -------
    django.http.HttpResponse
        Renders &#39;prod_query/sc_production.html&#39; with context including
        chart data on POST, or an empty context on GET.
    &#34;&#34;&#34;
    context = {}

    if request.method == &#39;POST&#39;:
        asset_num = request.POST.get(&#39;asset_num&#39;)
        start_date = request.POST.get(&#39;start_date&#39;)
        end_date = request.POST.get(&#39;end_date&#39;)

        start_date = datetime.strptime(start_date, &#39;%Y-%m-%d&#39;)
        end_date = datetime.strptime(end_date, &#39;%Y-%m-%d&#39;)

        db = MySQLdb.connect(
            host=&#34;10.4.1.224&#34;,
            user=&#34;stuser&#34;,
            passwd=&#34;stp383&#34;,
            db=&#34;prodrptdb&#34;
        )
        
        cursor = db.cursor()

        query = f&#34;&#34;&#34;
            SELECT pdate, actual_produced, shift
            FROM sc_production1
            WHERE asset_num = {asset_num}
            AND pdate BETWEEN &#39;{start_date}&#39; AND &#39;{end_date}&#39;
            ORDER BY pdate ASC;
        &#34;&#34;&#34;
        
        cursor.execute(query)
        rows = cursor.fetchall()

        cursor.close()
        db.close()

        # Initialize dictionary to store shift totals and grand totals by day
        daily_data = defaultdict(lambda: {&#39;7am-3pm&#39;: 0, &#39;3pm-11pm&#39;: 0, &#39;11pm-7am&#39;: 0, &#39;grand_total&#39;: 0})

        for row in rows:
            pdate, actual_produced, shift = row
            daily_data[pdate][shift] += actual_produced
            daily_data[pdate][&#39;grand_total&#39;] += actual_produced

        # Prepare data for Chart.js
        labels = [day.strftime(&#39;%Y-%m-%d&#39;) for day in daily_data.keys()]
        data_by_shift = {
            &#39;7am-3pm&#39;: [daily_data[day][&#39;7am-3pm&#39;] for day in daily_data],
            &#39;3pm-11pm&#39;: [daily_data[day][&#39;3pm-11pm&#39;] for day in daily_data],
            &#39;11pm-7am&#39;: [daily_data[day][&#39;11pm-7am&#39;] for day in daily_data],
            &#39;grand_total&#39;: [daily_data[day][&#39;grand_total&#39;] for day in daily_data]
        }

        context.update({
            &#39;labels&#39;: labels,
            &#39;data_by_shift&#39;: data_by_shift,
            &#39;asset_num&#39;: asset_num,
            &#39;start_date&#39;: start_date.strftime(&#39;%Y-%m-%d&#39;),
            &#39;end_date&#39;: end_date.strftime(&#39;%Y-%m-%d&#39;),
            &#39;show_chart&#39;: True  # Flag to show the chart
        })

    return render(request, &#39;prod_query/sc_production.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Handle SC production data queries and prepare Chart.js context.</p>
<p>On GET:
- Renders the 'prod_query/sc_production.html' template with no chart.</p>
<p>On POST:
1. Reads form fields from <code>request.POST</code>:
- <code>asset_num</code> (str/int): the asset number to query.
- <code>start_date</code> (str, "YYYY-MM-DD"): start of date range.
- <code>end_date</code> (str, "YYYY-MM-DD"): end of date range.
2. Parses <code>start_date</code> and <code>end_date</code> into <code>datetime.date</code>.
3. Connects to the MySQL database <code>prodrptdb</code> (host 10.4.1.224) using MySQLdb.
4. Executes a query against <code>sc_production1</code> to select daily production:
<code>SELECT pdate, actual_produced, shift
FROM sc_production1
WHERE asset_num = &lt;asset_num&gt;
AND pdate BETWEEN '&lt;start_date&gt;' AND '&lt;end_date&gt;'
ORDER BY pdate ASC;</code>
5. Aggregates results into a dictionary keyed by date, accumulating:
- <code>'7am-3pm'</code>, <code>'3pm-11pm'</code>, <code>'11pm-7am'</code> shift totals
- <code>'grand_total'</code> across all shifts.
6. Prepares Chart.js data structures:
- <code>labels</code>: list of date strings ("YYYY-MM-DD")
- <code>data_by_shift</code>: dict mapping each shift (and grand_total) to its list of daily totals.
7. Populates <code>context</code> with:
- <code>labels</code>, <code>data_by_shift</code>
- <code>asset_num</code>, <code>start_date</code>, <code>end_date</code>
- <code>show_chart</code>: True to signal the template to render the chart.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request. Expects POST form fields as described above.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders 'prod_query/sc_production.html' with context including
chart data on POST, or an empty context on GET.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_sc_production_data_v2"><code class="name flex">
<span>def <span class="ident">get_sc_production_data_v2</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sc_production_data_v2(request):
    &#34;&#34;&#34;
    Retrieve and return weekly SC production data by shift for a given asset.

    On GET:
      - Renders the &#39;prod_query/sc_production_v2.html&#39; template with a date-selection form.

    On POST:
      1. Reads from `request.POST`:
         - `asset_num` (str/int): the asset number to query.
         - `selected_date` (str, &#34;YYYY-MM-DD&#34;): any date within the target week.
      2. Parses `selected_date` into a `datetime.date` and computes the preceding Sunday.
      3. Defines the production window from Sunday at 11:00 PM through the following Saturday at 11:00 PM.
      4. Queries the `sc_production1` table for rows where:
           `asset_num = &lt;asset_num&gt;` AND
           `pdate BETWEEN &lt;start_date 23:00:00&gt; AND &lt;end_date 23:00:00&gt;`.
      5. Aggregates `actual_produced` totals per day and per shift:
         - Shifts: &#39;7am-3pm&#39;, &#39;3pm-11pm&#39;, &#39;11pm-7am&#39;
      6. Builds two parallel lists:
         - `labels`: strings like &#34;YYYY-MM-DD 7am-3pm&#34;
         - `totals`: corresponding production totals.
      7. Returns a JSON response:
           {
             &#39;selected_date&#39;: &lt;week’s reference date&gt;,
             &#39;labels&#39;: [...],
             &#39;totals&#39;: [...]
           }

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request. For POST, expects form fields `asset_num` and `selected_date`.

    Returns
    -------
    django.http.HttpResponse or django.http.JsonResponse
        - On GET: renders the selection form.
        - On POST: returns JSON with keys `selected_date`, `labels`, and `totals`.
    &#34;&#34;&#34;
    if request.method == &#39;POST&#39;:
        asset_num = request.POST.get(&#39;asset_num&#39;)
        selected_date = request.POST.get(&#39;selected_date&#39;)

        # Convert the selected date and find the Sunday of that week
        selected_date = datetime.strptime(selected_date, &#39;%Y-%m-%d&#39;)
        start_of_week = selected_date - timedelta(days=selected_date.weekday() + 1)  # Find the previous Sunday

        # The production starts from Sunday at 11pm-7am shift (so the actual production start time is 11pm Sunday)
        start_date = start_of_week + timedelta(hours=23)  # Sunday at 11pm
        end_date = start_date + timedelta(days=6, hours=23)  # End date is Saturday at 11pm

        # Connect to the database
        db = MySQLdb.connect(
            host=&#34;10.4.1.224&#34;,
            user=&#34;stuser&#34;,
            passwd=&#34;stp383&#34;,
            db=&#34;prodrptdb&#34;
        )
        
        cursor = db.cursor()

        # Query to get the production data for the entire week starting from Sunday 11pm
        query = f&#34;&#34;&#34;
            SELECT pdate, actual_produced, shift
            FROM sc_production1
            WHERE asset_num = {asset_num}
            AND pdate BETWEEN &#39;{start_date.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)}&#39; AND &#39;{end_date.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)}&#39;
            ORDER BY pdate ASC;
        &#34;&#34;&#34;
        
        cursor.execute(query)
        rows = cursor.fetchall()

        cursor.close()
        db.close()

        # Prepare the labels and data for Chart.js
        shift_intervals = [&#39;7am-3pm&#39;, &#39;3pm-11pm&#39;, &#39;11pm-7am&#39;]
        labels = []  # To store shift + date labels (e.g., &#39;2024-10-09 7am-3pm&#39;)
        totals = []  # To store the actual production totals for each shift

        # Initialize the dictionary for shift totals
        current_day = start_date.date()  # Only consider the date part for day changes
        daily_data = {shift: 0 for shift in shift_intervals}  # Store totals for each shift per day

        for row in rows:
            pdate, actual_produced, shift = row

            # No need for .date() since pdate is already a date object
            row_date = pdate

            # Check if the day changes, if yes, append the totals for the previous day
            if row_date != current_day:
                for shift_interval in shift_intervals:
                    if not (current_day == start_of_week.date() and shift_interval in [&#39;7am-3pm&#39;, &#39;3pm-11pm&#39;]):
                        labels.append(f&#34;{current_day.strftime(&#39;%Y-%m-%d&#39;)} {shift_interval}&#34;)
                        totals.append(daily_data[shift_interval])
                
                current_day = row_date  # Move to the new day
                daily_data = {shift: 0 for shift in shift_intervals}  # Reset for the new day

            # Add the production data to the correct shift
            daily_data[shift] += actual_produced

        # Append data for the final day
        for shift_interval in shift_intervals:
            if not (current_day == start_of_week.date() and shift_interval in [&#39;7am-3pm&#39;, &#39;3pm-11pm&#39;]):
                labels.append(f&#34;{current_day.strftime(&#39;%Y-%m-%d&#39;)} {shift_interval}&#34;)
                totals.append(daily_data[shift_interval])

        # Return the data as JSON
        return JsonResponse({
            &#39;selected_date&#39;: selected_date.strftime(&#39;%Y-%m-%d&#39;),
            &#39;labels&#39;: labels,
            &#39;totals&#39;: totals
        })

    # If it&#39;s a GET request, render the form page
    return render(request, &#39;prod_query/sc_production_v2.html&#39;)</code></pre>
</details>
<div class="desc"><p>Retrieve and return weekly SC production data by shift for a given asset.</p>
<p>On GET:
- Renders the 'prod_query/sc_production_v2.html' template with a date-selection form.</p>
<p>On POST:
1. Reads from <code>request.POST</code>:
- <code>asset_num</code> (str/int): the asset number to query.
- <code>selected_date</code> (str, "YYYY-MM-DD"): any date within the target week.
2. Parses <code>selected_date</code> into a <code>datetime.date</code> and computes the preceding Sunday.
3. Defines the production window from Sunday at 11:00 PM through the following Saturday at 11:00 PM.
4. Queries the <code>sc_production1</code> table for rows where:
<code>asset_num = &lt;asset_num&gt;</code> AND
<code>pdate BETWEEN &lt;start_date 23:00:00&gt; AND &lt;end_date 23:00:00&gt;</code>.
5. Aggregates <code>actual_produced</code> totals per day and per shift:
- Shifts: '7am-3pm', '3pm-11pm', '11pm-7am'
6. Builds two parallel lists:
- <code>labels</code>: strings like "YYYY-MM-DD 7am-3pm"
- <code>totals</code>: corresponding production totals.
7. Returns a JSON response:
{
'selected_date': <week’s reference date>,
'labels': [&hellip;],
'totals': [&hellip;]
}</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request. For POST, expects form fields <code>asset_num</code> and <code>selected_date</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code> or <code>django.http.JsonResponse</code></dt>
<dd>
<ul>
<li>On GET: renders the selection form.</li>
<li>On POST: returns JSON with keys <code>selected_date</code>, <code>labels</code>, and <code>totals</code>.</li>
</ul>
</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_sunday_to_friday_ranges"><code class="name flex">
<span>def <span class="ident">get_sunday_to_friday_ranges</span></span>(<span>first_day, last_day)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sunday_to_friday_ranges(first_day, last_day):
    &#34;&#34;&#34;
    Split a date window into contiguous Sunday-to-Friday sub-ranges.

    Starting from `first_day`, this function finds the first Friday on or after
    the start, then produces:
      1. An initial partial range from `first_day` up to that first Friday at 23:00.
      2. Full weeks from each subsequent Sunday at 23:00 through the following Friday at 23:00.
      3. A final partial range from the last Sunday before or on `last_day` at 23:00
         up to `last_day` (if it does not already end on a Friday range).

    All datetimes in the returned ranges have their time components set to 23:00:00.

    Parameters
    ----------
    first_day : datetime.datetime
        The start of the overall window.
    last_day : datetime.datetime
        The end of the overall window.

    Returns
    -------
    list of tuple(datetime.datetime, datetime.datetime)
        A list of `(start, end)` tuples covering every day from `first_day` to
        `last_day`, segmented into Sunday-through-Friday blocks as described.
    &#34;&#34;&#34;
    ranges = []
    first_friday = first_day
    while first_friday.weekday() != 4:
        first_friday += timedelta(days=1)
    first_friday = first_friday.replace(hour=23, minute=0, second=0)
    if first_day &lt; first_friday:
        ranges.append((first_day, first_friday))
    current_start = first_friday + timedelta(days=2) 
    current_start = current_start.replace(hour=23, minute=0, second=0)
    while current_start + timedelta(days=5) &lt;= last_day:
        current_end = current_start + timedelta(days=5)
        current_end = current_end.replace(hour=23, minute=0, second=0)
        ranges.append((current_start, current_end))
        current_start += timedelta(days=7)
    if last_day.weekday() != 6:
        if ranges and ranges[-1][1] &lt; last_day:
            last_sunday = last_day
            while last_sunday.weekday() != 6:
                last_sunday -= timedelta(days=1)
            last_sunday = last_sunday.replace(hour=23, minute=0, second=0)
            if last_sunday &gt; ranges[-1][1]:
                ranges.append((last_sunday, last_day))
    return ranges</code></pre>
</details>
<div class="desc"><p>Split a date window into contiguous Sunday-to-Friday sub-ranges.</p>
<p>Starting from <code>first_day</code>, this function finds the first Friday on or after
the start, then produces:
1. An initial partial range from <code>first_day</code> up to that first Friday at 23:00.
2. Full weeks from each subsequent Sunday at 23:00 through the following Friday at 23:00.
3. A final partial range from the last Sunday before or on <code>last_day</code> at 23:00
up to <code>last_day</code> (if it does not already end on a Friday range).</p>
<p>All datetimes in the returned ranges have their time components set to 23:00:00.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>first_day</code></strong> :&ensp;<code>datetime.datetime</code></dt>
<dd>The start of the overall window.</dd>
<dt><strong><code>last_day</code></strong> :&ensp;<code>datetime.datetime</code></dt>
<dd>The end of the overall window.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>tuple(datetime.datetime, datetime.datetime)</code></dt>
<dd>A list of <code>(start, end)</code> tuples covering every day from <code>first_day</code> to
<code>last_day</code>, segmented into Sunday-through-Friday blocks as described.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_sunday_to_friday_ranges_custom"><code class="name flex">
<span>def <span class="ident">get_sunday_to_friday_ranges_custom</span></span>(<span>start_date, end_date)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sunday_to_friday_ranges_custom(start_date, end_date):
    &#34;&#34;&#34;
    Generates Sunday 11 PM to Friday 11 PM blocks for a given time interval.

    Args:
        start_date (datetime): The start of the interval.
        end_date (datetime): The end of the interval.

    Returns:
        list of tuples: Each tuple contains the start and end of a time block.
    &#34;&#34;&#34;
    ranges = []

    # Check if the start date is within a Sunday-to-Friday block
    if start_date.weekday() &lt;= 4:  # If it&#39;s between Sunday and Friday
        # Add a partial block to the upcoming Friday
        current_start = add_partial_block_to_friday(start_date, ranges)
    else:
        # Find the first Sunday at 11 PM if start_date is outside a Sunday-to-Friday range
        current_start = find_first_sunday(start_date)

    # Calculate full Sunday-to-Friday blocks
    current_start = calculate_full_blocks(current_start, end_date, ranges)

    # Handle any remaining days
    handle_remaining_days(current_start, end_date, ranges)

    return ranges</code></pre>
</details>
<div class="desc"><p>Generates Sunday 11 PM to Friday 11 PM blocks for a given time interval.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start_date</code></strong> :&ensp;<code>datetime</code></dt>
<dd>The start of the interval.</dd>
<dt><strong><code>end_date</code></strong> :&ensp;<code>datetime</code></dt>
<dd>The end of the interval.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>tuples</code></dt>
<dd>Each tuple contains the start and end of a time block.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.get_total_produced_last_op_for_block"><code class="name flex">
<span>def <span class="ident">get_total_produced_last_op_for_block</span></span>(<span>operations)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_total_produced_last_op_for_block(operations):
    &#34;&#34;&#34;
    Determine the production count from the last operation in a block.

    This function inspects an `operations` dict—where keys are operation identifiers
    and values are sub-dicts potentially containing a `&#39;totals&#39;` entry—and returns
    the `total_produced` value for the highest‐ordered operation. It excludes the
    special `&#39;line_totals&#39;` key, sorts remaining operation keys numerically when
    possible (falling back to lexicographical order), and retrieves the production
    count from that final operation&#39;s totals.

    Parameters
    ----------
    operations : dict
        A mapping of operation identifiers (str) to data dicts. Each data dict
        may include a `&#39;totals&#39;` dict with a `&#39;total_produced&#39;` numeric field.

    Returns
    -------
    int
        The `total_produced` from the last-sorted operation, or 0 if:
          - there are no valid operations,
          - the chosen operation lacks a `&#39;totals&#39;` or `&#39;total_produced&#39;`,
          - any error occurs during processing.
    &#34;&#34;&#34;
    try:
        valid_operations = [op for op in operations.keys() if op != &#39;line_totals&#39;]
        if valid_operations:
            try:
                # Sort using numeric values if possible, fallback to string sorting
                last_op = sorted(valid_operations, key=lambda x: int(x) if x.isdigit() else x)[-1]
            except ValueError as ve:
                print(f&#34;ValueError during sorting operations: {ve}&#34;)
                last_op = sorted(valid_operations, key=str)[-1]  # Fallback to string sorting

            produced = 0
            if &#39;totals&#39; in operations[last_op]:
                produced = operations[last_op][&#39;totals&#39;].get(&#39;total_produced&#39;, 0)
            return produced
        return 0
    except Exception as e:
        print(f&#34;Error in get_total_produced_last_op_for_block: {e}&#34;)
        return 0</code></pre>
</details>
<div class="desc"><p>Determine the production count from the last operation in a block.</p>
<p>This function inspects an <code>operations</code> dict—where keys are operation identifiers
and values are sub-dicts potentially containing a <code>'totals'</code> entry—and returns
the <code>total_produced</code> value for the highest‐ordered operation. It excludes the
special <code>'line_totals'</code> key, sorts remaining operation keys numerically when
possible (falling back to lexicographical order), and retrieves the production
count from that final operation's totals.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>operations</code></strong> :&ensp;<code>dict</code></dt>
<dd>A mapping of operation identifiers (str) to data dicts. Each data dict
may include a <code>'totals'</code> dict with a <code>'total_produced'</code> numeric field.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The <code>total_produced</code> from the last-sorted operation, or 0 if:
- there are no valid operations,
- the chosen operation lacks a <code>'totals'</code> or <code>'total_produced'</code>,
- any error occurs during processing.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.gfx_downtime_and_produced_view"><code class="name flex">
<span>def <span class="ident">gfx_downtime_and_produced_view</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@csrf_exempt
def gfx_downtime_and_produced_view(request):
    &#34;&#34;&#34;
    POST Parameters expected:
      - machines: JSON list of machine numbers (e.g. [&#34;1723&#34;, &#34;1703R&#34;, ...])
      - line: The name of the line (e.g. &#34;AB1V Reaction&#34;)
      - start_date: ISO8601 date string (UTC or including &#34;Z&#34;)
    
    1) Validates the request and converts start_date to EST.
    2) Determines end_date (start_date + 5 days or now, whichever is earlier).
    3) Converts both start/end to timestamps in EST.
    4) Dynamically looks up part numbers for each machine based on the given line, 
       storing them in a dictionary: machine_parts[machine_id] = [part_1, part_2, ...].
    5) Fetches the “most recent target” for each machine from the database 
       (table: OAMachineTargets) as of that start_date.
    6) Calls your existing calculate_downtime(...) and calculate_total_produced(...)
       for each machine, passing the relevant part numbers to calculate_total_produced.
    7) Scales the machine targets for the partial week and returns all data as JSON.
    &#34;&#34;&#34;
    if request.method == &#34;POST&#34;:
        start_time = time.time()  # Record the start time
        
        try:
            # 1. Parse input data
            machines = json.loads(request.POST.get(&#39;machines&#39;, &#39;[]&#39;))
            line_name = request.POST.get(&#39;line&#39;)  # The line name
            start_date_str = request.POST.get(&#39;start_date&#39;)

            # Basic validation
            if not machines:
                return JsonResponse({&#39;error&#39;: &#39;No machine numbers provided&#39;}, status=400)
            if not start_date_str:
                return JsonResponse({&#39;error&#39;: &#39;Start date is required.&#39;}, status=400)
            if not line_name:
                return JsonResponse({&#39;error&#39;: &#39;Line is required.&#39;}, status=400)

            # 2. Parse and validate start_date (making it timezone-aware in EST)
            try:
                if start_date_str.endswith(&#39;Z&#39;):
                    # Convert trailing &#39;Z&#39; to &#39;+00:00&#39; if needed
                    start_date_str = start_date_str.replace(&#39;Z&#39;, &#39;+00:00&#39;)
                start_date = datetime.fromisoformat(start_date_str)

                # If no timezone, assume it&#39;s UTC and make it aware
                if start_date.tzinfo is None:
                    start_date = timezone.make_aware(start_date, timezone=timezone.utc)

                # Convert to EST
                est_timezone = pytz.timezone(&#39;America/New_York&#39;)
                start_date_est = start_date.astimezone(est_timezone)

                # end_date = min( (start_date + 5 days), now )
                end_date_candidate = start_date_est + timedelta(days=5)
                now_est = timezone.now().astimezone(est_timezone)
                end_date_est = min(end_date_candidate, now_est)
            except ValueError:
                print(f&#34;Invalid start date format: {start_date_str}&#34;)
                return JsonResponse({&#39;error&#39;: &#39;Invalid start date format.&#39;}, status=400)

            # Convert these to timestamps in EST
            start_timestamp = int(start_date_est.timestamp())
            end_timestamp = int(end_date_est.timestamp())

            # 3. Calculate total potential minutes
            total_potential_minutes_per_machine = (end_timestamp - start_timestamp) / 60.0

            # 4. Look up line-specific part numbers for each machine
            machine_parts = {}  # { &#34;1723&#34;: [&#34;50-0450&#34;,&#34;50-8670&#34;], ... }
            matching_line = next((l for l in lines if l[&#34;line&#34;] == line_name), None)
            if matching_line:
                # For each operation in this line, capture part_numbers for the machines in &#39;machines&#39;
                for operation in matching_line[&#34;operations&#34;]:
                    for m in operation[&#34;machines&#34;]:
                        m_num = m[&#34;number&#34;]
                        if m_num in machines:
                            # If the JSON has a &#34;part_numbers&#34; key, use it; else default to []
                            part_nums = m.get(&#34;part_numbers&#34;, [])
                            machine_parts[m_num] = part_nums
            else:
                # If line not found, machine_parts stays empty -&gt; produced will be 0
                pass

            # 5. Query the DB for machine targets for the selected line
            machine_targets = {}
            for machine in machines:
                most_recent_target = (
                    OAMachineTargets.objects.filter(
                        machine_id=machine,
                        line=line_name,
                        effective_date_unix__lte=start_timestamp
                    )
                    .order_by(&#39;-effective_date_unix&#39;)
                    .first()
                )

                if most_recent_target:
                    machine_targets[machine] = most_recent_target.target
                else:
                    machine_targets[machine] = 0  # Default to 0 if no target found

            # 6. Loop over machines, compute downtime and produced
            downtime_results = []
            produced_results = []
            total_downtime = 0
            total_produced = 0

            with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
                for machine in machines:
                    # Downtime threshold from your dict, default 5
                    downtime_threshold = MACHINE_THRESHOLDS.get(machine, 5)

                    # a) calculate_downtime
                    #    (If you also want downtime to filter by part, pass machine_parts[machine] instead of None)
                    machine_downtime = calculate_downtime(
                        machine=machine,
                        cursor=cursor,
                        start_timestamp=start_timestamp,
                        end_timestamp=end_timestamp,
                        downtime_threshold=downtime_threshold,
                        machine_parts=None  # or machine_parts.get(machine, [])
                    )
                    downtime_results.append({&#39;machine&#39;: machine, &#39;downtime&#39;: machine_downtime})
                    total_downtime += machine_downtime

                    # b) calculate_total_produced (pass the part numbers if present)
                    relevant_parts = machine_parts.get(machine, [])
                    machine_total_produced = calculate_total_produced(
                        machine=machine,
                        machine_parts=relevant_parts,
                        start_timestamp=start_timestamp,
                        end_timestamp=end_timestamp,
                        cursor=cursor
                    )
                    produced_results.append({&#39;machine&#39;: machine, &#39;produced&#39;: machine_total_produced})
                    total_produced += machine_total_produced

            # 7. Prepare scaled/adjusted targets per machine
            adjusted_machine_targets = {}
            # 7200 minutes in a full week (12x5 shifts or 24x5 days, etc. in your logic)
            full_week_minutes = 7200
            scaling_factor = total_potential_minutes_per_machine / full_week_minutes

            for machine in machines:
                original_target = machine_targets.get(machine, 0)
                adjusted_original_target = original_target * scaling_factor
                adjusted_machine_targets[machine] = {
                    &#39;original_target&#39;: original_target,
                    &#39;adjusted_original_target&#39;: adjusted_original_target
                }

            # 8. Build final JSON response
            end_time = time.time()
            elapsed_time = end_time - start_time
            print(f&#34;Processing complete. Total elapsed time: {elapsed_time:.2f} seconds.&#34;)

            return JsonResponse({
                &#39;downtime_results&#39;: downtime_results,
                &#39;total_downtime&#39;: total_downtime,
                &#39;produced_results&#39;: produced_results,
                &#39;total_produced&#39;: total_produced,
                &#39;total_potential_minutes_per_machine&#39;: total_potential_minutes_per_machine,
                &#39;elapsed_time&#39;: f&#34;{elapsed_time:.2f} seconds&#34;,
                &#39;machine_targets&#39;: adjusted_machine_targets,
                &#39;start_date&#39;: start_date_est.strftime(&#39;%Y-%m-%d %H:%M:%S %Z&#39;),  # Formatted EST start date
                &#39;end_date&#39;: end_date_est.strftime(&#39;%Y-%m-%d %H:%M:%S %Z&#39;)       # Formatted EST end date
            })

        except Exception as e:
            # Catch any unhandled exceptions
            print(f&#34;Unhandled error in gfx_downtime_and_produced_view: {str(e)}&#34;)
            return JsonResponse({&#39;error&#39;: str(e)}, status=500)

    # If GET or another method, return a simple message
    return JsonResponse({&#39;message&#39;: &#39;Send machine details via POST&#39;}, status=200)</code></pre>
</details>
<div class="desc"><p>POST Parameters expected:
- machines: JSON list of machine numbers (e.g. ["1723", "1703R", &hellip;])
- line: The name of the line (e.g. "AB1V Reaction")
- start_date: ISO8601 date string (UTC or including "Z")</p>
<p>1) Validates the request and converts start_date to EST.
2) Determines end_date (start_date + 5 days or now, whichever is earlier).
3) Converts both start/end to timestamps in EST.
4) Dynamically looks up part numbers for each machine based on the given line,
storing them in a dictionary: machine_parts[machine_id] = [part_1, part_2, &hellip;].
5) Fetches the “most recent target” for each machine from the database
(table: OAMachineTargets) as of that start_date.
6) Calls your existing calculate_downtime(&hellip;) and calculate_total_produced(&hellip;)
for each machine, passing the relevant part numbers to calculate_total_produced.
7) Scales the machine targets for the partial week and returns all data as JSON.</p></div>
</dd>
<dt id="prod_query.views.handle_remaining_days"><code class="name flex">
<span>def <span class="ident">handle_remaining_days</span></span>(<span>current_start, end_date, ranges)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def handle_remaining_days(current_start, end_date, ranges):
    &#34;&#34;&#34;
    Handle the remaining days if the interval ends before the next Sunday.

    This function calculates the last partial block from the most recent Sunday 
    (at 11 PM) before `current_start` to the `end_date` (adjusted to 11 PM), 
    and appends it to the `ranges` list.

    Parameters:
        current_start (datetime): The current start time to evaluate.
        end_date (datetime): The end date of the range to handle.
        ranges (list): A list to which the partial block (tuple) will be appended.

    Returns:
        None. The function modifies the `ranges` list in place.

    Example:
        If current_start is 2025-01-19 23:00:00 (Sunday),
        and end_date is 2025-01-23 23:00:00 (Wednesday), 
        the function will append:
        - (2025-01-19 23:00:00, 2025-01-23 23:00:00) to the ranges list.
    &#34;&#34;&#34;
    # Check if there is a valid range to handle
    if current_start &lt;= end_date:
        # Find the most recent Sunday before or on current_start
        last_sunday = current_start
        while last_sunday.weekday() != 6:  # weekday() == 6 means Sunday
            last_sunday -= timedelta(days=1)  # Move backward one day at a time

        # Adjust the last Sunday&#39;s time to 11 PM
        last_sunday = last_sunday.replace(hour=23, minute=0, second=0)

        # Add the partial block if the range is valid (last_sunday is before or on end_date)
        if last_sunday &lt;= end_date:
            ranges.append((last_sunday, end_date.replace(hour=23, minute=0, second=0)))</code></pre>
</details>
<div class="desc"><p>Handle the remaining days if the interval ends before the next Sunday.</p>
<p>This function calculates the last partial block from the most recent Sunday
(at 11 PM) before <code>current_start</code> to the <code>end_date</code> (adjusted to 11 PM),
and appends it to the <code>ranges</code> list.</p>
<h2 id="parameters">Parameters</h2>
<p>current_start (datetime): The current start time to evaluate.
end_date (datetime): The end date of the range to handle.
ranges (list): A list to which the partial block (tuple) will be appended.</p>
<h2 id="returns">Returns</h2>
<p>None. The function modifies the <code>ranges</code> list in place.</p>
<h2 id="example">Example</h2>
<p>If current_start is 2025-01-19 23:00:00 (Sunday),
and end_date is 2025-01-23 23:00:00 (Wednesday),
the function will append:
- (2025-01-19 23:00:00, 2025-01-23 23:00:00) to the ranges list.</p></div>
</dd>
<dt id="prod_query.views.machine_detail"><code class="name flex">
<span>def <span class="ident">machine_detail</span></span>(<span>request, machine, start_timestamp, times)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def machine_detail(request, machine, start_timestamp, times):
    &#34;&#34;&#34;
    Render detailed production and reject statistics for a single machine.

    Given a machine identifier (optionally with a &#34;REJ&#34; suffix for rejects),
    a Unix epoch start time, and a time-window code, this view:
      1. Measures execution time.
      2. Retrieves reject data via `get_reject_data(machine, start_timestamp, times, part_list)`.
      3. Normalizes the machine name by stripping &#34;REJ&#34; (if present) and retrieves
         production data via `get_production_data(clean_machine, start_timestamp, times, part_list)`.
      4. Computes pagination offsets (`pagerprev`, `pagernext`) based on the window length:
         - 1–6: 8-hour window
         - 7–8: 24-hour window
         - 9+: 7-day window
      5. Formats `start_dt` and `end_dt` as human-readable strings.
      6. Populates context keys:
         - `title`: f&#34;{machine} Detail&#34;
         - `machine`: original identifier
         - `reject_data`, `production_data`
         - `ts`: integer start timestamp
         - `times`: integer time-window code
         - `elapsed`: seconds taken to gather data
         - `pagerprev`, `pagernext`: epoch offsets for navigation
         - `start_dt`, `end_dt`: formatted window boundaries

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request, possibly including a GET parameter `parts`.
    machine : str
        The machine code to query; may include &#34;REJ&#34; to indicate reject data.
    start_timestamp : int or str
        The Unix epoch (in seconds) of the window’s start.
    times : int or str
        A time-window code determining the window length:
          • 1–6: eight-hour shift
          • 7–8: 24-hour shift
          • 9+: one-week span

    Returns
    -------
    django.http.HttpResponse
        Renders &#39;prod_query/machine_detail.html&#39; with the populated context.
    &#34;&#34;&#34;
    tic = time.time()
    part_list = request.GET.get(&#39;parts&#39;)
    context = {}
    context[&#39;title&#39;] = f&#39;{machine} Detail&#39;
    context[&#39;machine&#39;] = machine
    context[&#39;reject_data&#39;] = get_reject_data(
        machine, start_timestamp, times, part_list)
    
    # Remove &#34;REJ&#34; from machine only if it exists
    clean_machine = machine
    if &#34;REJ&#34; in machine:
        clean_machine = machine.replace(&#34;REJ&#34;, &#34;&#34;)

    context[&#39;production_data&#39;] = get_production_data(
        clean_machine, start_timestamp, times, part_list)
    context[&#39;ts&#39;] = int(start_timestamp)
    context[&#39;times&#39;] = int(times)
    context[&#39;elapsed&#39;] = time.time() - tic

    if (times &lt;= 6):
        window_length = 60*60*8
    elif (times &lt;= 8):
        window_length = 60*60*24
    else:
        window_length = 60*60*24*7

    context[&#39;pagerprev&#39;] = start_timestamp - window_length
    context[&#39;pagernext&#39;] = start_timestamp + window_length
    context[&#39;start_dt&#39;] = datetime.fromtimestamp(
        int(start_timestamp)).strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)
    context[&#39;end_dt&#39;] = datetime.fromtimestamp(
        int(start_timestamp + window_length)).strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)
    
    # print(context[&#39;elapsed&#39;])

    return render(request, &#39;prod_query/machine_detail.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Render detailed production and reject statistics for a single machine.</p>
<p>Given a machine identifier (optionally with a "REJ" suffix for rejects),
a Unix epoch start time, and a time-window code, this view:
1. Measures execution time.
2. Retrieves reject data via <code><a title="prod_query.views.get_reject_data" href="#prod_query.views.get_reject_data">get_reject_data()</a>(machine, start_timestamp, times, part_list)</code>.
3. Normalizes the machine name by stripping "REJ" (if present) and retrieves
production data via <code><a title="prod_query.views.get_production_data" href="#prod_query.views.get_production_data">get_production_data()</a>(clean_machine, start_timestamp, times, part_list)</code>.
4. Computes pagination offsets (<code>pagerprev</code>, <code>pagernext</code>) based on the window length:
- 1–6: 8-hour window
- 7–8: 24-hour window
- 9+: 7-day window
5. Formats <code>start_dt</code> and <code>end_dt</code> as human-readable strings.
6. Populates context keys:
- <code>title</code>: f"{machine} Detail"
- <code>machine</code>: original identifier
- <code>reject_data</code>, <code>production_data</code>
- <code>ts</code>: integer start timestamp
- <code>times</code>: integer time-window code
- <code>elapsed</code>: seconds taken to gather data
- <code>pagerprev</code>, <code>pagernext</code>: epoch offsets for navigation
- <code>start_dt</code>, <code>end_dt</code>: formatted window boundaries</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request, possibly including a GET parameter <code>parts</code>.</dd>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>The machine code to query; may include "REJ" to indicate reject data.</dd>
<dt><strong><code>start_timestamp</code></strong> :&ensp;<code>int</code> or <code>str</code></dt>
<dd>The Unix epoch (in seconds) of the window’s start.</dd>
<dt><strong><code>times</code></strong> :&ensp;<code>int</code> or <code>str</code></dt>
<dd>A time-window code determining the window length:
• 1–6: eight-hour shift
• 7–8: 24-hour shift
• 9+: one-week span</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders 'prod_query/machine_detail.html' with the populated context.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.machine_oee"><code class="name flex">
<span>def <span class="ident">machine_oee</span></span>(<span>request: django.http.request.HttpRequest)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def machine_oee(request: HttpRequest):
    import datetime
    &#34;&#34;&#34;
    A simplified OEE page: accepts GET params
      - start_date (Y-m-d H:i)
      - end_date   (Y-m-d H:i)
      - machines   (comma-separated list, e.g. &#34;1703R,12L&#34;)
    Calls your existing `fetch_combined_oee_production_data` to build all data,
    then filters out only the requested machines and passes them to a simple template.
    &#34;&#34;&#34;
    # — parse machine list —
    machines_param = request.GET.get(&#39;machines&#39;, &#39;&#39;)
    machine_list = [m.strip() for m in machines_param.split(&#39;,&#39;) if m.strip()]

    # — default dates: yesterday@7am → today@7am —
    now = datetime.datetime.now()
    default_end = now.replace(hour=7, minute=0, second=0, microsecond=0)
    if now &lt; default_end:
        default_end -= datetime.timedelta(days=1)
    default_start = default_end - datetime.timedelta(days=1)

    start_date = request.GET.get(&#39;start_date&#39;, default_start.strftime(&#39;%Y-%m-%d %H:%M&#39;))
    end_date   = request.GET.get(&#39;end_date&#39;,   default_end.strftime(&#39;%Y-%m-%d %H:%M&#39;))

    # — call your JSON-producing view to get all the data —
    #    we just need the Python dict it builds:
    fake_req = HttpRequest()
    fake_req.method = &#39;GET&#39;
    fake_req.GET = request.GET.copy()
    json_resp = fetch_combined_oee_production_data(fake_req)
    all_data = json.loads(json_resp.content.decode())

    # — filter production_data for only the machines we care about —
    prod = all_data.get(&#39;production_data&#39;, {})
    results = []

    for line_name, machines in prod.items():
        for mnum, mdata in machines.items():
            # only include machines the user asked for (or all if none specified)
            if not machine_list or mnum in machine_list:
                # 1) figure out which operation this machine belongs to
                op_name = None
                for ln in lines:
                    if ln[&#39;line&#39;] == line_name:
                        for op in ln.get(&#39;operations&#39;, []):
                            if any(str(m[&#39;number&#39;]) == str(mnum) for m in op.get(&#39;machines&#39;, [])):
                                op_name = op[&#39;op&#39;]
                                break
                        if op_name:
                            break

                # 2) scale your precomputed fractions to actual percentages
                mdata[&#39;P&#39;]  = mdata.get(&#39;P&#39;, 0)  * 100
                mdata[&#39;A&#39;]  = mdata.get(&#39;A&#39;, 0)  * 100
                mdata[&#39;PA&#39;] = mdata.get(&#39;PA&#39;, 0) * 100

                # 3) collect into your final list
                results.append({
                    &#39;machine&#39;:   mnum,
                    &#39;operation&#39;: op_name,
                    **mdata
                })


    return render(request, &#39;prod_query/machine_oee.html&#39;, {
        &#39;start_date&#39;:       start_date,
        &#39;end_date&#39;:         end_date,
        &#39;machines_param&#39;:   machines_param,
        &#39;machine_data_list&#39;: results,
    })</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.moving_average"><code class="name flex">
<span>def <span class="ident">moving_average</span></span>(<span>data, window_size)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def moving_average(data, window_size):
    &#34;&#34;&#34;
    Calculate the moving average of a list of numbers.
    
    Parameters:
    - data: list of numbers
    - window_size: int, size of the moving average window
    
    Returns:
    - list of moving average values
    &#34;&#34;&#34;
    return np.convolve(data, np.ones(window_size) / window_size, mode=&#39;valid&#39;).tolist()</code></pre>
</details>
<div class="desc"><p>Calculate the moving average of a list of numbers.</p>
<p>Parameters:
- data: list of numbers
- window_size: int, size of the moving average window</p>
<p>Returns:
- list of moving average values</p></div>
</dd>
<dt id="prod_query.views.oa_by_day"><code class="name flex">
<span>def <span class="ident">oa_by_day</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def oa_by_day(request):
    &#34;&#34;&#34;
    Render the production data page with an inline range calendar.
    The default is set so that the start_date is yesterday at 7am and the end_date is today at 7am.
    &#34;&#34;&#34;
    import datetime
    from datetime import timedelta

    # Set defaults: start at 7am yesterday, end at 7am today.
    now = datetime.datetime.now()
    default_end = now.replace(hour=7, minute=0, second=0, microsecond=0)
    # If now is before 7am today, adjust default_end to 7am of today already passed
    if now &lt; default_end:
        default_end -= timedelta(days=1)
    default_start = default_end - timedelta(days=1)

    start_date_str = request.GET.get(&#39;start_date&#39;, default_start.strftime(&#39;%Y-%m-%d %H:%M&#39;))
    end_date_str = request.GET.get(&#39;end_date&#39;, default_end.strftime(&#39;%Y-%m-%d %H:%M&#39;))

    # For display in header, compute previous_day (for example, the day before start_date)
    start_date_obj = datetime.datetime.strptime(start_date_str, &#39;%Y-%m-%d %H:%M&#39;)
    previous_day_str = (start_date_obj.date() - timedelta(days=0)).strftime(&#39;%Y-%m-%d&#39;)

    context = {
        &#39;start_date&#39;: start_date_str,  # e.g. &#34;2025-04-07 07:00&#34;
        &#39;end_date&#39;: end_date_str,      # e.g. &#34;2025-04-08 07:00&#34;
        &#39;previous_day&#39;: previous_day_str,
        &#39;lines&#39;: lines  # your global structure for lines/operations/machines
    }
    return render(request, &#39;prod_query/oa_by_day.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Render the production data page with an inline range calendar.
The default is set so that the start_date is yesterday at 7am and the end_date is today at 7am.</p></div>
</dd>
<dt id="prod_query.views.oa_byline2"><code class="name flex">
<span>def <span class="ident">oa_byline2</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def oa_byline2(request):
    &#34;&#34;&#34;
    Render and process the by-line overview for a selected production line and date.

    Supports both GET and POST:
      - GET: Displays the form with all available lines and no pre-selected values.
      - POST: 
        • Reads `date` (YYYY-MM-DD) and `line` from the submitted form.
        • Validates that the selected date is not in the future.
        • On valid input, calls `get_line_details(selected_date, selected_line, lines)`
          to populate production metrics and adds them to the context.
        • Formats the selected date into a “Month Year” string via `get_month_and_year`
          for use in titles.
        • On error (invalid or future date), sets `context[&#39;error&#39;]` accordingly.
        • Persists `selected_date` and `selected_line` in the context for form re-population.

    Context Keys
    ------------
    lines : list
        All available production lines for selection.
    selected_date : str or datetime.date
        The date chosen by the user (string on first POST, `date` object after parsing).
    selected_line : str
        The line identifier chosen by the user.
    error : str, optional
        Error message if date parsing fails or the date is in the future.
    month_year : str, optional
        Human-readable “Month Year” for the selected date, e.g. &#34;June 2025&#34;.
    [plus any keys returned by `get_line_details`]

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request. On POST, `request.POST` must contain `date` and `line`.

    Returns
    -------
    django.http.HttpResponse
        Renders &#39;prod_query/oa_display_v3.html&#39; with the assembled context.
    &#34;&#34;&#34;
    context = {&#39;lines&#39;: get_all_lines(lines)}  # Load all available lines
    if request.method == &#39;POST&#39;:
        selected_date_str = request.POST.get(&#39;date&#39;)
        selected_line = request.POST.get(&#39;line&#39;)
        
        # Add selected date and line to the context for persistence
        context[&#39;selected_date&#39;] = selected_date_str
        context[&#39;selected_line&#39;] = selected_line

        try:
            # Parse the selected date
            selected_date = datetime.strptime(selected_date_str, &#39;%Y-%m-%d&#39;)
            today = datetime.now()

            if selected_date &gt; today:
                context[&#39;error&#39;] = &#34;The selected date is in the future. Please select a valid date.&#34;
            else:
                # Call the function to get line details for the selected date and line
                line_details = get_line_details(selected_date, selected_line, lines)
                context.update(line_details)
                context[&#39;selected_date&#39;] = selected_date  # Add selected date in datetime format
                # Get the month and year for the title
                month_year = get_month_and_year(selected_date_str)
                if month_year:
                    context[&#39;month_year&#39;] = month_year
        except ValueError:
            # Handle invalid date errors
            context[&#39;error&#39;] = &#34;Invalid date or error processing the date.&#34;

    return render(request, &#39;prod_query/oa_display_v3.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Render and process the by-line overview for a selected production line and date.</p>
<p>Supports both GET and POST:
- GET: Displays the form with all available lines and no pre-selected values.
- POST:
• Reads <code>date</code> (YYYY-MM-DD) and <code>line</code> from the submitted form.
• Validates that the selected date is not in the future.
• On valid input, calls <code><a title="prod_query.views.get_line_details" href="#prod_query.views.get_line_details">get_line_details()</a>(selected_date, selected_line, lines)</code>
to populate production metrics and adds them to the context.
• Formats the selected date into a “Month Year” string via <code><a title="prod_query.views.get_month_and_year" href="#prod_query.views.get_month_and_year">get_month_and_year()</a></code>
for use in titles.
• On error (invalid or future date), sets <code>context['error']</code> accordingly.
• Persists <code>selected_date</code> and <code>selected_line</code> in the context for form re-population.</p>
<h2 id="context-keys">Context Keys</h2>
<p>lines : list
All available production lines for selection.
selected_date : str or datetime.date
The date chosen by the user (string on first POST, <code>date</code> object after parsing).
selected_line : str
The line identifier chosen by the user.
error : str, optional
Error message if date parsing fails or the date is in the future.
month_year : str, optional
Human-readable “Month Year” for the selected date, e.g. "June 2025".
[plus any keys returned by <code>get_line_details</code>]</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request. On POST, <code>request.POST</code> must contain <code>date</code> and <code>line</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders 'prod_query/oa_display_v3.html' with the assembled context.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.oa_display"><code class="name flex">
<span>def <span class="ident">oa_display</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def oa_display(request):
    return render(request, &#39;prod_query/oa_display.html&#39;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.oa_display_v2"><code class="name flex">
<span>def <span class="ident">oa_display_v2</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def oa_display_v2(request):
    &#34;&#34;&#34;
    Render the OA Display V2 page with the lines data for the dropdown.
    &#34;&#34;&#34;
    return render(request, &#39;prod_query/oa_display_v2.html&#39;, {&#39;lines&#39;: lines})</code></pre>
</details>
<div class="desc"><p>Render the OA Display V2 page with the lines data for the dropdown.</p></div>
</dd>
<dt id="prod_query.views.oa_drilldown"><code class="name flex">
<span>def <span class="ident">oa_drilldown</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def oa_drilldown(request):
    &#34;&#34;&#34;
    Render the drill-down page or return line-metric aggregates for a date range.

    GET:
        - Renders &#39;prod_query/oa_drilldown.html&#39; with:
            • lines: list of available production lines.

    POST (expects AJAX JSON response):
        - Expects form data:
            • start_date (YYYY-MM-DD)
            • end_date   (YYYY-MM-DD)
            • line       (line identifier)
        - Validates:
            • line is provided
            • both dates are provided, not in the future, and start ≤ end
        - On validation failure returns JsonResponse({&#39;error&#39;: &lt;message&gt;}, status=400).
        - Generates weekly time blocks (Sunday–Friday) between the dates.
        - Fetches and aggregates metrics for the selected line over those blocks.
        - Computes average downtime per machine and recalculates adjusted targets.
        - Calculates A and P values per machine.
        - Returns JsonResponse({
              &#39;aggregated_metrics&#39;: [ ... per-machine dicts ... ],
              &#39;average_downtime&#39;: {machine_id: downtime%, ...}
          }, status=200).
        - On unexpected errors, logs to console and returns JsonResponse({&#39;error&#39;: &lt;msg&gt;}, status=500).

    Parameters
    ----------
    request : django.http.HttpRequest
        The HTTP request object. On POST, should include &#39;start_date&#39;, &#39;end_date&#39;, and &#39;line&#39; in request.POST.

    Returns
    -------
    django.http.HttpResponse or django.http.JsonResponse
        - On GET: renders the drill-down template.
        - On POST success: JSON with aggregated metrics and downtime.
        - On POST validation errors: JSON error with status 400.
        - On server errors: JSON error with status 500.
    &#34;&#34;&#34;
    context = {&#39;lines&#39;: get_all_lines(lines)}  # Load all available lines

    if request.method == &#39;POST&#39;:
        start_date_str = request.POST.get(&#39;start_date&#39;, &#39;&#39;)
        end_date_str = request.POST.get(&#39;end_date&#39;, &#39;&#39;)
        selected_line = request.POST.get(&#39;line&#39;, &#39;&#39;)

        try:
            # Ensure valid input
            if not selected_line:
                return JsonResponse({&#39;error&#39;: &#39;Please select a line.&#39;}, status=400)
            if not start_date_str or not end_date_str:
                return JsonResponse({&#39;error&#39;: &#39;Start and end dates are required.&#39;}, status=400)

            start_date = datetime.strptime(start_date_str, &#39;%Y-%m-%d&#39;)
            end_date = datetime.strptime(end_date_str, &#39;%Y-%m-%d&#39;)
            now = datetime.now()

            if start_date &gt; now or end_date &gt; now:
                return JsonResponse({&#39;error&#39;: &#39;Dates cannot be in the future.&#39;}, status=400)
            if start_date &gt; end_date:
                return JsonResponse({&#39;error&#39;: &#39;Start date cannot be after end date.&#39;}, status=400)

            # Generate time blocks
            time_blocks = get_sunday_to_friday_ranges_custom(start_date, end_date)

            # Fetch metrics for the line and time blocks
            metrics = fetch_line_metrics(line_name=selected_line, time_blocks=time_blocks, lines=lines)

            # Aggregate metrics across all time blocks
            aggregated_metrics = aggregate_line_metrics(metrics)

            # Calculate average downtime for machines
            average_downtime = calculate_average_downtime(metrics)

            # Recalculate total adjusted targets
            aggregated_metrics = recalculate_adjusted_targets(aggregated_metrics, average_downtime)

            # Calculate A value and P value for each machine
            # print(&#34;[DEBUG] Aggregated Metrics (Per Machine):&#34;)
            for machine in aggregated_metrics:
                total_potential_minutes = machine[&#39;total_potential_minutes&#39;]
                total_downtime = machine[&#39;total_downtime&#39;]
                total_produced = machine[&#39;total_produced&#39;]
                total_adjusted_target = machine.get(&#39;total_adjusted_target&#39;, 0)
                avg_downtime = average_downtime.get(machine[&#39;machine_id&#39;], 0)

                # Calculate A value
                a_value = calculate_A(total_potential_minutes, total_downtime)
                machine[&#39;a_value&#39;] = a_value

                # Calculate P value
                p_value = drilldown_calculate_P(total_produced, total_adjusted_target, f&#34;{avg_downtime}%&#34;)
                machine[&#39;p_value&#39;] = p_value

                # Print debug info
                # print(f&#34;Machine ID: {machine[&#39;machine_id&#39;]}, &#34;
                #       f&#34;Total Produced: {total_produced}, &#34;
                #       f&#34;Total Adjusted Target: {total_adjusted_target}, &#34;
                #       f&#34;Average Downtime: {avg_downtime}%, &#34;
                #       f&#34;A Value: {a_value}, &#34;
                #       f&#34;P Value: {p_value}&#34;)

            return JsonResponse({&#39;aggregated_metrics&#39;: aggregated_metrics, &#39;average_downtime&#39;: average_downtime}, status=200)

        except Exception as e:
            print(f&#34;[ERROR] Exception in oa_drilldown: {e}&#34;)
            return JsonResponse({&#39;error&#39;: str(e)}, status=500)

    return render(request, &#39;prod_query/oa_drilldown.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Render the drill-down page or return line-metric aggregates for a date range.</p>
<h2 id="get">Get</h2>
<ul>
<li>Renders 'prod_query/oa_drilldown.html' with:
• lines: list of available production lines.</li>
</ul>
<p>POST (expects AJAX JSON response):
- Expects form data:
• start_date (YYYY-MM-DD)
• end_date
(YYYY-MM-DD)
• line
(line identifier)
- Validates:
• line is provided
• both dates are provided, not in the future, and start ≤ end
- On validation failure returns JsonResponse({'error': <message>}, status=400).
- Generates weekly time blocks (Sunday–Friday) between the dates.
- Fetches and aggregates metrics for the selected line over those blocks.
- Computes average downtime per machine and recalculates adjusted targets.
- Calculates A and P values per machine.
- Returns JsonResponse({
'aggregated_metrics': [ &hellip; per-machine dicts &hellip; ],
'average_downtime': {machine_id: downtime%, &hellip;}
}, status=200).
- On unexpected errors, logs to console and returns JsonResponse({'error': <msg>}, status=500).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The HTTP request object. On POST, should include 'start_date', 'end_date', and 'line' in request.POST.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code> or <code>django.http.JsonResponse</code></dt>
<dd>
<ul>
<li>On GET: renders the drill-down template.</li>
<li>On POST success: JSON with aggregated metrics and downtime.</li>
<li>On POST validation errors: JSON error with status 400.</li>
<li>On server errors: JSON error with status 500.</li>
</ul>
</dd>
</dl></div>
</dd>
<dt id="prod_query.views.parse_date_range"><code class="name flex">
<span>def <span class="ident">parse_date_range</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_date_range(request):
    import datetime, os, importlib, json
    &#34;&#34;&#34;Parses start_date and end_date from the request and returns computed values.&#34;&#34;&#34;
    default_date_str = datetime.datetime.today().strftime(&#39;%Y-%m-%d&#39;)
    start_date_str = request.GET.get(&#39;start_date&#39;, default_date_str)
    end_date_str = request.GET.get(&#39;end_date&#39;, default_date_str)
    
    try:
        start_date = datetime.datetime.strptime(start_date_str, &#39;%Y-%m-%d %H:%M&#39;)
        end_date = datetime.datetime.strptime(end_date_str, &#39;%Y-%m-%d %H:%M&#39;)
        auto_subtract = False
    except ValueError:
        start_date = datetime.datetime.strptime(start_date_str, &#39;%Y-%m-%d&#39;)
        end_date = datetime.datetime.strptime(end_date_str, &#39;%Y-%m-%d&#39;)
        auto_subtract = True

    if auto_subtract:
        start_date = start_date.replace(hour=7, minute=0, second=0)
        end_date = end_date.replace(hour=7, minute=0, second=0)
        start_time = start_date - datetime.timedelta(days=1)
    else:
        start_time = start_date

    end_time = end_date
    start_timestamp = int(start_time.timestamp())
    end_timestamp = int(end_time.timestamp())
    queried_minutes = (end_timestamp - start_timestamp) / 60
    previous_day_str = (start_date.date() - datetime.timedelta(days=1)).strftime(&#39;%Y-%m-%d&#39;)
    
    return start_time, end_time, start_timestamp, end_timestamp, queried_minutes, previous_day_str</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.parse_dates"><code class="name flex">
<span>def <span class="ident">parse_dates</span></span>(<span>start_date_str, end_date_str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_dates(start_date_str, end_date_str):
    &#34;&#34;&#34;
    Convert start and end dates from strings to timestamps.
    &#34;&#34;&#34;
    try:
        # Use the directly imported datetime
        start_timestamp = int(time.mktime(datetime.strptime(start_date_str, &#39;%Y-%m-%d&#39;).timetuple()))
        end_timestamp = int(time.mktime(datetime.strptime(end_date_str, &#39;%Y-%m-%d&#39;).timetuple()))
        return start_timestamp, end_timestamp
    except (ValueError, TypeError):
        return None, None</code></pre>
</details>
<div class="desc"><p>Convert start and end dates from strings to timestamps.</p></div>
</dd>
<dt id="prod_query.views.pr_downtime_view"><code class="name flex">
<span>def <span class="ident">pr_downtime_view</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pr_downtime_view(request):
    &#34;&#34;&#34;
    Provide downtime event details and strokes-per-minute chart data for a given asset.

    Expects HTTP GET with query parameters:
      - `assetnum` (str): the asset identifier (mapped via MACHINE_MAP if present).
      - `called4helptime` (str): ISO timestamp &#34;YYYY-MM-DD HH:MM:SS TZ&#34; when help was called.
      - `completedtime` (str): ISO timestamp &#34;YYYY-MM-DD HH:MM:SS TZ&#34; when downtime was resolved.

    Workflow:
      1. Validate presence of all three parameters or return HTTP 400.
      2. Map `assetnum` via `MACHINE_MAP`, defaulting to the original.
      3. Parse both timestamps into aware `datetime` objects in US/Eastern.
         On parse error, return HTTP 400 with an error message.
      4. Convert to Unix timestamps and compute total downtime in minutes.
      5. Determine an aggregation `interval` to produce up to 250 graph points.
      6. Retrieve raw downtime entries using `fetch_prdowntime1_entries`.
      7. Retrieve strokes-per-minute series via `fetch_chart_data`.
      8. Serialize:
         - `&#34;data&#34;`: list of dicts with keys `problem`, `called4helptime`, and `completedtime`.
         - `&#34;chart_data&#34;`: dict with parallel `&#34;labels&#34;` (ISO datetimes) and `&#34;counts&#34;` (int).
      9. Return a JSON response containing both datasets.

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP GET request with required query parameters.

    Returns
    -------
    django.http.JsonResponse
        On success (HTTP 200): 
          {
            &#34;data&#34;: [ { &#34;problem&#34;: str, &#34;called4helptime&#34;: str or None, &#34;completedtime&#34;: str or None }, … ],
            &#34;chart_data&#34;: { &#34;labels&#34;: [str, …], &#34;counts&#34;: [int, …] }
          }
        On error: JSON with an `&#34;error&#34;` key and appropriate HTTP status (400 or 500).
    &#34;&#34;&#34;
    try:
        default_numGraphPoints = 250  # Set default number of graph points
        
        # Extract parameters from the request
        assetnum = request.GET.get(&#39;assetnum&#39;)
        called4helptime = request.GET.get(&#39;called4helptime&#39;)
        completedtime = request.GET.get(&#39;completedtime&#39;)

        # Validate input
        if not all([assetnum, called4helptime, completedtime]):
            return JsonResponse({&#34;error&#34;: &#34;Missing required parameters&#34;}, status=400)

        # Map assetnum to the TKB machine, or use assetnum directly
        mapped_assetnum = MACHINE_MAP.get(assetnum, assetnum)

        # Parse incoming time strings into datetime objects
        est = pytz.timezone(&#39;US/Eastern&#39;)
        try:
            called4helptime_dt = datetime.strptime(called4helptime, &#34;%Y-%m-%d %H:%M:%S %Z&#34;).astimezone(est)
            completedtime_dt = datetime.strptime(completedtime, &#34;%Y-%m-%d %H:%M:%S %Z&#34;).astimezone(est)
        except Exception as e:
            return JsonResponse({&#34;error&#34;: f&#34;Invalid date format: {e}&#34;}, status=400)

        # Convert datetimes to Unix timestamps
        start_timestamp = int(time.mktime(called4helptime_dt.timetuple()))
        end_timestamp = int(time.mktime(completedtime_dt.timetuple()))

        # Calculate the total duration in minutes
        total_minutes = (completedtime_dt - called4helptime_dt).total_seconds() / 60

        # Calculate the interval to display default_numGraphPoints points
        interval = max(int(total_minutes / default_numGraphPoints), 1)

        # Fetch downtime data
        data = fetch_prdowntime1_entries(mapped_assetnum, called4helptime_dt.isoformat(), completedtime_dt.isoformat())

        # Fetch chart data for Strokes Per Minute
        labels, counts = fetch_chart_data(
            machine=mapped_assetnum,
            start=start_timestamp,
            end=end_timestamp,
            interval=interval,
            group_by_shift=False
        )
        
        # Prepare chart data for JSON serialization
        chart_labels = [dt.isoformat() if isinstance(dt, datetime) else dt for dt in labels]

        # Serialize downtime data
        serialized_data = [
            {
                &#34;problem&#34;: entry[0],
                &#34;called4helptime&#34;: entry[1].isoformat() if entry[1] else None,
                &#34;completedtime&#34;: entry[2].isoformat() if entry[2] else None,
            }
            for entry in data
        ]

        return JsonResponse({
            &#34;data&#34;: serialized_data,
            &#34;chart_data&#34;: {
                &#34;labels&#34;: chart_labels,
                &#34;counts&#34;: counts
            }
        }, safe=False)

    except Exception as e:
        return JsonResponse({&#34;error&#34;: str(e)}, status=500)</code></pre>
</details>
<div class="desc"><p>Provide downtime event details and strokes-per-minute chart data for a given asset.</p>
<p>Expects HTTP GET with query parameters:
- <code>assetnum</code> (str): the asset identifier (mapped via MACHINE_MAP if present).
- <code>called4helptime</code> (str): ISO timestamp "YYYY-MM-DD HH:MM:SS TZ" when help was called.
- <code>completedtime</code> (str): ISO timestamp "YYYY-MM-DD HH:MM:SS TZ" when downtime was resolved.</p>
<h2 id="workflow">Workflow</h2>
<ol>
<li>Validate presence of all three parameters or return HTTP 400.</li>
<li>Map <code>assetnum</code> via <code>MACHINE_MAP</code>, defaulting to the original.</li>
<li>Parse both timestamps into aware <code>datetime</code> objects in US/Eastern.
On parse error, return HTTP 400 with an error message.</li>
<li>Convert to Unix timestamps and compute total downtime in minutes.</li>
<li>Determine an aggregation <code>interval</code> to produce up to 250 graph points.</li>
<li>Retrieve raw downtime entries using <code>fetch_prdowntime1_entries</code>.</li>
<li>Retrieve strokes-per-minute series via <code><a title="prod_query.views.fetch_chart_data" href="#prod_query.views.fetch_chart_data">fetch_chart_data()</a></code>.</li>
<li>Serialize:</li>
<li><code>"data"</code>: list of dicts with keys <code>problem</code>, <code>called4helptime</code>, and <code>completedtime</code>.</li>
<li><code>"chart_data"</code>: dict with parallel <code>"labels"</code> (ISO datetimes) and <code>"counts"</code> (int).</li>
<li>Return a JSON response containing both datasets.</li>
</ol>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP GET request with required query parameters.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.JsonResponse</code></dt>
<dd>On success (HTTP 200):
{
"data": [ { "problem": str, "called4helptime": str or None, "completedtime": str or None }, … ],
"chart_data": { "labels": [str, …], "counts": [int, …] }
}
On error: JSON with an <code>"error"</code> key and appropriate HTTP status (400 or 500).</dd>
</dl></div>
</dd>
<dt id="prod_query.views.press_runtime_wrapper"><code class="name flex">
<span>def <span class="ident">press_runtime_wrapper</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def press_runtime_wrapper(request):
    &#34;&#34;&#34;
    Display press OEE data by machine over a specified date range.

    Supports both GET (via query params) and POST form submissions:
      - Reads `start_date`, `end_date`, and `machine_id` (comma-separated) from
        request.POST or request.GET (defaults to machine &#34;272&#34;).
      - Parses dates and, if equal, subtracts 24h from start to ensure at least one block.
      - Generates custom time blocks between the dates.
      - For each machine and time block:
          • Fetches press changeover records.
          • Retrieves production counts and raw downtime details.
          • Fetches PR downtime entries and annotates overlaps.
          • Aggregates downtime events (splitting overlap vs. non-overlap).
          • Calculates running intervals, targets, and production by part.
          • Summarizes contiguous run blocks.
      - Optionally attaches Statistical Process Monitoring chart data.
      - Populates `machines_data` with per-machine, per-block data:
          • part_numbers_data, downtime_entries, downtime_events, running_events.
      - Renders &#39;prod_query/press_oee.html&#39; with:
          • machines_data: dict keyed by machine ID
          • start_date, end_date, machine_id: for form persistence

    Parameters
    ----------
    request : django.http.HttpRequest
        HTTP request with optional POST or GET parameters:
          - start_date (YYYY-MM-DD)
          - end_date   (YYYY-MM-DD)
          - machine_id (comma-separated IDs, default &#34;272&#34;)

    Returns
    -------
    django.http.HttpResponse
        Renders the OEE dashboard template with collected press runtime and
        downtime data for the specified machines and date range.
    &#34;&#34;&#34;
    # Get parameters from POST or, if not provided, from GET (with defaults)
    start_date_str = request.POST.get(&#39;start_date&#39;) or request.GET.get(&#39;start_date&#39;, &#39;&#39;)
    end_date_str = request.POST.get(&#39;end_date&#39;) or request.GET.get(&#39;end_date&#39;, &#39;&#39;)
    machine_input = (request.POST.get(&#39;machine_id&#39;) or request.GET.get(&#39;machine_id&#39;, &#39;272&#39;)).strip()
    machine_ids = [m.strip() for m in machine_input.split(&#39;,&#39;) if m.strip()]

    # This dictionary will hold each machine&#39;s data grouped nicely.
    machines_data = {}

    # Process if start and end dates are provided (via POST or URL)
    if start_date_str and end_date_str:
        try:
            start_date = datetime.strptime(start_date_str, &#39;%Y-%m-%d&#39;)
            end_date = datetime.strptime(end_date_str, &#39;%Y-%m-%d&#39;)

            # If start date and end date are the same, subtract 24 hours from start date
            if start_date == end_date:
                start_date -= timedelta(hours=24)

            time_blocks = get_custom_time_blocks(start_date, end_date)
            if isinstance(time_blocks, str):
                return render(request, &#39;prod_query/press_oee.html&#39;, {&#39;error_message&#39;: time_blocks})

            human_readable_format = &#39;%Y-%m-%d %H:%M:%S&#39;
            
            # Initialize groups for each machine
            for machine in machine_ids:
                machines_data[machine] = {
                    &#39;part_numbers_data&#39;: [],
                    &#39;downtime_events&#39;: [],
                    &#39;downtime_entries&#39;: [],
                    &#39;running_events&#39;: [],
                }
            
            with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
                for block_start, block_end in time_blocks:
                    start_ts = int(block_start.timestamp())
                    end_ts = int(block_end.timestamp())
                    block_start_str = block_start.strftime(human_readable_format)
                    block_end_str = block_end.strftime(human_readable_format)
                    
                    for machine in machine_ids:
                        # Fetch and store press changeover records per machine
                        part_records = fetch_press_changeovers(machine, start_ts, end_ts)
                        machines_data[machine][&#39;part_numbers_data&#39;].append({
                            &#39;machine&#39;: machine,
                            &#39;block_start&#39;: block_start_str,
                            &#39;block_end&#39;: block_end_str,
                            &#39;raw_block_start&#39;: block_start,
                            &#39;raw_block_end&#39;: block_end,
                            &#39;part_records&#39;: part_records
                        })

                        produced = fetch_production_count(machine, cursor, start_ts, end_ts)
                        total_downtime, downtime_details = calculate_downtime_press(machine, cursor, start_ts, end_ts)
                        
                        # Fetch PR downtime entries
                        called4helptime_iso = block_start.isoformat()
                        completedtime_iso = block_end.isoformat()
                        pr_entries_for_block = []
                        try:
                            raw_downtime_data = fetch_press_prdowntime1_entries(machine, called4helptime_iso, completedtime_iso)
                            if not (isinstance(raw_downtime_data, dict) and &#39;error&#39; in raw_downtime_data):
                                for entry in raw_downtime_data:
                                    problem = entry[0]
                                    pr_start_time = entry[1]  # assumed datetime
                                    pr_end_time = entry[2]    # assumed datetime
                                    pr_idnumber = entry[3]
                                    if pr_end_time is not None:
                                        duration_minutes = int((pr_end_time - pr_start_time).total_seconds() / 60)
                                    else:
                                        duration_minutes = &#34;Ongoing&#34;
                                    pr_entry = {
                                        &#39;machine&#39;: machine,
                                        &#39;problem&#39;: problem,
                                        &#39;start_time&#39;: pr_start_time,
                                        &#39;end_time&#39;: pr_end_time,
                                        &#39;duration_minutes&#39;: duration_minutes,
                                        &#39;idnumber&#39;: pr_idnumber
                                    }
                                    pr_entries_for_block.append(pr_entry)
                                    machines_data[machine][&#39;downtime_entries&#39;].append(pr_entry)
                        except Exception as e:
                            print(f&#34;[ERROR] Exception while fetching PR downtime entries for machine {machine}: {e}&#34;)
                        
                        # Process downtime details and aggregate annotated downtime events
                        annotated_details = []
                        non_overlap_total = 0
                        overlap_total = 0
                        for detail in downtime_details:
                            dt_start = datetime.fromtimestamp(detail[&#39;start&#39;])
                            dt_end = datetime.fromtimestamp(detail[&#39;end&#39;])
                            overlap_info = compute_overlap_label(dt_start, dt_end, pr_entries_for_block)
                            annotated_detail = {
                                &#39;start&#39;: dt_start.strftime(human_readable_format),
                                &#39;end&#39;: dt_end.strftime(human_readable_format),
                                &#39;duration&#39;: detail[&#39;duration&#39;],
                                &#39;overlap&#39;: overlap_info[&#39;overlap&#39;],
                                &#39;pr_id&#39;: overlap_info[&#39;pr_id&#39;]
                            }
                            annotated_details.append(annotated_detail)
                            if overlap_info[&#39;overlap&#39;] == &#34;No Overlap&#34;:
                                if detail[&#39;duration&#39;] &lt; 240:
                                    overlap_total += detail[&#39;duration&#39;]
                                else:
                                    non_overlap_total += detail[&#39;duration&#39;]
                            else:
                                overlap_total += detail[&#39;duration&#39;]
                        
                        if total_downtime &gt; 5:
                            machines_data[machine][&#39;downtime_events&#39;].append({
                                &#39;machine&#39;: machine,
                                &#39;block_start&#39;: block_start_str,
                                &#39;block_end&#39;: block_end_str,
                                &#39;produced&#39;: produced,
                                &#39;downtime_minutes&#39;: total_downtime,
                                &#39;non_overlap_minutes&#39;: non_overlap_total,
                                &#39;overlap_minutes&#39;: overlap_total,
                                &#39;details&#39;: annotated_details
                            })

                        # Calculate running intervals for this machine in this block
                        runtime_intervals = calculate_runtime_press(machine, cursor, start_ts, end_ts, running_threshold=5)
                        formatted_runtime_intervals = []
                        for interval in runtime_intervals:
                            active_info = get_active_part(interval, part_records, machine)
                            parts_produced = fetch_production_count(machine, cursor, interval[&#39;start&#39;], interval[&#39;end&#39;])
                            try:
                                cycle_time = float(active_info[&#39;cycle_time&#39;])
                            except Exception:
                                cycle_time = None
                            target = int((interval[&#39;duration&#39;] * 60) / cycle_time) if cycle_time and cycle_time &gt; 0 else &#34;N/A&#34;
                            formatted_interval = {
                                &#39;start&#39;: datetime.fromtimestamp(interval[&#39;start&#39;]).strftime(human_readable_format),
                                &#39;end&#39;: datetime.fromtimestamp(interval[&#39;end&#39;]).strftime(human_readable_format),
                                &#39;duration&#39;: interval[&#39;duration&#39;],
                                &#39;part&#39;: active_info[&#39;part&#39;],
                                &#39;cycle_time&#39;: active_info[&#39;cycle_time&#39;],
                                &#39;parts_produced&#39;: parts_produced,
                                &#39;target&#39;: target
                            }
                            formatted_runtime_intervals.append(formatted_interval)
                        
                        aggregated_summary = summarize_contiguous_intervals(formatted_runtime_intervals, annotated_details, human_readable_format)
                        machines_data[machine][&#39;running_events&#39;].append({
                            &#39;machine&#39;: machine,
                            &#39;block_start&#39;: block_start_str,
                            &#39;block_end&#39;: block_end_str,
                            &#39;running_intervals&#39;: formatted_runtime_intervals,
                            &#39;summary&#39;: aggregated_summary
                        })
            
            # Optionally, attach SPM chart data if needed (update part_numbers_data accordingly)
            for machine in machine_ids:
                machines_data[machine][&#39;part_numbers_data&#39;] = attach_spm_chart_data_to_blocks(
                    machines_data[machine][&#39;part_numbers_data&#39;], machine, interval=5
                )
            
        except Exception as e:
            print(f&#34;[ERROR] Error processing time blocks: {e}&#34;)
    
    return render(request, &#39;prod_query/press_oee.html&#39;, {
        &#39;machines_data&#39;: machines_data,
        &#39;start_date&#39;: start_date_str,
        &#39;end_date&#39;: end_date_str,
        &#39;machine_id&#39;: machine_input,
    })</code></pre>
</details>
<div class="desc"><p>Display press OEE data by machine over a specified date range.</p>
<p>Supports both GET (via query params) and POST form submissions:
- Reads <code>start_date</code>, <code>end_date</code>, and <code>machine_id</code> (comma-separated) from
request.POST or request.GET (defaults to machine "272").
- Parses dates and, if equal, subtracts 24h from start to ensure at least one block.
- Generates custom time blocks between the dates.
- For each machine and time block:
• Fetches press changeover records.
• Retrieves production counts and raw downtime details.
• Fetches PR downtime entries and annotates overlaps.
• Aggregates downtime events (splitting overlap vs. non-overlap).
• Calculates running intervals, targets, and production by part.
• Summarizes contiguous run blocks.
- Optionally attaches Statistical Process Monitoring chart data.
- Populates <code>machines_data</code> with per-machine, per-block data:
• part_numbers_data, downtime_entries, downtime_events, running_events.
- Renders 'prod_query/press_oee.html' with:
• machines_data: dict keyed by machine ID
• start_date, end_date, machine_id: for form persistence</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>HTTP request with optional POST or GET parameters:
- start_date (YYYY-MM-DD)
- end_date
(YYYY-MM-DD)
- machine_id (comma-separated IDs, default "272")</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders the OEE dashboard template with collected press runtime and
downtime data for the specified machines and date range.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.press_runtime_wrapper2"><code class="name flex">
<span>def <span class="ident">press_runtime_wrapper2</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def press_runtime_wrapper2(request):
    &#34;&#34;&#34;
    Display press OEE data for a fixed set of machines over a specified date range.

    Handles both GET (URL params) and POST (form submission):
      - Reads `start_date` and `end_date` from query parameters, overridden by POST data if present.
      - Uses a hard-coded list of machines [&#39;272&#39;,&#39;273&#39;,&#39;277&#39;,&#39;278&#39;].
      - Parses dates and adjusts start if equal to end (subtracts 24h).
      - Generates custom time blocks between dates; on error renders with an error message.
      - For each machine and block:
          • Fetches changeover records.
          • Retrieves production counts and downtime details.
          • Fetches PR downtime entries and annotates overlap.
          • Aggregates downtime events (splitting overlap vs. non-overlap).
          • Calculates running intervals, per-interval production, and targets.
          • Summarizes contiguous running intervals.
      - Populates `machines_data` with per-machine dicts:
          • `part_numbers_data`, `downtime_entries`, `downtime_events`, `running_events`.
      - Renders `&#39;prod_query/press_oee2.html&#39;` with:
          • `machines_data`
          • `start_date`, `end_date` for form re-population

    Parameters
    ----------
    request : django.http.HttpRequest
        HTTP request object. May include:
          - GET or POST `start_date` (YYYY-MM-DD)
          - GET or POST `end_date`   (YYYY-MM-DD)

    Returns
    -------
    django.http.HttpResponse
        Renders the OEE dashboard template with collected press runtime and downtime
        data for the four predefined machines and the specified date range.
    &#34;&#34;&#34;
    # First, try to get dates from the URL (GET parameters)
    start_date_str = request.GET.get(&#39;start_date&#39;, &#39;&#39;)
    end_date_str = request.GET.get(&#39;end_date&#39;, &#39;&#39;)
    
    # If the form is submitted via POST, override with POST data
    if request.method == &#39;POST&#39;:
        start_date_str = request.POST.get(&#39;start_date&#39;, start_date_str)
        end_date_str = request.POST.get(&#39;end_date&#39;, end_date_str)
    
    machine_ids = [&#39;272&#39;, &#39;273&#39;, &#39;277&#39;, &#39;278&#39;]
    machines_data = {}

    if (request.method == &#39;POST&#39; or start_date_str and end_date_str):
        try:
            start_date = datetime.strptime(start_date_str, &#39;%Y-%m-%d&#39;)
            end_date = datetime.strptime(end_date_str, &#39;%Y-%m-%d&#39;)

            # If start date and end date are the same, subtract 24 hours from start date
            if start_date == end_date:
                start_date -= timedelta(hours=24)

            time_blocks = get_custom_time_blocks(start_date, end_date)
            if isinstance(time_blocks, str):
                return render(request, &#39;prod_query/press_oee2.html&#39;, {&#39;error_message&#39;: time_blocks})
            
            human_readable_format = &#39;%Y-%m-%d %H:%M:%S&#39;
            # Initialize groups for each machine
            for machine in machine_ids:
                machines_data[machine] = {
                    &#39;part_numbers_data&#39;: [],
                    &#39;downtime_events&#39;: [],
                    &#39;downtime_entries&#39;: [],
                    &#39;running_events&#39;: [],
                }
            
            with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
                for block_start, block_end in time_blocks:
                    start_ts = int(block_start.timestamp())
                    end_ts = int(block_end.timestamp())
                    block_start_str = block_start.strftime(human_readable_format)
                    block_end_str = block_end.strftime(human_readable_format)
                    
                    for machine in machine_ids:
                        # Fetch press changeover records
                        part_records = fetch_press_changeovers(machine, start_ts, end_ts)
                        machines_data[machine][&#39;part_numbers_data&#39;].append({
                            &#39;machine&#39;: machine,
                            &#39;block_start&#39;: block_start_str,
                            &#39;block_end&#39;: block_end_str,
                            &#39;raw_block_start&#39;: block_start,
                            &#39;raw_block_end&#39;: block_end,
                            &#39;part_records&#39;: part_records
                        })
                        
                        produced = fetch_production_count(machine, cursor, start_ts, end_ts)
                        total_downtime, downtime_details = calculate_downtime_press(machine, cursor, start_ts, end_ts)
                        
                        # Fetch PR downtime entries
                        called4helptime_iso = block_start.isoformat()
                        completedtime_iso = block_end.isoformat()
                        pr_entries_for_block = []
                        try:
                            raw_downtime_data = fetch_press_prdowntime1_entries(machine, called4helptime_iso, completedtime_iso)
                            if not (isinstance(raw_downtime_data, dict) and &#39;error&#39; in raw_downtime_data):
                                for entry in raw_downtime_data:
                                    problem = entry[0]
                                    pr_start_time = entry[1]
                                    pr_end_time = entry[2]
                                    pr_idnumber = entry[3]
                                    if pr_end_time is not None:
                                        duration_minutes = int((pr_end_time - pr_start_time).total_seconds() / 60)
                                    else:
                                        duration_minutes = &#34;Ongoing&#34;
                                    pr_entry = {
                                        &#39;machine&#39;: machine,
                                        &#39;problem&#39;: problem,
                                        &#39;start_time&#39;: pr_start_time,
                                        &#39;end_time&#39;: pr_end_time,
                                        &#39;duration_minutes&#39;: duration_minutes,
                                        &#39;idnumber&#39;: pr_idnumber
                                    }
                                    pr_entries_for_block.append(pr_entry)
                                    machines_data[machine][&#39;downtime_entries&#39;].append(pr_entry)
                        except Exception as e:
                            print(f&#34;[ERROR] Exception while fetching PR downtime entries for machine {machine}: {e}&#34;)
                        
                        # Process downtime details and aggregate annotated downtime events
                        annotated_details = []
                        non_overlap_total = 0
                        overlap_total = 0
                        for detail in downtime_details:
                            dt_start = datetime.fromtimestamp(detail[&#39;start&#39;])
                            dt_end = datetime.fromtimestamp(detail[&#39;end&#39;])
                            overlap_info = compute_overlap_label(dt_start, dt_end, pr_entries_for_block)
                            annotated_detail = {
                                &#39;start&#39;: dt_start.strftime(human_readable_format),
                                &#39;end&#39;: dt_end.strftime(human_readable_format),
                                &#39;duration&#39;: detail[&#39;duration&#39;],
                                &#39;overlap&#39;: overlap_info[&#39;overlap&#39;],
                                &#39;pr_id&#39;: overlap_info[&#39;pr_id&#39;]
                            }
                            annotated_details.append(annotated_detail)
                            if overlap_info[&#39;overlap&#39;] == &#34;No Overlap&#34;:
                                if detail[&#39;duration&#39;] &lt; 240:
                                    overlap_total += detail[&#39;duration&#39;]
                                else:
                                    non_overlap_total += detail[&#39;duration&#39;]
                            else:
                                overlap_total += detail[&#39;duration&#39;]
                        
                        if total_downtime &gt; 5:
                            machines_data[machine][&#39;downtime_events&#39;].append({
                                &#39;machine&#39;: machine,
                                &#39;block_start&#39;: block_start_str,
                                &#39;block_end&#39;: block_end_str,
                                &#39;produced&#39;: produced,
                                &#39;downtime_minutes&#39;: total_downtime,
                                &#39;non_overlap_minutes&#39;: non_overlap_total,
                                &#39;overlap_minutes&#39;: overlap_total,
                                &#39;details&#39;: annotated_details
                            })
                        
                        # Calculate running intervals for this machine in this block
                        runtime_intervals = calculate_runtime_press(machine, cursor, start_ts, end_ts, running_threshold=5)
                        formatted_runtime_intervals = []
                        for interval in runtime_intervals:
                            active_info = get_active_part(interval, part_records, machine)
                            parts_produced = fetch_production_count(machine, cursor, interval[&#39;start&#39;], interval[&#39;end&#39;])
                            try:
                                cycle_time = float(active_info[&#39;cycle_time&#39;])
                            except Exception:
                                cycle_time = None
                            target = int((interval[&#39;duration&#39;] * 60) / cycle_time) if cycle_time and cycle_time &gt; 0 else &#34;N/A&#34;
                            formatted_interval = {
                                &#39;start&#39;: datetime.fromtimestamp(interval[&#39;start&#39;]).strftime(human_readable_format),
                                &#39;end&#39;: datetime.fromtimestamp(interval[&#39;end&#39;]).strftime(human_readable_format),
                                &#39;duration&#39;: interval[&#39;duration&#39;],
                                &#39;part&#39;: active_info[&#39;part&#39;],
                                &#39;cycle_time&#39;: active_info[&#39;cycle_time&#39;],
                                &#39;parts_produced&#39;: parts_produced,
                                &#39;target&#39;: target
                            }
                            formatted_runtime_intervals.append(formatted_interval)
                        
                        aggregated_summary = summarize_contiguous_intervals(formatted_runtime_intervals, annotated_details, human_readable_format)
                        machines_data[machine][&#39;running_events&#39;].append({
                            &#39;machine&#39;: machine,
                            &#39;block_start&#39;: block_start_str,
                            &#39;block_end&#39;: block_end_str,
                            &#39;running_intervals&#39;: formatted_runtime_intervals,
                            &#39;summary&#39;: aggregated_summary
                        })
            
            # Optionally, attach SPM chart data if needed

        except Exception as e:
            print(f&#34;[ERROR] Error processing time blocks: {e}&#34;)
    
    return render(request, &#39;prod_query/press_oee2.html&#39;, {
        &#39;machines_data&#39;: machines_data,
        &#39;start_date&#39;: start_date_str,
        &#39;end_date&#39;: end_date_str,
    })</code></pre>
</details>
<div class="desc"><p>Display press OEE data for a fixed set of machines over a specified date range.</p>
<p>Handles both GET (URL params) and POST (form submission):
- Reads <code>start_date</code> and <code>end_date</code> from query parameters, overridden by POST data if present.
- Uses a hard-coded list of machines ['272','273','277','278'].
- Parses dates and adjusts start if equal to end (subtracts 24h).
- Generates custom time blocks between dates; on error renders with an error message.
- For each machine and block:
• Fetches changeover records.
• Retrieves production counts and downtime details.
• Fetches PR downtime entries and annotates overlap.
• Aggregates downtime events (splitting overlap vs. non-overlap).
• Calculates running intervals, per-interval production, and targets.
• Summarizes contiguous running intervals.
- Populates <code>machines_data</code> with per-machine dicts:
• <code>part_numbers_data</code>, <code>downtime_entries</code>, <code>downtime_events</code>, <code>running_events</code>.
- Renders <code>'prod_query/press_oee2.html'</code> with:
• <code>machines_data</code>
• <code>start_date</code>, <code>end_date</code> for form re-population</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>HTTP request object. May include:
- GET or POST <code>start_date</code> (YYYY-MM-DD)
- GET or POST <code>end_date</code>
(YYYY-MM-DD)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders the OEE dashboard template with collected press runtime and downtime
data for the four predefined machines and the specified date range.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.press_runtime_wrapper3"><code class="name flex">
<span>def <span class="ident">press_runtime_wrapper3</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def press_runtime_wrapper3(request):
    &#34;&#34;&#34;
    Compute and display detailed OEE metrics for multiple press machines over a date range.

    Only handles POST requests with form fields:
      - `start_date` (YYYY-MM-DD)
      - `end_date`   (YYYY-MM-DD)

    Workflow:
      1. Parse and validate `start_date` and `end_date` (if equal, subtract 24h from start).
      2. Generate custom time blocks between the dates.
      3. For each block and each machine in [&#39;272&#39;,&#39;273&#39;,&#39;277&#39;,&#39;278&#39;]:
         a. Fetch changeover records and append to `part_numbers_data`.
         b. Retrieve production counts and raw downtime intervals.
         c. Fetch PR downtime entries, annotate overlap vs. non-overlap.
         d. Build `downtime_events` for intervals &gt;5 minutes.
         e. Calculate running intervals, per-interval production, targets, and down-time splits.
         f. Summarize contiguous run intervals; append to `running_events`.
      4. After all blocks, compute per-machine totals:
         - uptime, planned vs. unplanned downtime, potential minutes,
           weighted cycle time, parts produced, target, A, P, and overall OEE.
      5. Aggregate defined machine groups (e.g., &#39;1500T&#39; = [&#39;272&#39;,&#39;273&#39;]).
      6. Prepare `sorted_machines_data` in the desired display order.

    Context passed to template:
      - `sorted_machines_data`: list of `{machine: id, data: {...}}`, including group entries.
      - `start_date`, `end_date`: strings for form persistence.

    Parameters
    ----------
    request : django.http.HttpRequest
        The HTTP POST request containing `start_date` and `end_date`.

    Returns
    -------
    django.http.HttpResponse
        Renders &#39;prod_query/press_oee3.html&#39; with the computed metrics context.
    &#34;&#34;&#34;
    # Get parameters from POST (or default values)
    start_date_str = request.POST.get(&#39;start_date&#39;, &#39;&#39;)
    end_date_str = request.POST.get(&#39;end_date&#39;, &#39;&#39;)
    machine_ids = [&#39;272&#39;, &#39;273&#39;, &#39;277&#39;, &#39;278&#39;]

    # This dictionary will hold each machine&#39;s data grouped nicely.
    machines_data = {}

    if request.method == &#39;POST&#39; and start_date_str and end_date_str:
        try:
            start_date = datetime.strptime(start_date_str, &#39;%Y-%m-%d&#39;)
            end_date = datetime.strptime(end_date_str, &#39;%Y-%m-%d&#39;)

            # If start date and end date are the same, subtract 24 hours from start date
            if start_date == end_date:
                start_date -= timedelta(hours=24)

            time_blocks = get_custom_time_blocks(start_date, end_date)
            if isinstance(time_blocks, str):
                return render(request, &#39;prod_query/press_oee3.html&#39;, {&#39;error_message&#39;: time_blocks})

            human_readable_format = &#39;%Y-%m-%d %H:%M:%S&#39;
            
            # Initialize groups for each individual machine
            for machine in machine_ids:
                machines_data[machine] = {
                    &#39;part_numbers_data&#39;: [],
                    &#39;downtime_events&#39;: [],
                    &#39;downtime_entries&#39;: [],
                    &#39;running_events&#39;: [],
                    &#39;totals&#39;: {}
                }
            
            with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
                for block_start, block_end in time_blocks:
                    start_ts = int(block_start.timestamp())
                    end_ts = int(block_end.timestamp())
                    block_start_str = block_start.strftime(human_readable_format)
                    block_end_str = block_end.strftime(human_readable_format)
                    
                    for machine in machine_ids:
                        # Fetch and store press changeover records per machine
                        part_records = fetch_press_changeovers(machine, start_ts, end_ts)
                        machines_data[machine][&#39;part_numbers_data&#39;].append({
                            &#39;machine&#39;: machine,
                            &#39;block_start&#39;: block_start_str,
                            &#39;block_end&#39;: block_end_str,
                            &#39;raw_block_start&#39;: block_start,
                            &#39;raw_block_end&#39;: block_end,
                            &#39;part_records&#39;: part_records
                        })

                        produced = fetch_production_count(machine, cursor, start_ts, end_ts)
                        total_downtime, downtime_details = calculate_downtime_press(machine, cursor, start_ts, end_ts)
                        
                        # Fetch PR downtime entries
                        called4helptime_iso = block_start.isoformat()
                        completedtime_iso = block_end.isoformat()
                        pr_entries_for_block = []
                        try:
                            raw_downtime_data = fetch_press_prdowntime1_entries(machine, called4helptime_iso, completedtime_iso)
                            if not (isinstance(raw_downtime_data, dict) and &#39;error&#39; in raw_downtime_data):
                                for entry in raw_downtime_data:
                                    problem = entry[0]
                                    pr_start_time = entry[1]  # assumed datetime
                                    pr_end_time = entry[2]    # assumed datetime
                                    pr_idnumber = entry[3]
                                    if pr_end_time is not None:
                                        duration_minutes = int((pr_end_time - pr_start_time).total_seconds() / 60)
                                    else:
                                        duration_minutes = &#34;Ongoing&#34;
                                    pr_entry = {
                                        &#39;machine&#39;: machine,
                                        &#39;problem&#39;: problem,
                                        &#39;start_time&#39;: pr_start_time,
                                        &#39;end_time&#39;: pr_end_time,
                                        &#39;duration_minutes&#39;: duration_minutes,
                                        &#39;idnumber&#39;: pr_idnumber
                                    }
                                    pr_entries_for_block.append(pr_entry)
                                    machines_data[machine][&#39;downtime_entries&#39;].append(pr_entry)
                        except Exception as e:
                            print(f&#34;[ERROR] Exception while fetching PR downtime entries for machine {machine}: {e}&#34;)
                        
                        # Process downtime details and aggregate annotated downtime events
                        annotated_details = []
                        non_overlap_total = 0
                        overlap_total = 0
                        for detail in downtime_details:
                            dt_start = datetime.fromtimestamp(detail[&#39;start&#39;])
                            dt_end = datetime.fromtimestamp(detail[&#39;end&#39;])
                            overlap_info = compute_overlap_label(dt_start, dt_end, pr_entries_for_block)
                            annotated_detail = {
                                &#39;start&#39;: dt_start.strftime(human_readable_format),
                                &#39;end&#39;: dt_end.strftime(human_readable_format),
                                &#39;duration&#39;: detail[&#39;duration&#39;],
                                &#39;overlap&#39;: overlap_info[&#39;overlap&#39;],
                                &#39;pr_id&#39;: overlap_info[&#39;pr_id&#39;]
                            }
                            annotated_details.append(annotated_detail)
                            if overlap_info[&#39;overlap&#39;] == &#34;No Overlap&#34;:
                                if detail[&#39;duration&#39;] &lt; 240:
                                    overlap_total += detail[&#39;duration&#39;]
                                else:
                                    non_overlap_total += detail[&#39;duration&#39;]
                            else:
                                overlap_total += detail[&#39;duration&#39;]
                        
                        if total_downtime &gt; 5:
                            machines_data[machine][&#39;downtime_events&#39;].append({
                                &#39;machine&#39;: machine,
                                &#39;block_start&#39;: block_start_str,
                                &#39;block_end&#39;: block_end_str,
                                &#39;produced&#39;: produced,
                                &#39;downtime_minutes&#39;: total_downtime,
                                &#39;non_overlap_minutes&#39;: non_overlap_total,
                                &#39;overlap_minutes&#39;: overlap_total,
                                &#39;details&#39;: annotated_details
                            })

                        # Calculate running intervals for this machine in this block
                        runtime_intervals = calculate_runtime_press(machine, cursor, start_ts, end_ts, running_threshold=5)
                        formatted_runtime_intervals = []
                        for interval in runtime_intervals:
                            active_info = get_active_part(interval, part_records, machine)
                            parts_produced = fetch_production_count(machine, cursor, interval[&#39;start&#39;], interval[&#39;end&#39;])
                            try:
                                cycle_time = float(active_info[&#39;cycle_time&#39;])
                            except Exception:
                                cycle_time = None
                            target = int((interval[&#39;duration&#39;] * 60) / cycle_time) if cycle_time and cycle_time &gt; 0 else &#34;N/A&#34;
                            formatted_interval = {
                                &#39;start&#39;: datetime.fromtimestamp(interval[&#39;start&#39;]).strftime(human_readable_format),
                                &#39;end&#39;: datetime.fromtimestamp(interval[&#39;end&#39;]).strftime(human_readable_format),
                                &#39;duration&#39;: interval[&#39;duration&#39;],
                                &#39;part&#39;: active_info[&#39;part&#39;],
                                &#39;cycle_time&#39;: cycle_time,
                                &#39;parts_produced&#39;: parts_produced,
                                &#39;target&#39;: target,
                                &#39;unplanned_minutes_down&#39;: sum(d[&#39;duration&#39;] for d in annotated_details if d[&#39;overlap&#39;] != &#34;No Overlap&#34;),
                                &#39;planned_minutes_down&#39;: sum(d[&#39;duration&#39;] for d in annotated_details if d[&#39;overlap&#39;] == &#34;No Overlap&#34;)
                            }
                            formatted_runtime_intervals.append(formatted_interval)
                        
                        aggregated_summary = summarize_contiguous_intervals(formatted_runtime_intervals, annotated_details, human_readable_format)
                        machines_data[machine][&#39;running_events&#39;].append({
                            &#39;machine&#39;: machine,
                            &#39;block_start&#39;: block_start_str,
                            &#39;block_end&#39;: block_end_str,
                            &#39;running_intervals&#39;: formatted_runtime_intervals,
                            &#39;summary&#39;: aggregated_summary
                        })
            
            # After processing all blocks, compute totals for each machine
            for machine, data in machines_data.items():
                total_minutes_up = 0
                total_unplanned_down = 0
                total_planned_down = 0
                total_potential_minutes = 0
                total_parts_produced = 0
                total_target = 0
                weighted_cycle_sum = 0

                for event in data.get(&#39;running_events&#39;, []):
                    summaries = event.get(&#39;summary&#39;)
                    if summaries:
                        for summary in summaries:
                            total_minutes_up += summary.get(&#39;duration&#39;, 0)
                            total_unplanned_down += summary.get(&#39;unplanned_minutes_down&#39;, 0)
                            total_planned_down += summary.get(&#39;planned_minutes_down&#39;, 0)
                            total_potential_minutes += summary.get(&#39;total_potential_minutes&#39;, 0)
                            total_parts_produced += summary.get(&#39;parts_produced&#39;, 0)
                            target_val = summary.get(&#39;target&#39;)
                            if isinstance(target_val, (int, float)):
                                total_target += target_val
                            cycle_time = summary.get(&#39;cycle_time&#39;)
                            potential = summary.get(&#39;total_potential_minutes&#39;, 0)
                            if cycle_time and potential:
                                weighted_cycle_sum += cycle_time * potential

                if total_potential_minutes &gt; 0:
                    weighted_cycle = weighted_cycle_sum / total_potential_minutes
                    weighted_cycle = round(weighted_cycle, 2)
                else:
                    weighted_cycle = None

                overall_availability = total_minutes_up / total_potential_minutes if total_potential_minutes else 0
                overall_performance = total_parts_produced / total_target if total_target else 0
                overall_oee = overall_availability * overall_performance

                machines_data[machine][&#39;totals&#39;] = {
                    &#39;block&#39;: f&#34;{start_date_str} - {end_date_str}&#34;,
                    &#39;total_minutes_up&#39;: total_minutes_up,
                    &#39;total_unplanned_down&#39;: total_unplanned_down,
                    &#39;total_planned_down&#39;: total_planned_down,
                    &#39;total_potential_minutes&#39;: total_potential_minutes,
                    &#39;weighted_cycle&#39;: weighted_cycle if weighted_cycle is not None else &#34;N/A&#34;,
                    &#39;total_parts_produced&#39;: total_parts_produced,
                    &#39;total_target&#39;: total_target,
                    &#39;availability&#39;: overall_availability,
                    &#39;performance&#39;: overall_performance,
                    &#39;oee&#39;: overall_oee
                }
            
            # --- Aggregate groups ---
            group_definitions = {
                &#39;1500T&#39;: [&#39;272&#39;, &#39;273&#39;]  # The group for 1500T aggregates these machines.
            }
            aggregated_groups = aggregate_machine_groups(machines_data, group_definitions)
            # Add the aggregated group rows into machines_data and mark them with a flag (group=True)
            for group_label, totals in aggregated_groups.items():
                machines_data[group_label] = {&#39;totals&#39;: totals, &#39;group&#39;: True}
            
            # Build a list of machine entries for sorted display.
            # Order: first Press 272 and 273, then group &#34;1500T&#34;, then the rest.
            sorted_machines_data = []
            for machine in [&#39;272&#39;, &#39;273&#39;]:
                if machine in machines_data:
                    sorted_machines_data.append({&#39;machine&#39;: machine, &#39;data&#39;: machines_data[machine]})
            if &#39;1500T&#39; in machines_data:
                sorted_machines_data.append({&#39;machine&#39;: &#39;1500T&#39;, &#39;data&#39;: machines_data[&#39;1500T&#39;]})
            for machine in [&#39;277&#39;, &#39;278&#39;]:
                if machine in machines_data:
                    sorted_machines_data.append({&#39;machine&#39;: machine, &#39;data&#39;: machines_data[machine]})


        except Exception as e:
            print(f&#34;[ERROR] Error processing time blocks: {e}&#34;)
    
    return render(request, &#39;prod_query/press_oee3.html&#39;, {
        &#39;sorted_machines_data&#39;: sorted_machines_data if &#39;sorted_machines_data&#39; in locals() else [],
        &#39;start_date&#39;: start_date_str,
        &#39;end_date&#39;: end_date_str,
    })</code></pre>
</details>
<div class="desc"><p>Compute and display detailed OEE metrics for multiple press machines over a date range.</p>
<p>Only handles POST requests with form fields:
- <code>start_date</code> (YYYY-MM-DD)
- <code>end_date</code>
(YYYY-MM-DD)</p>
<h2 id="workflow">Workflow</h2>
<ol>
<li>Parse and validate <code>start_date</code> and <code>end_date</code> (if equal, subtract 24h from start).</li>
<li>Generate custom time blocks between the dates.</li>
<li>For each block and each machine in ['272','273','277','278']:
a. Fetch changeover records and append to <code>part_numbers_data</code>.
b. Retrieve production counts and raw downtime intervals.
c. Fetch PR downtime entries, annotate overlap vs. non-overlap.
d. Build <code>downtime_events</code> for intervals &gt;5 minutes.
e. Calculate running intervals, per-interval production, targets, and down-time splits.
f. Summarize contiguous run intervals; append to <code>running_events</code>.</li>
<li>After all blocks, compute per-machine totals:</li>
<li>uptime, planned vs. unplanned downtime, potential minutes,
weighted cycle time, parts produced, target, A, P, and overall OEE.</li>
<li>Aggregate defined machine groups (e.g., '1500T' = ['272','273']).</li>
<li>Prepare <code>sorted_machines_data</code> in the desired display order.</li>
</ol>
<p>Context passed to template:
- <code>sorted_machines_data</code>: list of <code>{machine: id, data: {...}}</code>, including group entries.
- <code>start_date</code>, <code>end_date</code>: strings for form persistence.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The HTTP POST request containing <code>start_date</code> and <code>end_date</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders 'prod_query/press_oee3.html' with the computed metrics context.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.prod_query"><code class="name flex">
<span>def <span class="ident">prod_query</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prod_query(request):
    &#34;&#34;&#34;
    Render and process machine production inquiries over various time windows.

    On GET:
      - Instantiate an empty `MachineInquiryForm` and render the &#39;prod_query/prod_query.html&#39; template.

    On POST (when `form.is_valid()`):
      1. Extract form fields:
         - `inquiry_date` (date): the date to query.
         - `times` (int): a code indicating the time window:
             • 1–6: eight consecutive 1-hour buckets
             • 7–8: three 8-hour shift buckets (24 h total)
             • 9–10: seven daily buckets (1 week)
             • 11–12: twenty-one consecutive 8-h shift buckets (1 week)
         - `machines` (list of str): machine identifiers; code also queries variants
             with &#34;REJ&#34; and &#34;AS&#34; suffixes.
         - `parts` (list of str, optional): part numbers to filter.

      2. Compute `shift_start` and `shift_end` datetimes via `shift_start_end_from_form_times()`.
      3. Build a parameterized SQL query against `GFxPRoduction`, grouping counts into
         the appropriate time buckets based on `times`, filtering by `Machine` and `Part`.
      4. Execute the query for each machine variant, aggregate results into `results`.
      5. Compute per-bucket totals across all machines.
      6. If weekly-shift mode (`times` 11 or 12), package the 21 shift totals into a dict
         mapping each day of the week to its three shifts.
      7. Measure query execution time and add to context.

    Context Variables
    -----------------
    form                : MachineInquiryForm
    production          : list of lists
        Each row: [Machine, Part, bucket1, bucket2, …, total]
    totals              : list of numeric
        Sum of each time bucket across all rows.
    packaged_shifts     : dict (optional)
        For weekly-shift queries, maps weekdays to lists of three shift totals.
    start, end          : datetime
        Computed shift start/end times.
    ts                  : int
        Unix timestamp of `shift_start`.
    times               : int
        The selected time-window code.
    is_weekly_shifts    : bool
        True if `times` indicates weekly-shift mode.
    elapsed_time        : float
        Seconds taken to execute the query loop.

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming request. Supports GET (renders form) and POST (processes inquiry).

    Returns
    -------
    django.http.HttpResponse
        Renders &#39;prod_query/prod_query.html&#39; with the populated context.
    &#34;&#34;&#34;
    context = {}
    if request.method == &#39;GET&#39;:
        form = MachineInquiryForm()

    if request.method == &#39;POST&#39;:
        tic = time.time()

        form = MachineInquiryForm(request.POST)
        results = []

        if form.is_valid():
            # print(&#39;form valid&#39;)

            inquiry_date = form.cleaned_data.get(&#39;inquiry_date&#39;)

            times = form.cleaned_data.get(&#39;times&#39;)

            machines = form.cleaned_data.get(&#39;machines&#39;)

            machine_list = []
            for machine in machines:
                machine = machine.strip()
                machine_list.append(machine)
                machine_list.append(f&#39;{machine}REJ&#39;)
                machine_list.append(f&#39;{machine}AS&#39;)

            # build list of parts with quotes and commas for sql IN clause
            parts = form.cleaned_data.get(&#39;parts&#39;)

            part_list = &#39;&#39;
            for part in parts:
                part_list += f&#39;&#34;{part.strip()}&#34;, &#39;
            part_list = part_list[:-2]

            shift_start, shift_end = shift_start_end_from_form_times(inquiry_date, times)

            shift_start_ts = datetime.timestamp(shift_start)
            
            # Initialize &#39;sql&#39; to none before building it
            sql = None

            if int(times) &lt;= 6:  # 8 hour query
                sql = &#39;SELECT Machine, Part, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts) + &#39; AND TimeStamp &lt;= &#39; + \
                    str(shift_start_ts + 3600) + \
                    &#39; THEN 1 ELSE 0 END) as hour1, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 3600) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 7200) + \
                    &#39; THEN 1 ELSE 0 END) as hour2, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 7200) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 10800) + \
                    &#39; THEN 1 ELSE 0 END) as hour3, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 10800) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 14400) + \
                    &#39; THEN 1 ELSE 0 END) as hour4, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 14400) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 18000) + \
                    &#39; THEN 1 ELSE 0 END) as hour5, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 18000) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 21600) + \
                    &#39; THEN 1 ELSE 0 END) as hour6, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 21600) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 25200) + \
                    &#39; THEN 1 ELSE 0 END) as hour7, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts +
                                                           25200) + &#39; THEN 1 ELSE 0 END) AS hour8 &#39;
                sql += &#39;FROM GFxPRoduction &#39;
                sql += &#39;WHERE TimeStamp &gt;= &#39; + \
                    str(shift_start_ts) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 28800) + &#39; &#39;
                if machine:
                    sql += &#39;AND Machine = %s &#39;
                if len(part_list):
                    sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
                sql += &#39;GROUP BY Part &#39;
                sql += &#39;ORDER BY Part ASC;&#39;

            elif int(times) &lt;= 8:  # 24 hour by shift query
                sql = &#39;SELECT Machine, Part, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts) + &#39; AND TimeStamp &lt;= &#39; + \
                    str(shift_start_ts + 28800) + \
                    &#39; THEN 1 ELSE 0 END) as shift1, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 28800) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 57600) + \
                    &#39; THEN 1 ELSE 0 END) as shift2, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts +
                                                           57600) + &#39; THEN 1 ELSE 0 END) AS shift3 &#39;
                sql += &#39;FROM GFxPRoduction &#39;
                sql += &#39;WHERE TimeStamp &gt;= &#39; + \
                    str(shift_start_ts) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 86400) + &#39; &#39;
                if machine:
                    sql += &#39;AND Machine = %s &#39;
                if len(part_list):
                    sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
                sql += &#39;GROUP BY Part &#39;
                sql += &#39;ORDER BY Part ASC;&#39;

            elif int(times) == 9 or int(times) == 10:  # week at a time query
                sql = &#39;SELECT Machine, Part, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts) + &#39; AND TimeStamp &lt;= &#39; + \
                    str(shift_start_ts + 86400) + \
                    &#39; THEN 1 ELSE 0 END) as mon, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 86400) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 172800) + \
                    &#39; THEN 1 ELSE 0 END) as tue, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 172800) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 259200) + \
                    &#39; THEN 1 ELSE 0 END) as wed, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 259200) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 345600) + \
                    &#39; THEN 1 ELSE 0 END) as thur, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 345600) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 432000) + \
                    &#39; THEN 1 ELSE 0 END) as fri, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 432000) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 518400) + \
                    &#39; THEN 1 ELSE 0 END) as sat, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + \
                    str(shift_start_ts + 518400) + \
                    &#39; THEN 1 ELSE 0 END) AS sun &#39;
                sql += &#39;FROM GFxPRoduction &#39;
                sql += &#39;WHERE TimeStamp &gt;= &#39; + \
                    str(shift_start_ts) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 604800) + &#39; &#39;
                if machine:
                    sql += &#39;AND Machine = %s &#39;
                if len(part_list):
                    sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
                sql += &#39;GROUP BY Part &#39;
                sql += &#39;ORDER BY Part ASC;&#39;

            elif int(times) in [11, 12]:  # Week by 8-hour shifts
                sql = &#39;SELECT Machine, Part, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 28800) + &#39; THEN 1 ELSE 0 END) as shift1, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 28800) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 57600) + &#39; THEN 1 ELSE 0 END) as shift2, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 57600) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 86400) + &#39; THEN 1 ELSE 0 END) as shift3, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 86400) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 115200) + &#39; THEN 1 ELSE 0 END) as shift4, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 115200) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 144000) + &#39; THEN 1 ELSE 0 END) as shift5, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 144000) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 172800) + &#39; THEN 1 ELSE 0 END) as shift6, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 172800) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 201600) + &#39; THEN 1 ELSE 0 END) as shift7, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 201600) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 230400) + &#39; THEN 1 ELSE 0 END) as shift8, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 230400) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 259200) + &#39; THEN 1 ELSE 0 END) as shift9, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 259200) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 288000) + &#39; THEN 1 ELSE 0 END) as shift10, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 288000) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 316800) + &#39; THEN 1 ELSE 0 END) as shift11, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 316800) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 345600) + &#39; THEN 1 ELSE 0 END) as shift12, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 345600) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 374400) + &#39; THEN 1 ELSE 0 END) as shift13, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 374400) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 403200) + &#39; THEN 1 ELSE 0 END) as shift14, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 403200) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 432000) + &#39; THEN 1 ELSE 0 END) as shift15, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 432000) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 460800) + &#39; THEN 1 ELSE 0 END) as shift16, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 460800) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 489600) + &#39; THEN 1 ELSE 0 END) as shift17, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 489600) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 518400) + &#39; THEN 1 ELSE 0 END) as shift18, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 518400) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 547200) + &#39; THEN 1 ELSE 0 END) as shift19, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 547200) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 576000) + &#39; THEN 1 ELSE 0 END) as shift20, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 576000) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 604800) + &#39; THEN 1 ELSE 0 END) as shift21 &#39;
                sql += &#39;FROM GFxPRoduction &#39;
                sql += &#39;WHERE TimeStamp &gt;= &#39; + str(shift_start_ts) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 604800) + &#39; &#39;
                if machine:
                    sql += &#39;AND Machine = %s &#39;
                if len(part_list):
                    sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
                sql += &#39;GROUP BY Part &#39;
                sql += &#39;ORDER BY Part ASC;&#39;


            # Fetch data and process results
            cursor = connections[&#39;prodrpt-md&#39;].cursor()
            try:
                for machine in machine_list:
                    cursor.execute(sql, [machine])
                    result = cursor.fetchall()
                    for row in result:
                        machine = row[0]
                        if machine.endswith(&#39;REJ&#39;):
                            machine = machine[:-3]
                        row = list(row)
                        row.append(sum(row[2:]))  # Calculate the total for all shifts
                        results.append(row)
            except Exception as e:
                print(&#34;Oops!&#34;, e, &#34;occurred.&#34;)
            finally:
                cursor.close()

            # Calculate totals for each shift
            totals = [0] * (len(results[0]) - 2) if results else []  # Initialize totals list
            for row in results:
                for i, value in enumerate(row[2:], start=0):  # Start from the first shift column
                    if isinstance(value, (int, float)):
                        totals[i] += value

            # # Debug: Print totals for each shift
            # for i, total in enumerate(totals, start=1):
                # print(f&#34;Shift {i} Total: {total}&#34;)

            # Package shifts into days if weekly shifts selected
            packaged_shifts = {}
            if int(times) in [11, 12]:  # Week by 8-hour shifts
                packaged_shifts = {
                    &#34;Monday&#34;: totals[0:3],
                    &#34;Tuesday&#34;: totals[3:6],
                    &#34;Wednesday&#34;: totals[6:9],
                    &#34;Thursday&#34;: totals[9:12],
                    &#34;Friday&#34;: totals[12:15],
                    &#34;Saturday&#34;: totals[15:18],
                    &#34;Sunday&#34;: totals[18:21],
                }

            # Debug: Print the packaged shifts for each day
            # print(&#34;Packaged Shifts by Day:&#34;)
            # for day, shifts in packaged_shifts.items():
            #     print(f&#34;{day}: {shifts}&#34;)

            # Update context
            context[&#39;packaged_shifts&#39;] = packaged_shifts
            context[&#39;production&#39;] = results
            context[&#39;totals&#39;] = totals
            context[&#39;start&#39;] = shift_start
            context[&#39;end&#39;] = shift_end
            context[&#39;ts&#39;] = int(shift_start_ts)
            context[&#39;times&#39;] = int(times)
            context[&#39;is_weekly_shifts&#39;] = int(times) in [11, 12]  # Add flag for weekly shifts

            toc = time.time()
            context[&#39;elapsed_time&#39;] = toc - tic

    context[&#39;form&#39;] = form

    return render(request, &#39;prod_query/prod_query.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Render and process machine production inquiries over various time windows.</p>
<p>On GET:
- Instantiate an empty <code>MachineInquiryForm</code> and render the 'prod_query/prod_query.html' template.</p>
<p>On POST (when <code>form.is_valid()</code>):
1. Extract form fields:
- <code>inquiry_date</code> (date): the date to query.
- <code>times</code> (int): a code indicating the time window:
• 1–6: eight consecutive 1-hour buckets
• 7–8: three 8-hour shift buckets (24 h total)
• 9–10: seven daily buckets (1 week)
• 11–12: twenty-one consecutive 8-h shift buckets (1 week)
- <code>machines</code> (list of str): machine identifiers; code also queries variants
with "REJ" and "AS" suffixes.
- <code>parts</code> (list of str, optional): part numbers to filter.</p>
<ol>
<li>Compute <code>shift_start</code> and <code>shift_end</code> datetimes via <code><a title="prod_query.views.shift_start_end_from_form_times" href="#prod_query.views.shift_start_end_from_form_times">shift_start_end_from_form_times()</a></code>.</li>
<li>Build a parameterized SQL query against <code>GFxPRoduction</code>, grouping counts into
the appropriate time buckets based on <code>times</code>, filtering by <code>Machine</code> and <code>Part</code>.</li>
<li>Execute the query for each machine variant, aggregate results into <code>results</code>.</li>
<li>Compute per-bucket totals across all machines.</li>
<li>If weekly-shift mode (<code>times</code> 11 or 12), package the 21 shift totals into a dict
mapping each day of the week to its three shifts.</li>
<li>Measure query execution time and add to context.</li>
</ol>
<h2 id="context-variables">Context Variables</h2>
<p>form
: MachineInquiryForm
production
: list of lists
Each row: [Machine, Part, bucket1, bucket2, …, total]
totals
: list of numeric
Sum of each time bucket across all rows.
packaged_shifts
: dict (optional)
For weekly-shift queries, maps weekdays to lists of three shift totals.
start, end
: datetime
Computed shift start/end times.
ts
: int
Unix timestamp of <code>shift_start</code>.
times
: int
The selected time-window code.
is_weekly_shifts
: bool
True if <code>times</code> indicates weekly-shift mode.
elapsed_time
: float
Seconds taken to execute the query loop.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming request. Supports GET (renders form) and POST (processes inquiry).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders 'prod_query/prod_query.html' with the populated context.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.prod_query_index_view"><code class="name flex">
<span>def <span class="ident">prod_query_index_view</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prod_query_index_view(request):
    &#34;&#34;&#34;
    Render the main index page for production query tools.

    This view prepares basic page metadata and displays the entry point
    for all production-related query interfaces.

    Context
    -------
    main_heading : str
        The primary heading displayed on the page (&#34;Prod Query Index&#34;).
    title : str
        The HTML `&lt;title&gt;` for the page (&#34;Prod Query Index - pmsdata12&#34;).

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP GET request.

    Returns
    -------
    django.http.HttpResponse
        Renders &#39;prod_query/index_prod_query.html&#39; with the above context.
    &#34;&#34;&#34;
    context = {}
    context[&#34;main_heading&#34;] = &#34;Prod Query Index&#34;
    context[&#34;title&#34;] = &#34;Prod Query Index - pmsdata12&#34;
    return render(request, f&#39;prod_query/index_prod_query.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Render the main index page for production query tools.</p>
<p>This view prepares basic page metadata and displays the entry point
for all production-related query interfaces.</p>
<h2 id="context">Context</h2>
<p>main_heading : str
The primary heading displayed on the page ("Prod Query Index").
title : str
The HTML <code>&lt;title&gt;</code> for the page ("Prod Query Index - pmsdata12").</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP GET request.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders 'prod_query/index_prod_query.html' with the above context.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.production_from_cycletime"><code class="name flex">
<span>def <span class="ident">production_from_cycletime</span></span>(<span>cycle_time)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def production_from_cycletime(cycle_time):
    &#34;&#34;&#34;
    Calculates theoretical production for an hour based on the cycle time.
    &#34;&#34;&#34;
    if cycle_time == 0:
        return 0  # No production if cycle time is zero
    return int(3600 / cycle_time)  # How many parts could be made in 1 hour</code></pre>
</details>
<div class="desc"><p>Calculates theoretical production for an hour based on the cycle time.</p></div>
</dd>
<dt id="prod_query.views.recalculate_adjusted_targets"><code class="name flex">
<span>def <span class="ident">recalculate_adjusted_targets</span></span>(<span>aggregated_metrics, average_downtime)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def recalculate_adjusted_targets(aggregated_metrics, average_downtime):
    &#34;&#34;&#34;
    Recalculate total adjusted targets for machines using average percentage downtime.

    Args:
        aggregated_metrics (list): Aggregated metrics for machines.
        average_downtime (dict): Average downtime percentages for machines.

    Returns:
        list: Updated aggregated metrics with recalculated adjusted targets.
    &#34;&#34;&#34;
    for machine in aggregated_metrics:
        machine_id = machine[&#39;machine_id&#39;]
        if machine_id in average_downtime:
            # Truncate average downtime percentage to 2 decimal places
            average_downtime_percentage = float(f&#34;{average_downtime[machine_id] / 100:.2f}&#34;)
            total_target = machine[&#39;total_target&#39;]

            # Debugging: Print values before calculation
            # print(f&#34;[DEBUG] Machine {machine_id}: Total Target = {total_target}, Average Downtime = {average_downtime[machine_id]}%&#34;)

            # Adjusted target calculation
            adjusted_target = int(total_target * (1 - average_downtime_percentage))

            # Debugging: Print the adjusted target calculation step
            # print(f&#34;[DEBUG] Machine {machine_id}: Adjusted Target Calculation = {total_target} * (1 - {average_downtime_percentage}) = {adjusted_target}&#34;)

            # Assign the calculated adjusted target
            machine[&#39;total_adjusted_target&#39;] = adjusted_target
        else:
            # Debugging: If no downtime data is found for a machine
            print(f&#34;[DEBUG] Machine {machine_id}: No Average Downtime Found. Using Total Target = {machine[&#39;total_target&#39;]}&#34;)
    return aggregated_metrics</code></pre>
</details>
<div class="desc"><p>Recalculate total adjusted targets for machines using average percentage downtime.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>aggregated_metrics</code></strong> :&ensp;<code>list</code></dt>
<dd>Aggregated metrics for machines.</dd>
<dt><strong><code>average_downtime</code></strong> :&ensp;<code>dict</code></dt>
<dd>Average downtime percentages for machines.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>Updated aggregated metrics with recalculated adjusted targets.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.reject_query"><code class="name flex">
<span>def <span class="ident">reject_query</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reject_query(request):
    &#34;&#34;&#34;
    Render and process reject-rate inquiries for selected machines and parts.

    On every request:
      - Query the distinct machine-part combinations available in the
        `01_vw_production_rejects` view and expose them as `available`.

    On GET:
      - Instantiate an empty `MachineInquiryForm` and render the 
        &#39;prod_query/reject_query.html&#39; template with `available` and `form`.

    On POST (when `form.is_valid()`):
      1. Extract from the form:
         - `inquiry_date` (date)
         - `times` (int code for time window, 1–6 hour buckets, 7–8 shifts, or week)
         - `machines` (list of identifiers)
         - `parts` (list of part numbers)
      2. Compute `shift_start` and `shift_end` via `shift_start_end_from_form_times()`.
      3. Build a SQL query against `01_vw_production_rejects` that counts rejects
         per time bucket (hourly, shift, or daily), filtered by the selected
         machines and parts.
      4. Execute the query, fetch rows, append a total-per-row column, and
         collect into `production`.
      5. Record query execution time as `elapsed_time`.

    Context Variables
    -----------------
    available     : list of [Part, Machine]
        Distinct combinations for form selection.
    form          : MachineInquiryForm
    production    : list of lists
        Each row: [Machine, Part, bucket1, bucket2, …, total]
    start, end    : datetime.datetime
        Computed window boundaries.
    ts            : float
        Unix timestamp of `shift_start`.
    times         : int
        The selected time-window code.
    elapsed_time  : float
        Seconds taken to run the query.
    title         : str
        Page title (&#34;Production&#34;).

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request, supporting GET and POST methods.

    Returns
    -------
    django.http.HttpResponse
        Renders &#39;prod_query/reject_query.html&#39; with the above context.
    &#34;&#34;&#34;
    context = {}
    tic = time.time()

    available_results = []
    available_sql = &#39;SELECT DISTINCT(CONCAT(Machine,Part)) AS cc, Part, Machine FROM 01_vw_production_rejects ORDER BY Part, Machine;&#39;
    cursor = connections[&#39;prodrpt-md&#39;].cursor()
    try:
        cursor.execute(available_sql)
        result = cursor.fetchall()
        for row in result:
            row = list(row[1:])
            available_results.append(row)
    except Exception as e:
        print(&#34;Oops!&#34;, e, &#34;occurred.&#34;)
    finally:
        cursor.close()
    context[&#39;available&#39;] = available_results

    if request.method == &#39;GET&#39;:
        form = MachineInquiryForm()

    if request.method == &#39;POST&#39;:
        tic = time.time()

        form = MachineInquiryForm(request.POST)
        results = []

        if form.is_valid():

            inquiry_date = form.cleaned_data.get(&#39;inquiry_date&#39;)
            times = form.cleaned_data.get(&#39;times&#39;)

            # build list of machines with quotes and commas
            machines = form.cleaned_data.get(&#39;machines&#39;)

            machine_list = &#39;&#39;
            for machine in machines:
                machine_list += f&#39;&#34;{machine.strip()}&#34;, &#39;
            machine_list = machine_list[:-2]

            parts = form.cleaned_data.get(&#39;parts&#39;)

            part_list = &#39;&#39;
            for part in parts:
                part_list += f&#39;&#34;{part.strip()}&#34;, &#39;
            part_list = part_list[:-2]

            shift_start, shift_end = shift_start_end_from_form_times(inquiry_date, times)

            shift_start_ts = datetime.timestamp(shift_start)

            if int(times) &lt;= 6:  # 8 hour query
                sql = &#39;SELECT Machine, Part, Reason, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts) + &#39; AND TimeStamp &lt;= &#39; + \
                    str(shift_start_ts + 3600) + \
                    &#39; THEN 1 ELSE 0 END) as hour1, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 3600) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 7200) + \
                    &#39; THEN 1 ELSE 0 END) as hour2, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 7200) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 10800) + \
                    &#39; THEN 1 ELSE 0 END) as hour3, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 10800) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 14400) + \
                    &#39; THEN 1 ELSE 0 END) as hour4, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 14400) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 18000) + \
                    &#39; THEN 1 ELSE 0 END) as hour5, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 18000) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 21600) + \
                    &#39; THEN 1 ELSE 0 END) as hour6, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 21600) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 25200) + \
                    &#39; THEN 1 ELSE 0 END) as hour7, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts +
                                                           25200) + &#39; THEN 1 ELSE 0 END) AS hour8 &#39;
                sql += &#39;FROM `01_vw_production_rejects` &#39;
                sql += &#39;WHERE TimeStamp &gt;= &#39; + \
                    str(shift_start_ts) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 28800) + &#39; &#39;
                if len(machine_list):
                    sql += &#39;AND Machine IN (&#39; + machine_list + &#39;) &#39;
                if len(part_list):
                    sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
                sql += &#39;GROUP BY Machine, Reason, Part &#39;
                sql += &#39;ORDER BY Part ASC, Machine ASC, Reason ASC;&#39;

            elif int(times) &lt;= 8:  # 24 hour by shift query
                sql = &#39;SELECT Machine, Part, Reason, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts) + &#39; AND TimeStamp &lt;= &#39; + \
                    str(shift_start_ts + 28800) + \
                    &#39; THEN 1 ELSE 0 END) as shift1, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 28800) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 57600) + \
                    &#39; THEN 1 ELSE 0 END) as shift2, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts +
                                                           57600) + &#39; THEN 1 ELSE 0 END) AS shift3 &#39;
                sql += &#39;FROM `01_vw_production_rejects` &#39;
                sql += &#39;WHERE TimeStamp &gt;= &#39; + \
                    str(shift_start_ts) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 86400) + &#39; &#39;
                if len(machine_list):
                    sql += &#39;AND Machine IN (&#39; + machine_list + &#39;) &#39;
                if len(part_list):
                    sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
                sql += &#39;GROUP BY Machine, Reason, Part &#39;
                sql += &#39;ORDER BY Part ASC, Machine ASC, Reason ASC;&#39;

            else:  # week at a time query
                sql = &#39;SELECT Machine, Part, Reason, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts) + &#39; AND TimeStamp &lt;= &#39; + \
                    str(shift_start_ts + 86400) + \
                    &#39; THEN 1 ELSE 0 END) as mon, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 86400) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 172800) + \
                    &#39; THEN 1 ELSE 0 END) as tue, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 172800) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 259200) + \
                    &#39; THEN 1 ELSE 0 END) as wed, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 259200) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 345600) + \
                    &#39; THEN 1 ELSE 0 END) as thur, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 345600) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 432000) + \
                    &#39; THEN 1 ELSE 0 END) as fri, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + str(shift_start_ts + 432000) + \
                    &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 518400) + \
                    &#39; THEN 1 ELSE 0 END) as sat, &#39;
                sql += &#39;SUM(CASE WHEN TimeStamp &gt;= &#39; + \
                    str(shift_start_ts + 518400) + \
                    &#39; THEN 1 ELSE 0 END) AS sun &#39;
                sql += &#39;FROM `01_vw_production_rejects` &#39;
                sql += &#39;WHERE TimeStamp &gt;= &#39; + \
                    str(shift_start_ts) + &#39; AND TimeStamp &lt; &#39; + \
                    str(shift_start_ts + 604800) + &#39; &#39;
                if len(machine_list):
                    sql += &#39;AND Machine IN (&#39; + machine_list + &#39;) &#39;
                if len(part_list):
                    sql += &#39;AND Part IN (&#39; + part_list + &#39;) &#39;
                sql += &#39;GROUP BY Machine, Reason, Part &#39;
                sql += &#39;ORDER BY Part ASC, Machine ASC, Reason ASC;&#39;

            cursor = connections[&#39;prodrpt-md&#39;].cursor()
            print(sql)
            try:
                cursor.execute(sql)
                result = cursor.fetchall()

                for row in result:
                    row = list(row)
                    row.append(sum(row[3:]))
                    results.append(row)

            except Exception as e:
                print(&#34;Oops!&#34;, e, &#34;occurred.&#34;)
            finally:
                cursor.close()

            context[&#39;production&#39;] = results
            context[&#39;start&#39;] = shift_start
            context[&#39;end&#39;] = shift_end
            context[&#39;ts&#39;] = shift_start_ts
            context[&#39;times&#39;] = int(times)

            toc = time.time()
            context[&#39;elapsed_time&#39;] = toc-tic
            logger.info(sql)
            logger.info(
                f&#39;[{toc-tic:.3f}] machines=&#34;{machines}&#34; parts=&#34;{parts}&#34; times=&#34;{times}&#34; date=&#34;{inquiry_date}&#34; {datetime.isoformat(shift_start)} {shift_start_ts:.0f}&#39;)

    context[&#39;form&#39;] = form
    context[&#39;title&#39;] = &#39;Production&#39;

    return render(request, &#39;prod_query/reject_query.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Render and process reject-rate inquiries for selected machines and parts.</p>
<p>On every request:
- Query the distinct machine-part combinations available in the
<code>01_vw_production_rejects</code> view and expose them as <code>available</code>.</p>
<p>On GET:
- Instantiate an empty <code>MachineInquiryForm</code> and render the
'prod_query/reject_query.html' template with <code>available</code> and <code>form</code>.</p>
<p>On POST (when <code>form.is_valid()</code>):
1. Extract from the form:
- <code>inquiry_date</code> (date)
- <code>times</code> (int code for time window, 1–6 hour buckets, 7–8 shifts, or week)
- <code>machines</code> (list of identifiers)
- <code>parts</code> (list of part numbers)
2. Compute <code>shift_start</code> and <code>shift_end</code> via <code><a title="prod_query.views.shift_start_end_from_form_times" href="#prod_query.views.shift_start_end_from_form_times">shift_start_end_from_form_times()</a></code>.
3. Build a SQL query against <code>01_vw_production_rejects</code> that counts rejects
per time bucket (hourly, shift, or daily), filtered by the selected
machines and parts.
4. Execute the query, fetch rows, append a total-per-row column, and
collect into <code>production</code>.
5. Record query execution time as <code>elapsed_time</code>.</p>
<h2 id="context-variables">Context Variables</h2>
<p>available
: list of [Part, Machine]
Distinct combinations for form selection.
form
: MachineInquiryForm
production
: list of lists
Each row: [Machine, Part, bucket1, bucket2, …, total]
start, end
: datetime.datetime
Computed window boundaries.
ts
: float
Unix timestamp of <code>shift_start</code>.
times
: int
The selected time-window code.
elapsed_time
: float
Seconds taken to run the query.
title
: str
Page title ("Production").</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request, supporting GET and POST methods.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders 'prod_query/reject_query.html' with the above context.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.save_machine_target"><code class="name flex">
<span>def <span class="ident">save_machine_target</span></span>(<span>machine_id, effective_date, target, line=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_machine_target(machine_id, effective_date, target, line=None):
    &#34;&#34;&#34;
    Save or update a machine target record in the database.

    :param machine_id: ID of the machine
    :param effective_date: Effective date in &#34;YYYY-MM-DD&#34; format
    :param target: Target value to save
    :param line: Line value to save
    :return: Saved or updated OAMachineTargets instance
    &#34;&#34;&#34;
    try:
        # Convert effective_date to Unix timestamp
        date_obj = datetime.strptime(effective_date, &#34;%Y-%m-%d&#34;)
        unix_timestamp = int(time.mktime(date_obj.timetuple()))
    except ValueError as e:
        raise ValueError(f&#34;Invalid effective date format: {effective_date}&#34;) from e

    # Check if an entry already exists for the machine, line, and effective date
    record, created = OAMachineTargets.objects.update_or_create(
        machine_id=machine_id,
        line=line,  # Include the line in the filter criteria
        effective_date_unix=unix_timestamp,
        defaults={&#34;target&#34;: target},
    )
    return record, created</code></pre>
</details>
<div class="desc"><p>Save or update a machine target record in the database.</p>
<p>:param machine_id: ID of the machine
:param effective_date: Effective date in "YYYY-MM-DD" format
:param target: Target value to save
:param line: Line value to save
:return: Saved or updated OAMachineTargets instance</p></div>
</dd>
<dt id="prod_query.views.shift_start_end_from_form_times"><code class="name flex">
<span>def <span class="ident">shift_start_end_from_form_times</span></span>(<span>inquiry_date, times)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shift_start_end_from_form_times(inquiry_date, times):
    &#34;&#34;&#34;
    Determine the start and end datetimes for predefined shift windows.

    Given a date and a shift code (as string), returns the corresponding
    shift’s start and end as naive `datetime` objects.

    Shift Codes
    -----------
    &#39;1&#39;  : Night shift, 10:00 PM (previous day) → 6:00 AM
    &#39;2&#39;  : Night shift, 11:00 PM (previous day) → 7:00 AM
    &#39;3&#39;  : Day shift, 6:00 AM → 2:00 PM
    &#39;4&#39;  : Day shift, 7:00 AM → 3:00 PM
    &#39;5&#39;  : Afternoon, 2:00 PM → 10:00 PM
    &#39;6&#39;  : Afternoon, 3:00 PM → 11:00 PM
    &#39;7&#39;  : 24-hour window, 6:00 AM → next day 6:00 AM
    &#39;8&#39;  : 24-hour window, 7:00 AM → next day 7:00 AM
    &#39;9&#39;  : Weekly window starting Sunday 10:00 PM → 7 days later
    &#39;10&#39; : Weekly window starting Sunday 11:00 PM → 7 days later
    &#39;11&#39; : Week-by-shifts, Sunday 10:00 PM start → 7 days later
    &#39;12&#39; : Week-by-shifts, Sunday 11:00 PM start → 7 days later

    Parameters
    ----------
    inquiry_date : datetime.date
        The date from which to calculate the shift window.
    times : str
        A code &#39;1&#39;–&#39;12&#39; indicating which predefined shift or window to use.

    Returns
    -------
    tuple of (datetime.datetime, datetime.datetime)
        A 2-tuple of naive datetimes: (`shift_start`, `shift_end`).
    &#34;&#34;&#34;
    if times == &#39;1&#39;:  # 10pm - 6am
        shift_start = datetime(
                    inquiry_date.year, inquiry_date.month, inquiry_date.day, 22, 0, 0)-timedelta(days=1)
        shift_end = shift_start + timedelta(hours=8)
    elif times == &#39;2&#39;:  # 11pm - 7am
        shift_start = datetime(
                    inquiry_date.year, inquiry_date.month, inquiry_date.day, 23, 0, 0)-timedelta(days=1)
        shift_end = shift_start + timedelta(hours=8)
    elif times == &#39;3&#39;:  # 6am - 2pm
        shift_start = datetime(
                    inquiry_date.year, inquiry_date.month, inquiry_date.day, 6, 0, 0)
        shift_end = shift_start + timedelta(hours=8)
    elif times == &#39;4&#39;:  # 7am - 3pm
        shift_start = datetime(
                    inquiry_date.year, inquiry_date.month, inquiry_date.day, 7, 0, 0)
        shift_end = shift_start + timedelta(hours=8)
    elif times == &#39;5&#39;:  # 2pm - 10pm
        shift_start = datetime(
                    inquiry_date.year, inquiry_date.month, inquiry_date.day, 14, 0, 0)
        shift_end = shift_start + timedelta(hours=8)
    elif times == &#39;6&#39;:  # 3pm - 11pm
        shift_start = datetime(
                    inquiry_date.year, inquiry_date.month, inquiry_date.day, 15, 0, 0)
        shift_end = shift_start + timedelta(hours=8)

    elif times == &#39;7&#39;:  # 6am - 6am
        shift_start = datetime(
                    inquiry_date.year, inquiry_date.month, inquiry_date.day, 6, 0, 0)
        shift_end = shift_start + timedelta(days=1)
    elif times == &#39;8&#39;:  # 7am - 7am
        shift_start = datetime(
                    inquiry_date.year, inquiry_date.month, inquiry_date.day, 7, 0, 0)
        shift_end = shift_start + timedelta(days=1)

    elif times == &#39;9&#39;:  # 11pm to 11pm week
        days_past_sunday = inquiry_date.isoweekday() % 7
        shift_start = datetime(inquiry_date.year, inquiry_date.month,
                                       inquiry_date.day, 22, 0, 0)-timedelta(days=days_past_sunday)
        shift_end = shift_start + timedelta(days=7)
    elif times == &#39;10&#39;:  # 10pm to 10pmn week
        days_past_sunday = inquiry_date.isoweekday() % 7
        shift_start = datetime(inquiry_date.year, inquiry_date.month,
                                       inquiry_date.day, 23, 0, 0)-timedelta(days=days_past_sunday)
        shift_end = shift_start + timedelta(days=7)
    elif times == &#39;11&#39;:  # Week by Shifts (Sunday 10pm start)
        days_past_sunday = inquiry_date.isoweekday() % 7
        shift_start = datetime(inquiry_date.year, inquiry_date.month,
                                       inquiry_date.day, 22, 0, 0)-timedelta(days=days_past_sunday)
        shift_end = shift_start + timedelta(days=7)
    elif times == &#39;12&#39;:  # Week by Shifts (Sunday 11pm start)
        days_past_sunday = inquiry_date.isoweekday() % 7
        shift_start = datetime(inquiry_date.year, inquiry_date.month,
                                       inquiry_date.day, 23, 0, 0)-timedelta(days=days_past_sunday)
        shift_end = shift_start + timedelta(days=7)
    return shift_start,shift_end</code></pre>
</details>
<div class="desc"><p>Determine the start and end datetimes for predefined shift windows.</p>
<p>Given a date and a shift code (as string), returns the corresponding
shift’s start and end as naive <code>datetime</code> objects.</p>
<h2 id="shift-codes">Shift Codes</h2>
<p>'1'
: Night shift, 10:00 PM (previous day) → 6:00 AM
'2'
: Night shift, 11:00 PM (previous day) → 7:00 AM
'3'
: Day shift, 6:00 AM → 2:00 PM
'4'
: Day shift, 7:00 AM → 3:00 PM
'5'
: Afternoon, 2:00 PM → 10:00 PM
'6'
: Afternoon, 3:00 PM → 11:00 PM
'7'
: 24-hour window, 6:00 AM → next day 6:00 AM
'8'
: 24-hour window, 7:00 AM → next day 7:00 AM
'9'
: Weekly window starting Sunday 10:00 PM → 7 days later
'10' : Weekly window starting Sunday 11:00 PM → 7 days later
'11' : Week-by-shifts, Sunday 10:00 PM start → 7 days later
'12' : Week-by-shifts, Sunday 11:00 PM start → 7 days later</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>inquiry_date</code></strong> :&ensp;<code>datetime.date</code></dt>
<dd>The date from which to calculate the shift window.</dd>
<dt><strong><code>times</code></strong> :&ensp;<code>str</code></dt>
<dd>A code '1'–'12' indicating which predefined shift or window to use.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code> of <code>(datetime.datetime, datetime.datetime)</code></dt>
<dd>A 2-tuple of naive datetimes: (<code>shift_start</code>, <code>shift_end</code>).</dd>
</dl></div>
</dd>
<dt id="prod_query.views.shift_totals_view"><code class="name flex">
<span>def <span class="ident">shift_totals_view</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shift_totals_view(request):
    &#34;&#34;&#34;
    Display and process shift totals inquiries for one or more machines over a date range.

    On GET:
      - Renders the &#39;prod_query/shift_totals.html&#39; template with an empty ShiftTotalsForm.

    On POST:
      1. Validates the submitted ShiftTotalsForm, which includes:
         - `machine_number` (str): comma-separated machine IDs.
         - `start_date` (date): the beginning of the analysis window.
         - `end_date` (date): the end of the analysis window.
      2. Splits and strips the machine numbers.
      3. For each machine, calls `fetch_chart_data(machine, start_ts, end_ts, group_by_shift=True)`
         to retrieve four parallel lists:
         - `labels`: list of dates (YYYY-MM-DD).
         - `day_counts`: counts for the day shift.
         - `afternoon_counts`: counts for the afternoon shift.
         - `night_counts`: counts for the night shift.
         - `total_counts`: total counts across all shifts.
      4. Computes a 7-day moving average of `total_counts`, aligning the averaged labels.
      5. Builds a `chartdata` list of dictionaries, each containing:
         - `machine_number`
         - `labels`
         - `datasets`: Chart.js configurations for day, afternoon, night, and total series.
         - `moving_avg`: sub-dictionary with `labels` and `data` for the moving average.
      6. Updates the context with the bound form and `chartdata`.

    Parameters
    ----------
    request : django.http.HttpRequest
        The HTTP request object, supporting GET and POST methods.

    Returns
    -------
    django.http.HttpResponse
        Renders &#39;prod_query/shift_totals.html&#39; with context:
          - `form`: the ShiftTotalsForm (empty or bound).
          - `chartdata`: list of chart configurations for each machine (if POST and valid).
    &#34;&#34;&#34;
    context = {&#39;form&#39;: ShiftTotalsForm()}
    if request.method == &#39;POST&#39;:
        form = ShiftTotalsForm(request.POST)
        if form.is_valid():
            machine_numbers = form.cleaned_data[&#39;machine_number&#39;].split(&#39;,&#39;)
            start_date = form.cleaned_data[&#39;start_date&#39;]
            end_date = form.cleaned_data[&#39;end_date&#39;]

            chartdata = []
            for machine_number in machine_numbers:
                machine_number = machine_number.strip()
                labels, day_counts, afternoon_counts, night_counts, total_counts = fetch_chart_data(
                    machine_number, int(time.mktime(start_date.timetuple())), int(time.mktime(end_date.timetuple())), group_by_shift=True)

                window_size = 7
                moving_avg = moving_average(total_counts, window_size)
                avg_labels = labels[window_size - 1:]

                chartdata.append({
                    &#39;machine_number&#39;: machine_number,
                    &#39;labels&#39;: labels,
                    &#39;datasets&#39;: [
                        {&#39;label&#39;: &#39;Day Shift&#39;, &#39;data&#39;: day_counts, &#39;borderWidth&#39;: 1, &#39;borderColor&#39;: &#39;rgba(255, 99, 132, 1)&#39;},
                        {&#39;label&#39;: &#39;Afternoon Shift&#39;, &#39;data&#39;: afternoon_counts, &#39;borderWidth&#39;: 1, &#39;borderColor&#39;: &#39;rgba(54, 162, 235, 1)&#39;},
                        {&#39;label&#39;: &#39;Night Shift&#39;, &#39;data&#39;: night_counts, &#39;borderWidth&#39;: 1, &#39;borderColor&#39;: &#39;rgba(75, 192, 192, 1)&#39;},
                        {&#39;label&#39;: &#39;Total&#39;, &#39;data&#39;: total_counts, &#39;borderWidth&#39;: 2, &#39;borderColor&#39;: &#39;rgba(0, 0, 0, 1)&#39;, &#39;borderDash&#39;: [5, 5]}
                    ],
                    &#39;moving_avg&#39;: {
                        &#39;labels&#39;: avg_labels,
                        &#39;data&#39;: moving_avg
                    }
                })

            context.update({
                &#39;form&#39;: form,
                &#39;chartdata&#39;: chartdata
            })
        else:
            print(&#34;Form is invalid&#34;)
    return render(request, &#39;prod_query/shift_totals.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Display and process shift totals inquiries for one or more machines over a date range.</p>
<p>On GET:
- Renders the 'prod_query/shift_totals.html' template with an empty ShiftTotalsForm.</p>
<p>On POST:
1. Validates the submitted ShiftTotalsForm, which includes:
- <code>machine_number</code> (str): comma-separated machine IDs.
- <code>start_date</code> (date): the beginning of the analysis window.
- <code>end_date</code> (date): the end of the analysis window.
2. Splits and strips the machine numbers.
3. For each machine, calls <code>fetch_chart_data(machine, start_ts, end_ts, group_by_shift=True)</code>
to retrieve four parallel lists:
- <code>labels</code>: list of dates (YYYY-MM-DD).
- <code>day_counts</code>: counts for the day shift.
- <code>afternoon_counts</code>: counts for the afternoon shift.
- <code>night_counts</code>: counts for the night shift.
- <code>total_counts</code>: total counts across all shifts.
4. Computes a 7-day moving average of <code>total_counts</code>, aligning the averaged labels.
5. Builds a <code>chartdata</code> list of dictionaries, each containing:
- <code>machine_number</code>
- <code>labels</code>
- <code>datasets</code>: Chart.js configurations for day, afternoon, night, and total series.
- <code>moving_avg</code>: sub-dictionary with <code>labels</code> and <code>data</code> for the moving average.
6. Updates the context with the bound form and <code>chartdata</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The HTTP request object, supporting GET and POST methods.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders 'prod_query/shift_totals.html' with context:
- <code>form</code>: the ShiftTotalsForm (empty or bound).
- <code>chartdata</code>: list of chart configurations for each machine (if POST and valid).</dd>
</dl></div>
</dd>
<dt id="prod_query.views.stip_weekends"><code class="name flex">
<span>def <span class="ident">stip_weekends</span></span>(<span>start_date_str, end_date_str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stip_weekends(start_date_str, end_date_str):
    &#34;&#34;&#34;
    Given two date strings, remove any portions that fall between Friday 23:00 and Sunday 23:00.
    The expected format is &#34;Y-m-d H:i&#34;. If the string doesn&#39;t include a time, defaults to midnight.
    Returns a list of (start_datetime, end_datetime) tuples.
    &#34;&#34;&#34;
    import datetime
    from datetime import timedelta, time

    dt_format = &#34;%Y-%m-%d %H:%M&#34;
    date_only_format = &#34;%Y-%m-%d&#34;

    def parse_date(date_str):
        # Try the full date-time format.
        try:
            return datetime.datetime.strptime(date_str, dt_format)
        except ValueError:
            # Fall back to date-only format and assume a default time.
            try:
                date_only = datetime.datetime.strptime(date_str, date_only_format)
                # You might choose a different default time.
                return datetime.datetime.combine(date_only.date(), time(0, 0))
            except ValueError as e:
                raise ValueError(f&#34;Invalid date format for {date_str}&#34;) from e

    start = parse_date(start_date_str)
    end = parse_date(end_date_str)

    def is_in_weekend(dt):
        # Define weekend as from Friday 23:00 to Sunday 23:00.
        if dt.weekday() == 4 and dt.time() &gt;= time(23, 0):
            return True
        if dt.weekday() == 5:  # Saturday all day
            return True
        if dt.weekday() == 6 and dt.time() &lt; time(23, 0):
            return True
        return False

    intervals = []
    current = start
    while current &lt; end:
        if is_in_weekend(current):
            # Skip ahead to the end of the weekend.
            if current.weekday() == 4:
                weekend_start = datetime.datetime.combine(current.date(), time(23, 0))
            else:
                days_back = current.weekday() - 4  # Saturday:1, Sunday:2
                friday_date = current.date() - timedelta(days=days_back)
                weekend_start = datetime.datetime.combine(friday_date, time(23, 0))
            weekend_end = weekend_start + timedelta(days=2)  # Until Sunday 23:00
            current = weekend_end
            continue
        else:
            # Determine the next upcoming weekend.
            if current.weekday() == 4 and current.time() &lt; time(23, 0):
                upcoming_weekend = datetime.datetime.combine(current.date(), time(23, 0))
            else:
                days_until_friday = (4 - current.weekday()) % 7
                upcoming_friday = current.date() + timedelta(days=days_until_friday)
                upcoming_weekend = datetime.datetime.combine(upcoming_friday, time(23, 0))
            block_end = min(end, upcoming_weekend)
            intervals.append((current, block_end))
            current = block_end
    return intervals</code></pre>
</details>
<div class="desc"><p>Given two date strings, remove any portions that fall between Friday 23:00 and Sunday 23:00.
The expected format is "Y-m-d H:i". If the string doesn't include a time, defaults to midnight.
Returns a list of (start_datetime, end_datetime) tuples.</p></div>
</dd>
<dt id="prod_query.views.strokes_per_min_graph"><code class="name flex">
<span>def <span class="ident">strokes_per_min_graph</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def strokes_per_min_graph(request):
    &#34;&#34;&#34;
    Display and retrieve data for a strokes-per-minute line chart over a specified time range.

    GET:
      - Instantiates an empty `CycleQueryForm` for user input.
      - Sets `numGraphPoints` to a default of 300.
      - Renders &#39;prod_query/strokes_per_minute.html&#39; with the form and default point count.

    POST:
      - Binds `CycleQueryForm` with submitted data (machine, start/end dates and times).
      - Validates and extracts:
          • machine (str)
          • start_date (date), start_time (time)
          • end_date (date), end_time (time)
      - Reads `numGraphPoints` from POST (defaults to 300), clamped to [50, 1000].
      - Computes `start_ts` and `end_ts` as Unix timestamps.
      - Calculates total minutes and derives a whole-minute `interval`:
          • If `interval == 1`, uses an internal 5-minute `effective_interval` for querying.
      - Calls `fetch_chart_data(machine, start_ts, end_ts, interval=effective_interval, group_by_shift=False)`
        to get lists of `(datetime, count)` for each bin.
      - If the original interval was 1, expands each 5-minute bin into five 1-minute points.
      - Builds `chartdata` dict with:
          - `labels`: list of datetime labels for the x-axis
          - `dataset`: dict with `label`, `data`, and `borderWidth`
      - Re-renders the template with the populated form, `numGraphPoints`, and `chartdata`.

    Context
    -------
    form : CycleQueryForm
        The input form for specifying machine and time range.
    numGraphPoints : int
        Number of data points requested by the user (50–1000).
    chartdata : dict (POST only)
        Contains `labels` (datetimes) and `dataset` (chart.js configuration).

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request (GET to show the form, POST to fetch chart data).

    Returns
    -------
    django.http.HttpResponse
        Renders &#39;prod_query/strokes_per_minute.html&#39; with the context described above.
    &#34;&#34;&#34;
    default_numGraphPoints = 300
    context = {}
    if request.method == &#39;GET&#39;:
        form = CycleQueryForm()
        context[&#39;form&#39;] = form
        context[&#39;numGraphPoints&#39;] = default_numGraphPoints
    elif request.method == &#39;POST&#39;:
        form = CycleQueryForm(request.POST)
        if form.is_valid():
            machine = form.cleaned_data[&#39;machine&#39;]
            start_date = form.cleaned_data[&#39;start_date&#39;]
            start_time = form.cleaned_data[&#39;start_time&#39;]
            end_date = form.cleaned_data[&#39;end_date&#39;]
            end_time = form.cleaned_data[&#39;end_time&#39;]
            numGraphPoints = int(request.POST.get(&#39;numGraphPoints&#39;, default_numGraphPoints))

            # clamp into [50,1000]
            numGraphPoints = max(50, min(1000, numGraphPoints))

            # build datetimes + timestamps
            start_dt = datetime.combine(start_date, start_time)
            end_dt   = datetime.combine(end_date,   end_time)
            start_ts = int(time.mktime(start_dt.timetuple()))
            end_ts   = int(time.mktime(end_dt.timetuple()))

            # compute your “ideal” interval in whole minutes
            total_minutes = (end_dt - start_dt).total_seconds() / 60
            interval      = max(int(total_minutes / numGraphPoints), 1)

            # if that interval is 1, override to 5 behind the scenes
            effective_interval = 5 if interval == 1 else interval

            # fetch with the effective interval
            labels, counts = fetch_chart_data(
                machine,
                start_ts,
                end_ts,
                interval=effective_interval,
                group_by_shift=False
            )

            # now: if we overrode (so interval==1), expand each 5m-bin
            if interval == 1:
                expanded_labels = []
                expanded_counts = []
                for dt, c in zip(labels, counts):
                    # dt is the start of a 5-minute bin; replicate it 5 times
                    for i in range(effective_interval):
                        expanded_labels.append(dt + timedelta(minutes=i))
                        expanded_counts.append(c)
                labels, counts = expanded_labels, expanded_counts

            # send to template
            context[&#39;chartdata&#39;] = {
                &#39;labels&#39;: labels,
                &#39;dataset&#39;: {
                    &#39;label&#39;: &#39;Strokes per Minute&#39;,
                    &#39;data&#39;: counts,
                    &#39;borderWidth&#39;: 1
                }
            }

        context[&#39;form&#39;]           = form
        context[&#39;numGraphPoints&#39;] = numGraphPoints

    return render(request, &#39;prod_query/strokes_per_minute.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Display and retrieve data for a strokes-per-minute line chart over a specified time range.</p>
<h2 id="get">Get</h2>
<ul>
<li>Instantiates an empty <code>CycleQueryForm</code> for user input.</li>
<li>Sets <code>numGraphPoints</code> to a default of 300.</li>
<li>Renders 'prod_query/strokes_per_minute.html' with the form and default point count.</li>
</ul>
<h2 id="post">Post</h2>
<ul>
<li>Binds <code>CycleQueryForm</code> with submitted data (machine, start/end dates and times).</li>
<li>Validates and extracts:
• machine (str)
• start_date (date), start_time (time)
• end_date (date), end_time (time)</li>
<li>Reads <code>numGraphPoints</code> from POST (defaults to 300), clamped to [50, 1000].</li>
<li>Computes <code>start_ts</code> and <code>end_ts</code> as Unix timestamps.</li>
<li>Calculates total minutes and derives a whole-minute <code>interval</code>:
• If <code>interval == 1</code>, uses an internal 5-minute <code>effective_interval</code> for querying.</li>
<li>Calls <code>fetch_chart_data(machine, start_ts, end_ts, interval=effective_interval, group_by_shift=False)</code>
to get lists of <code>(datetime, count)</code> for each bin.</li>
<li>If the original interval was 1, expands each 5-minute bin into five 1-minute points.</li>
<li>Builds <code>chartdata</code> dict with:<ul>
<li><code>labels</code>: list of datetime labels for the x-axis</li>
<li><code>dataset</code>: dict with <code>label</code>, <code>data</code>, and <code>borderWidth</code></li>
</ul>
</li>
<li>Re-renders the template with the populated form, <code>numGraphPoints</code>, and <code>chartdata</code>.</li>
</ul>
<h2 id="context">Context</h2>
<p>form : CycleQueryForm
The input form for specifying machine and time range.
numGraphPoints : int
Number of data points requested by the user (50–1000).
chartdata : dict (POST only)
Contains <code>labels</code> (datetimes) and <code>dataset</code> (chart.js configuration).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request (GET to show the form, POST to fetch chart data).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders 'prod_query/strokes_per_minute.html' with the context described above.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.strokes_per_minute_chart_data"><code class="name flex">
<span>def <span class="ident">strokes_per_minute_chart_data</span></span>(<span>machine, start, end, interval=5)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def strokes_per_minute_chart_data(machine, start, end, interval=5):
    &#34;&#34;&#34;
    Generate time-series data of average strokes per minute for a given machine.

    Executes a SQL query against the `GFxProduction` table to count events
    (strokes) in fixed-minute intervals, then fills any missing intervals
    with zero counts and computes the average strokes per minute.

    Parameters
    ----------
    machine : str
        The machine identifier to filter the production records.
    start : int
        The start time as a Unix epoch timestamp (seconds).
    end : int
        The end time as a Unix epoch timestamp (seconds).
    interval : int, optional
        The aggregation interval in minutes (default is 5).

    Returns
    -------
    labels : list of datetime.datetime
        A list of Python datetime objects marking the start of each interval.
    counts : list of float
        A list of average strokes per minute for each interval
        (count_in_interval / interval).

    Notes
    -----
    - Uses CEILING of the minute-difference divided by `interval` to bucket events.
    - Fills in any intervals with no events as zero.
    - Assumes the `TimeStamp` column in `GFxProduction` is stored as a Unix epoch.
    - Requires a Django DB connection alias `&#39;prodrpt-md&#39;`.
    &#34;&#34;&#34;
    sql  = f&#39;SELECT DATE_ADD(&#39;
    sql += f&#39;FROM_UNIXTIME({start}), &#39;
    sql += f&#39;Interval CEILING(TIMESTAMPDIFF(MINUTE, FROM_UNIXTIME({start}), &#39;
    sql += f&#39;FROM_UNIXTIME(TimeStamp))/{interval})*{interval} minute) as event_datetime_interval, &#39;
    sql += f&#39;count(*) &#39;
    sql += f&#39;FROM GFxPRoduction &#39;
    sql += f&#39;WHERE TimeStamp BETWEEN {start} AND {end} AND Machine = &#34;{machine}&#34; &#39;
    sql += f&#39;GROUP BY event_datetime_interval &#39;
    sql += f&#39;ORDER BY event_datetime_interval; &#39;

    with connections[&#39;prodrpt-md&#39;].cursor() as c:
        c.execute(sql)
        labels = []
        counts = []
        
        row = c.fetchone()
        for time in range(int(start),int(end),interval*60):
            dt= datetime.fromtimestamp(time)

            if not row:  # fills in rows that dont exist at the end of the period
                row = (dt,0)
            if row[0] &gt; dt:  # create periods with no production (dont show in query)
                labels.append(dt)
                counts.append(0)
                continue
            while row[0] &lt; dt:
                row = c.fetchone() # query pulls one period before
            if row[0] == dt:
                labels.append(dt)
                counts.append(row[1]/interval)
                row = c.fetchone()
        
    return labels, counts</code></pre>
</details>
<div class="desc"><p>Generate time-series data of average strokes per minute for a given machine.</p>
<p>Executes a SQL query against the <code>GFxProduction</code> table to count events
(strokes) in fixed-minute intervals, then fills any missing intervals
with zero counts and computes the average strokes per minute.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>The machine identifier to filter the production records.</dd>
<dt><strong><code>start</code></strong> :&ensp;<code>int</code></dt>
<dd>The start time as a Unix epoch timestamp (seconds).</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>int</code></dt>
<dd>The end time as a Unix epoch timestamp (seconds).</dd>
<dt><strong><code>interval</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The aggregation interval in minutes (default is 5).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>labels</code></strong> :&ensp;<code>list</code> of <code>datetime.datetime</code></dt>
<dd>A list of Python datetime objects marking the start of each interval.</dd>
<dt><strong><code>counts</code></strong> :&ensp;<code>list</code> of <code>float</code></dt>
<dd>A list of average strokes per minute for each interval
(count_in_interval / interval).</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>Uses CEILING of the minute-difference divided by <code>interval</code> to bucket events.</li>
<li>Fills in any intervals with no events as zero.</li>
<li>Assumes the <code>TimeStamp</code> column in <code>GFxProduction</code> is stored as a Unix epoch.</li>
<li>Requires a Django DB connection alias <code>'prodrpt-md'</code>.</li>
</ul></div>
</dd>
<dt id="prod_query.views.sub_index"><code class="name flex">
<span>def <span class="ident">sub_index</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sub_index(request):
    return redirect(&#39;prod_query:prod-query_index&#39;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="prod_query.views.summarize_contiguous_intervals"><code class="name flex">
<span>def <span class="ident">summarize_contiguous_intervals</span></span>(<span>intervals, downtime_details, human_readable_format='%Y-%m-%d %H:%M:%S')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def summarize_contiguous_intervals(intervals, downtime_details, human_readable_format=&#39;%Y-%m-%d %H:%M:%S&#39;):
    &#34;&#34;&#34;
    Aggregates contiguous intervals by part number and adds:
      - &#39;planned_minutes_down&#39;: Sum of downtime events (in whole minutes) that are &gt;= 240 minutes 
          and do NOT overlap with a PR downtime.
      - &#39;unplanned_minutes_down&#39;: Sum of the remaining downtime events within the group.
      - &#39;minutes_down&#39;: The sum of planned and unplanned downtime.
      - &#39;total_potential_minutes&#39;: Total minutes up (duration) plus minutes_down.
      - &#39;target&#39;: Calculated as (total_potential_minutes * 60) / cycle_time for the group.
      - Additional PA/OEE metrics are computed by calling compute_press_pa_oee.
    
    The downtime events (downtime_details) are expected to be a list of dicts with keys:
      &#39;start&#39;, &#39;end&#39;, &#39;duration&#39;, &#39;overlap&#39;
    where the times are formatted as strings using human_readable_format.
    
    Returns:
      A list of dictionaries (one per contiguous group) with the aggregated values and PA/OEE metrics.
    &#34;&#34;&#34;
    if not intervals:
        return []
    
    summaries = []
    # Start with the first interval as the current group.
    current_group = intervals[0].copy()
    try:
        current_group[&#39;duration&#39;] = int(current_group[&#39;duration&#39;])
    except:
        pass
    try:
        current_group[&#39;parts_produced&#39;] = int(current_group[&#39;parts_produced&#39;]) if current_group[&#39;parts_produced&#39;] != &#34;N/A&#34; else &#34;N/A&#34;
    except:
        pass
    try:
        current_group[&#39;target&#39;] = int(current_group[&#39;target&#39;]) if current_group[&#39;target&#39;] != &#34;N/A&#34; else &#34;N/A&#34;
    except:
        pass

    for interval in intervals[1:]:
        if interval[&#39;part&#39;] == current_group[&#39;part&#39;]:
            # Same part, so update the current group.
            current_group[&#39;end&#39;] = interval[&#39;end&#39;]
            try:
                current_group[&#39;duration&#39;] += int(interval[&#39;duration&#39;])
            except:
                current_group[&#39;duration&#39;] = &#34;N/A&#34;
            if current_group[&#39;parts_produced&#39;] != &#34;N/A&#34; and interval[&#39;parts_produced&#39;] != &#34;N/A&#34;:
                current_group[&#39;parts_produced&#39;] += int(interval[&#39;parts_produced&#39;])
            else:
                current_group[&#39;parts_produced&#39;] = &#34;N/A&#34;
            if current_group[&#39;target&#39;] != &#34;N/A&#34; and interval[&#39;target&#39;] != &#34;N/A&#34;:
                current_group[&#39;target&#39;] += int(interval[&#39;target&#39;])
            else:
                current_group[&#39;target&#39;] = &#34;N/A&#34;
        else:
            # Compute downtime metrics for the current group.
            try:
                group_start = datetime.strptime(current_group[&#39;start&#39;], human_readable_format)
                group_end = datetime.strptime(current_group[&#39;end&#39;], human_readable_format)
            except Exception:
                group_start = group_end = None
            planned = 0
            unplanned = 0
            if group_start and group_end:
                for dt_event in downtime_details:
                    try:
                        event_start = datetime.strptime(dt_event[&#39;start&#39;], human_readable_format)
                        event_end = datetime.strptime(dt_event[&#39;end&#39;], human_readable_format)
                    except Exception:
                        continue
                    # Only include downtime events that fall completely within the group&#39;s boundaries.
                    if event_start &gt;= group_start and event_end &lt;= group_end:
                        if dt_event[&#39;duration&#39;] &gt;= 240 and dt_event[&#39;overlap&#39;] == &#34;No Overlap&#34;:
                            planned += dt_event[&#39;duration&#39;]
                        else:
                            unplanned += dt_event[&#39;duration&#39;]
            current_group[&#39;planned_minutes_down&#39;] = planned
            current_group[&#39;unplanned_minutes_down&#39;] = unplanned
            current_group[&#39;minutes_down&#39;] = planned + unplanned
            if isinstance(current_group.get(&#39;duration&#39;), int):
                current_group[&#39;total_potential_minutes&#39;] = current_group[&#39;duration&#39;] + current_group[&#39;minutes_down&#39;]
            else:
                current_group[&#39;total_potential_minutes&#39;] = &#34;N/A&#34;
            # Recalculate target using total potential minutes:
            try:
                cycle_time = float(current_group.get(&#39;cycle_time&#39;))
            except Exception:
                cycle_time = None
            if (isinstance(current_group.get(&#39;total_potential_minutes&#39;), int) and cycle_time and cycle_time &gt; 0):
                current_group[&#39;target&#39;] = int((current_group[&#39;total_potential_minutes&#39;] * 60) / cycle_time)
            else:
                current_group[&#39;target&#39;] = &#34;N/A&#34;
            # Call compute_press_pa_oee to get PA/OEE metrics and update the group.
            pa_oee_data = compute_press_pa_oee(
                total_potential_minutes=current_group.get(&#39;total_potential_minutes&#39;, 0),
                planned_minutes_down=current_group.get(&#39;planned_minutes_down&#39;, 0),
                unplanned_minutes_down=current_group.get(&#39;unplanned_minutes_down&#39;, 0),
                total_minutes_up=current_group.get(&#39;duration&#39;, 0),
                cycle_time=current_group.get(&#39;cycle_time&#39;, 0),
                actual_parts=current_group.get(&#39;parts_produced&#39;, 0),
                total_target=current_group.get(&#39;target&#39;, 0)
            )
            current_group.update(pa_oee_data)
            summaries.append(current_group)
            # Start a new group for the next part.
            current_group = interval.copy()
            try:
                current_group[&#39;duration&#39;] = int(current_group[&#39;duration&#39;])
            except:
                pass
            try:
                current_group[&#39;parts_produced&#39;] = int(current_group[&#39;parts_produced&#39;]) if current_group[&#39;parts_produced&#39;] != &#34;N/A&#34; else &#34;N/A&#34;
            except:
                pass
            try:
                current_group[&#39;target&#39;] = int(current_group[&#39;target&#39;]) if current_group[&#39;target&#39;] != &#34;N/A&#34; else &#34;N/A&#34;
            except:
                pass

    # Process final group.
    try:
        group_start = datetime.strptime(current_group[&#39;start&#39;], human_readable_format)
        group_end = datetime.strptime(current_group[&#39;end&#39;], human_readable_format)
    except Exception:
        group_start = group_end = None
    planned = 0
    unplanned = 0
    if group_start and group_end:
        for dt_event in downtime_details:
            try:
                event_start = datetime.strptime(dt_event[&#39;start&#39;], human_readable_format)
                event_end = datetime.strptime(dt_event[&#39;end&#39;], human_readable_format)
            except Exception:
                continue
            if event_start &gt;= group_start and event_end &lt;= group_end:
                if dt_event[&#39;duration&#39;] &gt;= 240 and dt_event[&#39;overlap&#39;] == &#34;No Overlap&#34;:
                    planned += dt_event[&#39;duration&#39;]
                else:
                    unplanned += dt_event[&#39;duration&#39;]
    current_group[&#39;planned_minutes_down&#39;] = planned
    current_group[&#39;unplanned_minutes_down&#39;] = unplanned
    current_group[&#39;minutes_down&#39;] = planned + unplanned
    if isinstance(current_group.get(&#39;duration&#39;), int):
        current_group[&#39;total_potential_minutes&#39;] = current_group[&#39;duration&#39;] + current_group[&#39;minutes_down&#39;]
    else:
        current_group[&#39;total_potential_minutes&#39;] = &#34;N/A&#34;
    try:
        cycle_time = float(current_group.get(&#39;cycle_time&#39;))
    except Exception:
        cycle_time = None
    if (isinstance(current_group.get(&#39;total_potential_minutes&#39;), int) and cycle_time and cycle_time &gt; 0):
        current_group[&#39;target&#39;] = int((current_group[&#39;total_potential_minutes&#39;] * 60) / cycle_time)
    else:
        current_group[&#39;target&#39;] = &#34;N/A&#34;
    pa_oee_data = compute_press_pa_oee(
        total_potential_minutes=current_group.get(&#39;total_potential_minutes&#39;, 0),
        planned_minutes_down=current_group.get(&#39;planned_minutes_down&#39;, 0),
        unplanned_minutes_down=current_group.get(&#39;unplanned_minutes_down&#39;, 0),
        total_minutes_up=current_group.get(&#39;duration&#39;, 0),
        cycle_time=current_group.get(&#39;cycle_time&#39;, 0),
        actual_parts=current_group.get(&#39;parts_produced&#39;, 0),
        total_target=current_group.get(&#39;target&#39;, 0)
    )
    current_group.update(pa_oee_data)
    summaries.append(current_group)
    return summaries</code></pre>
</details>
<div class="desc"><p>Aggregates contiguous intervals by part number and adds:
- 'planned_minutes_down': Sum of downtime events (in whole minutes) that are &gt;= 240 minutes
and do NOT overlap with a PR downtime.
- 'unplanned_minutes_down': Sum of the remaining downtime events within the group.
- 'minutes_down': The sum of planned and unplanned downtime.
- 'total_potential_minutes': Total minutes up (duration) plus minutes_down.
- 'target': Calculated as (total_potential_minutes * 60) / cycle_time for the group.
- Additional PA/OEE metrics are computed by calling compute_press_pa_oee.</p>
<p>The downtime events (downtime_details) are expected to be a list of dicts with keys:
'start', 'end', 'duration', 'overlap'
where the times are formatted as strings using human_readable_format.</p>
<h2 id="returns">Returns</h2>
<p>A list of dictionaries (one per contiguous group) with the aggregated values and PA/OEE metrics.</p></div>
</dd>
<dt id="prod_query.views.target_create_ajax"><code class="name flex">
<span>def <span class="ident">target_create_ajax</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@require_POST
def target_create_ajax(request):
    &#34;&#34;&#34;
    Create a new OEE machine target via AJAX.

    Expects a POST request with a JSON body containing:
      - machine (int or str):        The machine identifier.
      - line (str):                  The production line identifier.
      - part (str, optional):        The part identifier (may be empty).
      - cycle_time (float or str):   The cycle time in seconds (or parsable to float).
      - effective_date (str):        The target’s effective date in &#34;YYYY-MM-DD&#34; format.
      - comment (str, optional):     Any user comment.

    Workflow:
      1. Parse and validate the JSON payload.
      2. Convert `effective_date` to a UTC Unix timestamp at EST midnight via `_parse_date_to_unix`.
      3. Compute the target value as `int(7200*60 / cycle_time)` (assuming a 2-hour run at the given cycle).
      4. Create an `OAMachineTargets` record with the provided fields.
      5. Return JSON `{&#39;success&#39;: True, &#39;id&#39;: &lt;new_record_id&gt;}` on success.

    Returns
    -------
    django.http.JsonResponse
        - On success: `{&#39;success&#39;: True, &#39;id&#39;: &lt;int&gt;}` with HTTP 200.
        - On failure: `{&#39;success&#39;: False, &#39;error&#39;: &lt;message&gt;}` with HTTP 400.

    Raises
    ------
    ValueError, KeyError, RuntimeError
        If JSON is invalid, required fields are missing, or conversion errors occur;
        these are caught and returned as JSON errors.
    &#34;&#34;&#34;
    try:
        data = json.loads(request.body)
        machine = data[&#39;machine&#39;]
        line    = data[&#39;line&#39;]
        part       = data.get(&#39;part&#39;, &#39;&#39;).strip()          # ← NEW
        cycle   = float(data[&#39;cycle_time&#39;])
        date_str= data[&#39;effective_date&#39;]
        comment = data.get(&#39;comment&#39;, &#39;&#39;).strip()

        eff_unix = _parse_date_to_unix(date_str)

        total_seconds = 7200 * 60
        target_val = int(total_seconds / cycle) if cycle &gt; 0 else 0

        t = OAMachineTargets.objects.create(
            machine_id=machine,
            line=line,
            part=part,                   # ← NEW
            target=target_val,
            effective_date_unix=eff_unix,
            comment=comment
        )
        return JsonResponse({&#39;success&#39;: True, &#39;id&#39;: t.id})
    except Exception as e:
        return JsonResponse({&#39;success&#39;: False, &#39;error&#39;: str(e)}, status=400)</code></pre>
</details>
<div class="desc"><p>Create a new OEE machine target via AJAX.</p>
<p>Expects a POST request with a JSON body containing:
- machine (int or str):
The machine identifier.
- line (str):
The production line identifier.
- part (str, optional):
The part identifier (may be empty).
- cycle_time (float or str):
The cycle time in seconds (or parsable to float).
- effective_date (str):
The target’s effective date in "YYYY-MM-DD" format.
- comment (str, optional):
Any user comment.</p>
<h2 id="workflow">Workflow</h2>
<ol>
<li>Parse and validate the JSON payload.</li>
<li>Convert <code>effective_date</code> to a UTC Unix timestamp at EST midnight via <code>_parse_date_to_unix</code>.</li>
<li>Compute the target value as <code>int(7200*60 / cycle_time)</code> (assuming a 2-hour run at the given cycle).</li>
<li>Create an <code>OAMachineTargets</code> record with the provided fields.</li>
<li>Return JSON <code>{'success': True, 'id': &lt;new_record_id&gt;}</code> on success.</li>
</ol>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.JsonResponse</code></dt>
<dd>
<ul>
<li>On success: <code>{'success': True, 'id': &lt;int&gt;}</code> with HTTP 200.</li>
<li>On failure: <code>{'success': False, 'error': &lt;message&gt;}</code> with HTTP 400.</li>
</ul>
</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError, KeyError, RuntimeError</code></dt>
<dd>If JSON is invalid, required fields are missing, or conversion errors occur;
these are caught and returned as JSON errors.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.target_delete_ajax"><code class="name flex">
<span>def <span class="ident">target_delete_ajax</span></span>(<span>request, pk)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@require_POST
def target_delete_ajax(request, pk):
    &#34;&#34;&#34;
    Soft-delete an OEE machine target via AJAX by marking it as deleted.

    Expects:
      - HTTP POST.
      - URL parameter `pk` identifying the `OAMachineTargets` record.

    Workflow:
      1. Retrieve the `OAMachineTargets` instance with primary key `pk`.
      2. Set its `isDeleted` flag to True.
      3. Save only the `isDeleted` field.
      4. Return JSON `{&#39;success&#39;: True}` on success.

    Error Handling:
      - If no matching record exists, returns HTTP 404 with `{&#39;success&#39;: False, &#39;error&#39;: &#39;Not found&#39;}`.
      - Any other exception returns HTTP 400 with `{&#39;success&#39;: False, &#39;error&#39;: &lt;message&gt;}`.

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP POST request.
    pk : int
        The primary key of the `OAMachineTargets` to delete.

    Returns
    -------
    django.http.JsonResponse
        JSON with `success` boolean and optional `error` message.
    &#34;&#34;&#34;
    try:
        obj = OAMachineTargets.objects.get(pk=pk)
        obj.isDeleted = True
        obj.save(update_fields=[&#39;isDeleted&#39;])
        return JsonResponse({&#39;success&#39;: True})
    except OAMachineTargets.DoesNotExist:
        return JsonResponse({&#39;success&#39;: False, &#39;error&#39;: &#39;Not found&#39;}, status=404)
    except Exception as e:
        return JsonResponse({&#39;success&#39;: False, &#39;error&#39;: str(e)}, status=400)</code></pre>
</details>
<div class="desc"><p>Soft-delete an OEE machine target via AJAX by marking it as deleted.</p>
<h2 id="expects">Expects</h2>
<ul>
<li>HTTP POST.</li>
<li>URL parameter <code>pk</code> identifying the <code>OAMachineTargets</code> record.</li>
</ul>
<h2 id="workflow">Workflow</h2>
<ol>
<li>Retrieve the <code>OAMachineTargets</code> instance with primary key <code>pk</code>.</li>
<li>Set its <code>isDeleted</code> flag to True.</li>
<li>Save only the <code>isDeleted</code> field.</li>
<li>Return JSON <code>{'success': True}</code> on success.</li>
</ol>
<p>Error Handling:
- If no matching record exists, returns HTTP 404 with <code>{'success': False, 'error': 'Not found'}</code>.
- Any other exception returns HTTP 400 with <code>{'success': False, 'error': &lt;message&gt;}</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP POST request.</dd>
<dt><strong><code>pk</code></strong> :&ensp;<code>int</code></dt>
<dd>The primary key of the <code>OAMachineTargets</code> to delete.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.JsonResponse</code></dt>
<dd>JSON with <code>success</code> boolean and optional <code>error</code> message.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.target_edit_ajax"><code class="name flex">
<span>def <span class="ident">target_edit_ajax</span></span>(<span>request, pk)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@require_POST
def target_edit_ajax(request, pk):
    &#34;&#34;&#34;
    Edit an existing OEE machine target via AJAX.

    Expects a POST request with a JSON body containing:
      - machine (int or str):        The new machine identifier.
      - line (str):                  The new production line identifier.
      - part (str):                  The new part identifier.
      - cycle_time (float or str):   The cycle time in seconds (or parsable to float).
      - effective_date (str):        The target’s effective date in &#34;YYYY-MM-DD&#34; format.
      - comment (str, optional):     Any user comment.

    Workflow:
      1. Parse and validate the JSON payload.
      2. Convert `effective_date` to a UTC Unix timestamp at EST midnight via `_parse_date_to_unix`.
      3. Compute the updated target value as `int(7200*60 / cycle_time)` (assuming a 2-hour run).
      4. Retrieve the `OAMachineTargets` record by primary key `pk`.
      5. Update its fields (`machine_id`, `line`, `part`, `target`, `effective_date_unix`, `comment`).
      6. Call `full_clean()` to run model validators, then `save()`.
      7. Return JSON `{&#39;success&#39;: True}` on success.

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP POST request containing the JSON payload.
    pk : int
        Primary key of the `OAMachineTargets` record to update.

    Returns
    -------
    django.http.JsonResponse
        - On success: `{&#39;success&#39;: True}` with HTTP 200.
        - On failure: `{&#39;success&#39;: False, &#39;error&#39;: &lt;message&gt;}` with HTTP 400.

    Raises
    ------
    ValueError, KeyError, ObjectDoesNotExist, ValidationError
        Any exceptions are caught and returned as JSON errors.
    &#34;&#34;&#34;
    try:
        data = json.loads(request.body)
        machine = data[&#39;machine&#39;]
        line    = data[&#39;line&#39;]
        part    = data[&#39;part&#39;]
        cycle   = float(data[&#39;cycle_time&#39;])
        date_str= data[&#39;effective_date&#39;]
        comment = data.get(&#39;comment&#39;, &#39;&#39;).strip()

        eff_unix = _parse_date_to_unix(date_str)

        total_seconds = 7200 * 60
        target_val = int(total_seconds / cycle) if cycle &gt; 0 else 0

        obj = OAMachineTargets.objects.get(pk=pk)
        obj.machine_id           = machine
        obj.line                 = line
        obj.part                 = part
        obj.target               = target_val
        obj.effective_date_unix  = eff_unix
        obj.comment              = comment
        obj.full_clean()  # run model validators
        obj.save()

        return JsonResponse({&#39;success&#39;: True})
    except Exception as e:
        return JsonResponse({&#39;success&#39;: False, &#39;error&#39;: str(e)}, status=400)</code></pre>
</details>
<div class="desc"><p>Edit an existing OEE machine target via AJAX.</p>
<p>Expects a POST request with a JSON body containing:
- machine (int or str):
The new machine identifier.
- line (str):
The new production line identifier.
- part (str):
The new part identifier.
- cycle_time (float or str):
The cycle time in seconds (or parsable to float).
- effective_date (str):
The target’s effective date in "YYYY-MM-DD" format.
- comment (str, optional):
Any user comment.</p>
<h2 id="workflow">Workflow</h2>
<ol>
<li>Parse and validate the JSON payload.</li>
<li>Convert <code>effective_date</code> to a UTC Unix timestamp at EST midnight via <code>_parse_date_to_unix</code>.</li>
<li>Compute the updated target value as <code>int(7200*60 / cycle_time)</code> (assuming a 2-hour run).</li>
<li>Retrieve the <code>OAMachineTargets</code> record by primary key <code>pk</code>.</li>
<li>Update its fields (<code>machine_id</code>, <code>line</code>, <code>part</code>, <code>target</code>, <code>effective_date_unix</code>, <code>comment</code>).</li>
<li>Call <code>full_clean()</code> to run model validators, then <code>save()</code>.</li>
<li>Return JSON <code>{'success': True}</code> on success.</li>
</ol>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP POST request containing the JSON payload.</dd>
<dt><strong><code>pk</code></strong> :&ensp;<code>int</code></dt>
<dd>Primary key of the <code>OAMachineTargets</code> record to update.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.JsonResponse</code></dt>
<dd>
<ul>
<li>On success: <code>{'success': True}</code> with HTTP 200.</li>
<li>On failure: <code>{'success': False, 'error': &lt;message&gt;}</code> with HTTP 400.</li>
</ul>
</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError, KeyError, ObjectDoesNotExist, ValidationError</code></dt>
<dd>Any exceptions are caught and returned as JSON errors.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.targets_list"><code class="name flex">
<span>def <span class="ident">targets_list</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@login_required(login_url=&#39;/login/&#39;)
def targets_list(request):
    &#34;&#34;&#34;
    Display a paginated list of active OEE machine targets for authorized managers.

    Access Control
    --------------
    - User must be authenticated.
    - User must belong to the “oee_target_managers” group.
      Otherwise, returns a simple Access Denied page with a 5-second meta-refresh back to “/”.

    Behavior
    --------
    - Queries `OAMachineTargets` for non-deleted entries (`isDeleted=False`),
      ordered by most recent `effective_date_unix` and then by `machine_id`.
    - Counts total results.
    - Retrieves the first `PAGE_SIZE` entries (for initial page).
    - Calls `annotate_targets` to add any computed fields to the page’s queryset.
    - Renders the ‘prod_query/targets_list.html’ template with:
        • `targets`:   the current page’s targets,
        • `offset`:    the page size (for “load more” logic),
        • `total`:     total number of results,
        • `page_size`: the constant `PAGE_SIZE`.

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request.

    Returns
    -------
    django.http.HttpResponse
        - On success: HTML page listing targets.
        - On unauthorized access: HTML page with message and auto-redirect.
    &#34;&#34;&#34;
    if not request.user.groups.filter(name=&#34;oee_target_managers&#34;).exists():
        # simple HTML with a 5-second meta refresh back to “/”
        html = &#34;&#34;&#34;
        &lt;!DOCTYPE html&gt;
        &lt;html&gt;
          &lt;head&gt;
            &lt;meta http-equiv=&#34;refresh&#34; content=&#34;5;url=/&#34;&gt;
            &lt;title&gt;Access Denied&lt;/title&gt;
          &lt;/head&gt;
          &lt;body style=&#34;display:flex;align-items:center;justify-content:center;height:100vh;&#34;&gt;
            &lt;h1&gt;Only admins can access this page.&lt;/h1&gt;
          &lt;/body&gt;
        &lt;/html&gt;
        &#34;&#34;&#34;
        return HttpResponse(html, content_type=&#34;text/html&#34;)

    # …otherwise your normal code
    qs_all  = OAMachineTargets.objects.filter(isDeleted=False) \
                                       .order_by(&#39;-effective_date_unix&#39;, &#39;machine_id&#39;)
    total   = qs_all.count()
    page_qs = qs_all[:PAGE_SIZE]
    annotate_targets(page_qs)
    return render(request, &#39;prod_query/targets_list.html&#39;, {
        &#39;targets&#39;:   page_qs,
        &#39;offset&#39;:    PAGE_SIZE,
        &#39;total&#39;:     total,
        &#39;page_size&#39;: PAGE_SIZE,
    })</code></pre>
</details>
<div class="desc"><p>Display a paginated list of active OEE machine targets for authorized managers.</p>
<h2 id="access-control">Access Control</h2>
<ul>
<li>User must be authenticated.</li>
<li>User must belong to the “oee_target_managers” group.
Otherwise, returns a simple Access Denied page with a 5-second meta-refresh back to “/”.</li>
</ul>
<h2 id="behavior">Behavior</h2>
<ul>
<li>Queries <code>OAMachineTargets</code> for non-deleted entries (<code>isDeleted=False</code>),
ordered by most recent <code>effective_date_unix</code> and then by <code>machine_id</code>.</li>
<li>Counts total results.</li>
<li>Retrieves the first <code>PAGE_SIZE</code> entries (for initial page).</li>
<li>Calls <code><a title="prod_query.views.annotate_targets" href="#prod_query.views.annotate_targets">annotate_targets()</a></code> to add any computed fields to the page’s queryset.</li>
<li>Renders the ‘prod_query/targets_list.html’ template with:
• <code>targets</code>:
the current page’s targets,
• <code>offset</code>:
the page size (for “load more” logic),
• <code>total</code>:
total number of results,
• <code>page_size</code>: the constant <code>PAGE_SIZE</code>.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>
<ul>
<li>On success: HTML page listing targets.</li>
<li>On unauthorized access: HTML page with message and auto-redirect.</li>
</ul>
</dd>
</dl></div>
</dd>
<dt id="prod_query.views.targets_load_more_ajax"><code class="name flex">
<span>def <span class="ident">targets_load_more_ajax</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def targets_load_more_ajax(request):
    &#34;&#34;&#34;
    Serve the next page of OEE machine targets via AJAX for infinite scroll or “load more.”

    Expects a query parameter:
      - `offset` (int): The number of records already loaded; defaults to 0.

    Workflow:
      1. Parse `offset` from `request.GET`.
      2. Query `OAMachineTargets` where `isDeleted=False`, ordered by newest `effective_date_unix`
         then `machine_id`.
      3. Slice the queryset from `offset` to `offset + PAGE_SIZE`.
      4. Call `annotate_targets` to enrich each target with computed fields.
      5. Render the `_targets_rows.html` partial with the new batch.
      6. Determine if more records remain (`has_more`).
      7. Return a JSON response containing:
         - `html`: rendered HTML for the new rows,
         - `has_more`: boolean indicating whether additional pages exist.

    Parameters
    ----------
    request : django.http.HttpRequest
        The AJAX request, with optional `?offset=` in the query string.

    Returns
    -------
    django.http.JsonResponse
        JSON object with:
          - `html` (str): HTML fragment for the next batch of rows.
          - `has_more` (bool): True if further pages are available.
    &#34;&#34;&#34;
    # expects ?offset=&lt;int&gt;
    offset = int(request.GET.get(&#39;offset&#39;, 0))
    qs_all = OAMachineTargets.objects.filter(isDeleted=False) \
    .order_by(&#39;-effective_date_unix&#39;, &#39;machine_id&#39;)
    next_batch = qs_all[offset:offset + PAGE_SIZE]
    annotate_targets(next_batch)

    html = render_to_string(&#39;prod_query/_targets_rows.html&#39;, {
        &#39;targets&#39;: next_batch
    }, request)

    has_more = offset + PAGE_SIZE &lt; qs_all.count()
    return JsonResponse({&#39;html&#39;: html, &#39;has_more&#39;: has_more})</code></pre>
</details>
<div class="desc"><p>Serve the next page of OEE machine targets via AJAX for infinite scroll or “load more.”</p>
<p>Expects a query parameter:
- <code>offset</code> (int): The number of records already loaded; defaults to 0.</p>
<h2 id="workflow">Workflow</h2>
<ol>
<li>Parse <code>offset</code> from <code>request.GET</code>.</li>
<li>Query <code>OAMachineTargets</code> where <code>isDeleted=False</code>, ordered by newest <code>effective_date_unix</code>
then <code>machine_id</code>.</li>
<li>Slice the queryset from <code>offset</code> to <code>offset + PAGE_SIZE</code>.</li>
<li>Call <code><a title="prod_query.views.annotate_targets" href="#prod_query.views.annotate_targets">annotate_targets()</a></code> to enrich each target with computed fields.</li>
<li>Render the <code>_targets_rows.html</code> partial with the new batch.</li>
<li>Determine if more records remain (<code>has_more</code>).</li>
<li>Return a JSON response containing:</li>
<li><code>html</code>: rendered HTML for the new rows,</li>
<li><code>has_more</code>: boolean indicating whether additional pages exist.</li>
</ol>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The AJAX request, with optional <code>?offset=</code> in the query string.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.JsonResponse</code></dt>
<dd>JSON object with:
- <code>html</code> (str): HTML fragment for the next batch of rows.
- <code>has_more</code> (bool): True if further pages are available.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.test_view"><code class="name flex">
<span>def <span class="ident">test_view</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_view(request):
    &#34;&#34;&#34;
    Django view that calls fetch_timestamps_for_timeblocks and returns the data as JSON.
    &#34;&#34;&#34;
    try:
        timestamps = fetch_timestamps_for_timeblocks()
        return JsonResponse({&#34;timestamps&#34;: timestamps})
    except Exception as e:
        return JsonResponse({&#34;error&#34;: str(e)}, status=500)</code></pre>
</details>
<div class="desc"><p>Django view that calls fetch_timestamps_for_timeblocks and returns the data as JSON.</p></div>
</dd>
<dt id="prod_query.views.total_scrap_for_line"><code class="name flex">
<span>def <span class="ident">total_scrap_for_line</span></span>(<span>scrap_line, start_date, end_date)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def total_scrap_for_line(scrap_line, start_date, end_date):
    &#34;&#34;&#34;
    Retrieve and sum scrap records for a specific production line over a date range.

    Executes a raw SQL query against the &#39;prodrpt-md&#39; database’s `tkb_scrap` table to fetch
    all rows where `scrap_line` matches the given identifier and `date_current` falls between
    `start_date` and `end_date` (inclusive). Returns the total scrap amount and the detailed
    row data.

    Parameters
    ----------
    scrap_line : str
        The production line identifier to filter scrap records.
    start_date : date or datetime or str
        The lower bound of the date_current filter (inclusive). Should be in a format accepted
        by the database for a BETWEEN query.
    end_date : date or datetime or str
        The upper bound of the date_current filter (inclusive). Should be in a format accepted
        by the database for a BETWEEN query.

    Returns
    -------
    dict
        A dictionary with:
          - &#39;total_scrap_amount&#39; (numeric): Sum of the `scrap_amount` field for all matching rows.
          - &#39;scrap_data&#39; (list of dict): A list of row dictionaries, each containing:
                &#39;Id&#39;, &#39;Scrap Part&#39;, &#39;Scrap Operation&#39;, &#39;Scrap Category&#39;,
                &#39;Scrap Amount&#39;, &#39;Scrap Line&#39;, &#39;Total Cost&#39;, &#39;Date&#39;, &#39;Date Current&#39;.

    Raises
    ------
    RuntimeError
        If any database error or other exception occurs during query execution, with
        a message prefixed by &#34;Error fetching scrap data:&#34;.
    &#34;&#34;&#34;
    try:
        query = &#34;&#34;&#34;
            SELECT Id, scrap_part, scrap_operation, scrap_category, scrap_amount, scrap_line, 
                   total_cost, date, date_current
            FROM tkb_scrap
            WHERE scrap_line = %s
            AND date_current BETWEEN %s AND %s
            ORDER BY date_current ASC;
        &#34;&#34;&#34;
        with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
            cursor.execute(query, [scrap_line, start_date, end_date])
            rows = cursor.fetchall()
        total_scrap_amount = sum(row[4] for row in rows)
        results = [
            {
                &#39;Id&#39;: row[0],
                &#39;Scrap Part&#39;: row[1],
                &#39;Scrap Operation&#39;: row[2],
                &#39;Scrap Category&#39;: row[3],
                &#39;Scrap Amount&#39;: row[4],
                &#39;Scrap Line&#39;: row[5],
                &#39;Total Cost&#39;: row[6],
                &#39;Date&#39;: row[7],
                &#39;Date Current&#39;: row[8],
            }
            for row in rows
        ]
        return {
            &#39;total_scrap_amount&#39;: total_scrap_amount,
            &#39;scrap_data&#39;: results
        }
    except Exception as e:
        print(f&#34;Error in total_scrap_for_line: {e}&#34;)  # Log the error to the console
        raise RuntimeError(f&#34;Error fetching scrap data: {str(e)}&#34;)  # Re-raise the exception</code></pre>
</details>
<div class="desc"><p>Retrieve and sum scrap records for a specific production line over a date range.</p>
<p>Executes a raw SQL query against the 'prodrpt-md' database’s <code>tkb_scrap</code> table to fetch
all rows where <code>scrap_line</code> matches the given identifier and <code>date_current</code> falls between
<code>start_date</code> and <code>end_date</code> (inclusive). Returns the total scrap amount and the detailed
row data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>scrap_line</code></strong> :&ensp;<code>str</code></dt>
<dd>The production line identifier to filter scrap records.</dd>
<dt><strong><code>start_date</code></strong> :&ensp;<code>date</code> or <code>datetime</code> or <code>str</code></dt>
<dd>The lower bound of the date_current filter (inclusive). Should be in a format accepted
by the database for a BETWEEN query.</dd>
<dt><strong><code>end_date</code></strong> :&ensp;<code>date</code> or <code>datetime</code> or <code>str</code></dt>
<dd>The upper bound of the date_current filter (inclusive). Should be in a format accepted
by the database for a BETWEEN query.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>A dictionary with:
- 'total_scrap_amount' (numeric): Sum of the <code>scrap_amount</code> field for all matching rows.
- 'scrap_data' (list of dict): A list of row dictionaries, each containing:
'Id', 'Scrap Part', 'Scrap Operation', 'Scrap Category',
'Scrap Amount', 'Scrap Line', 'Total Cost', 'Date', 'Date Current'.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If any database error or other exception occurs during query execution, with
a message prefixed by "Error fetching scrap data:".</dd>
</dl></div>
</dd>
<dt id="prod_query.views.total_scrap_view"><code class="name flex">
<span>def <span class="ident">total_scrap_view</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def total_scrap_view(request):
    &#34;&#34;&#34;
    Return scrap records and totals for a specified scrap line over a 5-day window.

    Expects HTTP GET with query parameters:
      - `scrap_line` (str): identifier of the scrap line (required).
      - `start_date` (str): ISO-formatted date or datetime string (with optional &#39;Z&#39; suffix)
                            marking the beginning of the 5-day window (required).

    Workflow:
      1. Validate presence of `scrap_line` and `start_date` or return HTTP 400 with an error.
      2. Parse `start_date` via `datetime.fromisoformat`, handling a trailing &#39;Z&#39; as UTC.
      3. Compute `end_date` as `start_date + 5 days`.
      4. Query the `tkb_scrap` table for records where:
           `scrap_line = %s` AND
           `date_current BETWEEN %s AND %s`
         ordering by `date_current` ascending.
      5. Sum the `scrap_amount` column across the returned rows.
      6. Build a list of dicts for each row with keys:
         `Id`, `Scrap Part`, `Scrap Operation`, `Scrap Category`,
         `Scrap Amount`, `Scrap Line`, `Total Cost`, `Date`, `Date Current`.
      7. Return HTTP 200 JSON:
         ```json
         {
           &#34;total_scrap_amount&#34;: &lt;float&gt;,
           &#34;scrap_data&#34;: [ { ... }, ... ]
         }
         ```
      8. On parsing or database errors, return HTTP 400 or 500 with an error message.

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request with the required GET parameters.

    Returns
    -------
    django.http.JsonResponse
        - On success: contains `total_scrap_amount` and `scrap_data`.
        - On error: contains an `&#34;error&#34;` key with status 400 or 500.
    &#34;&#34;&#34;
    try:
        # Extract and validate GET parameters
        scrap_line = request.GET.get(&#39;scrap_line&#39;)
        start_date_str = request.GET.get(&#39;start_date&#39;)

        if not scrap_line:
            return JsonResponse({&#39;error&#39;: &#34;Scrap line is required.&#34;}, status=400)

        if not start_date_str:
            return JsonResponse({&#39;error&#39;: &#34;Start date is required.&#34;}, status=400)

        try:
            # Handle ISO format with UTC &#39;Z&#39;
            if start_date_str.endswith(&#39;Z&#39;):
                start_date_str = start_date_str.replace(&#39;Z&#39;, &#39;+00:00&#39;)
            
            start_date = datetime.fromisoformat(start_date_str)
            end_date = start_date + timedelta(days=5)
        except Exception:
            return JsonResponse({&#39;error&#39;: &#34;Invalid start date format.&#34;}, status=400)

        query = &#34;&#34;&#34;
            SELECT Id, scrap_part, scrap_operation, scrap_category, scrap_amount, scrap_line, 
                   total_cost, date, date_current
            FROM tkb_scrap
            WHERE scrap_line = %s
            AND date_current BETWEEN %s AND %s
            ORDER BY date_current ASC;
        &#34;&#34;&#34;

        # Use the Django database connection
        with connections[&#39;prodrpt-md&#39;].cursor() as cursor:
            cursor.execute(query, [scrap_line, start_date, end_date])
            rows = cursor.fetchall()

        # Calculate total scrap amount and prepare results
        total_scrap_amount = sum(row[4] for row in rows)
        results = [
            {
                &#39;Id&#39;: row[0],
                &#39;Scrap Part&#39;: row[1],
                &#39;Scrap Operation&#39;: row[2],
                &#39;Scrap Category&#39;: row[3],
                &#39;Scrap Amount&#39;: row[4],
                &#39;Scrap Line&#39;: row[5],
                &#39;Total Cost&#39;: row[6],
                &#39;Date&#39;: row[7],
                &#39;Date Current&#39;: row[8],
            }
            for row in rows
        ]

        return JsonResponse({&#39;total_scrap_amount&#39;: total_scrap_amount, &#39;scrap_data&#39;: results})

    except Exception as e:
        return JsonResponse({&#39;error&#39;: str(e)}, status=500)</code></pre>
</details>
<div class="desc"><p>Return scrap records and totals for a specified scrap line over a 5-day window.</p>
<p>Expects HTTP GET with query parameters:
- <code>scrap_line</code> (str): identifier of the scrap line (required).
- <code>start_date</code> (str): ISO-formatted date or datetime string (with optional 'Z' suffix)
marking the beginning of the 5-day window (required).</p>
<h2 id="workflow">Workflow</h2>
<ol>
<li>Validate presence of <code>scrap_line</code> and <code>start_date</code> or return HTTP 400 with an error.</li>
<li>Parse <code>start_date</code> via <code>datetime.fromisoformat</code>, handling a trailing 'Z' as UTC.</li>
<li>Compute <code>end_date</code> as <code>start_date + 5 days</code>.</li>
<li>Query the <code>tkb_scrap</code> table for records where:
<code>scrap_line = %s</code> AND
<code>date_current BETWEEN %s AND %s</code>
ordering by <code>date_current</code> ascending.</li>
<li>Sum the <code>scrap_amount</code> column across the returned rows.</li>
<li>Build a list of dicts for each row with keys:
<code>Id</code>, <code>Scrap Part</code>, <code>Scrap Operation</code>, <code>Scrap Category</code>,
<code>Scrap Amount</code>, <code>Scrap Line</code>, <code>Total Cost</code>, <code>Date</code>, <code>Date Current</code>.</li>
<li>Return HTTP 200 JSON:
<code>json
{
"total_scrap_amount": &lt;float&gt;,
"scrap_data": [ { ... }, ... ]
}</code></li>
<li>On parsing or database errors, return HTTP 400 or 500 with an error message.</li>
</ol>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request with the required GET parameters.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.JsonResponse</code></dt>
<dd>
<ul>
<li>On success: contains <code>total_scrap_amount</code> and <code>scrap_data</code>.</li>
<li>On error: contains an <code>"error"</code> key with status 400 or 500.</li>
</ul>
</dd>
</dl></div>
</dd>
<dt id="prod_query.views.update_target"><code class="name flex">
<span>def <span class="ident">update_target</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@csrf_exempt
def update_target(request):
    &#34;&#34;&#34;
    Handle updating the target for a machine on a specific effective date.
    &#34;&#34;&#34;
    print(&#34;Received update_target request.&#34;)
    if request.method == &#34;POST&#34;:
        try:
            # Parse JSON data from the request body
            data = json.loads(request.body)
            print(&#34;Data received from frontend:&#34;, data)
            
            # Retrieve the variables
            machine_id = data.get(&#34;machine_id&#34;)
            effective_date = data.get(&#34;effective_date&#34;)
            target = data.get(&#34;target&#34;)
            line = data.get(&#34;line&#34;)
            
            print(f&#34;Machine ID: {machine_id}&#34;)
            print(f&#34;Effective Date: {effective_date}&#34;)
            print(f&#34;Target: {target}&#34;)
            print(f&#34;Line: {line}&#34;)
            
            # Validate inputs
            if not machine_id or not effective_date or not target:
                print(&#34;Missing required parameters.&#34;)
                return JsonResponse({&#34;error&#34;: &#34;Missing required parameters.&#34;}, status=400)
            
            # Save or update the machine target
            record, created = save_machine_target(machine_id, effective_date, target, line)
            
            print(&#34;Record saved or updated:&#34;, record)
            print(&#34;Was the record newly created?&#34;, created)
            
            # Prepare the response
            response_data = {
                &#34;message&#34;: &#34;Target updated successfully.&#34;,
                &#34;created&#34;: created,
                &#34;record&#34;: {
                    &#34;machine_id&#34;: record.machine_id,
                    &#34;effective_date&#34;: record.effective_date_unix,
                    &#34;target&#34;: record.target,
                    &#34;line&#34;: record.line,  # Include line in the response
                },
            }
            return JsonResponse(response_data, status=200)
        
        except json.JSONDecodeError:
            print(&#34;Invalid JSON data received.&#34;)
            return JsonResponse({&#34;error&#34;: &#34;Invalid JSON data.&#34;}, status=400)
        except Exception as e:
            print(&#34;Unexpected error:&#34;, str(e))
            return JsonResponse({&#34;error&#34;: str(e)}, status=500)
    
    print(&#34;Invalid request method.&#34;)
    return JsonResponse({&#34;error&#34;: &#34;Invalid request method.&#34;}, status=405)</code></pre>
</details>
<div class="desc"><p>Handle updating the target for a machine on a specific effective date.</p></div>
</dd>
<dt id="prod_query.views.validate_threshold"><code class="name flex">
<span>def <span class="ident">validate_threshold</span></span>(<span>threshold)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validate_threshold(threshold):
    &#34;&#34;&#34;
    Ensure the downtime threshold is a valid integer, defaulting to 5 if invalid.
    &#34;&#34;&#34;
    try:
        return int(threshold)
    except (ValueError, TypeError):
        return 5</code></pre>
</details>
<div class="desc"><p>Ensure the downtime threshold is a valid integer, defaulting to 5 if invalid.</p></div>
</dd>
<dt id="prod_query.views.weekly_prod"><code class="name flex">
<span>def <span class="ident">weekly_prod</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def weekly_prod(request):
    &#34;&#34;&#34;
    Generate and display a weekly production report for specified parts.

    Allows selection of a target week via WeeklyProdDate form and updating production goals
    via WeeklyProdUpdate form. For each configured part:
      - Calculates shift start timestamps for 21 shifts over the week.
      - Retrieves the actual production counts per shift from the `GFxPRoduction` database.
      - Computes cumulative totals, predictions to week’s end, and variance against the set goal.
      - Prepends the part number and appends week_total, predicted_total, goal, and difference to each row.

    Context variables passed to the &#39;prod_query/weekly-prod.html&#39; template:
      - form:                WeeklyProdDate form for selecting the week.
      - update_form:         WeeklyProdUpdate form for setting or updating the weekly goal.
      - dates:               List of seven dates (Monday–Sunday) for the target week.
      - rows:                List of data rows; each row contains:
                              [part, col1...col21, week_total, predicted, goal, difference].
      - page_title:          &#34;Weekly Production&#34;

    Request methods
    ---------------
    GET:
      - Initializes `form` and `update_form` to the current or default week.
      - Renders the report with default parameters.
    POST:
      - If updating a goal, processes WeeklyProdUpdate and saves/overwrites the Weekly_Production_Goal.
      - Processes WeeklyProdDate to shift the target week forward, backward, or specific date.
      - Rebuilds `form` and `update_form` with the updated target and effective dates.
      - Renders the report for the newly selected week.

    Parameters
    ----------
    request : django.http.HttpRequest
        The incoming HTTP request. May be GET or POST with form data.

    Returns
    -------
    django.http.HttpResponse
        Renders the &#39;prod_query/weekly-prod.html&#39; template populated with the report data.
    &#34;&#34;&#34;


    # Part, shift start in 24 hour time, list of machines used
    parameters = [
        (&#34;50-9341&#34;, 22, [&#39;1533&#39;]),
        (&#34;50-0455&#34;, 22, [&#39;1816&#39;]),
        (&#34;50-1467&#34;, 22, [&#39;742&#39;, &#39;650L&#39;, &#39;650R&#39;, &#39;769&#39;]),  # 650L and 650R replaced with 742 5/28/2024
        (&#34;50-3050&#34;, 22, [&#39;769&#39;]),
        (&#34;50-8670&#34;, 23, [&#39;1724&#39;, &#39;1725&#39;, &#39;1750&#39;]),
        (&#34;50-0450&#34;, 23, [&#39;1724&#39;, &#39;1725&#39;, &#39;1750&#39;]),
        (&#34;50-5401&#34;, 23, [&#39;1724&#39;, &#39;1725&#39;, &#39;1750&#39;]),
        (&#34;50-0447&#34;, 23, [&#39;1724&#39;, &#39;1725&#39;, &#39;1750&#39;]),
        (&#34;50-5404&#34;, 23, [&#39;1724&#39;, &#39;1725&#39;, &#39;1750&#39;]),
        (&#34;50-0519&#34;, 23, [&#39;1724&#39;, &#39;1725&#39;, &#39;1750&#39;]),
        (&#34;50-4865&#34;, 23, [&#39;1617&#39;]),
        (&#34;50-5081&#34;, 23, [&#39;1617&#39;]),
        (&#34;50-4748&#34;, 23, [&#39;797&#39;]),
        (&#34;50-3214&#34;, 23, [&#39;1725&#39;]),
        (&#34;50-5214&#34;, 23, [&#39;1725&#39;]),
    ]
    # Add new part information here.
    # Increase number of rows in template script file

    context = {}
    tic = time.time()
    target = datetime.today().date()        #this is wrong, doesn&#39;t allow setting goal setting for previous weeks
    (temp_year,temp_week,temp_day) = datetime.today().date().isocalendar()
    effective_date = date.fromisocalendar(year=temp_year, week=temp_week, day=7)
    effective_date -= timedelta(days = 7)
    context[&#39;form&#39;] = WeeklyProdDate(initial={&#39;date&#39;: target})
    context[&#39;update_form&#39;] = WeeklyProdUpdate(initial={&#39;effective_date&#39;: effective_date})

    if request.method == &#39;POST&#39;:

        if &#39;update&#39; in request.POST:
            form = WeeklyProdUpdate(request.POST)
            if form.is_valid():
                effective_date = form.cleaned_data.get(&#39;effective_date&#39;)
                goal = form.cleaned_data.get(&#39;goal&#39;)
                part_number = form.cleaned_data.get(&#39;part_number&#39;)

                #check for weekly goal, if there overwrite it, else make new weekly goal
                
                effective_year = effective_date.year
                effective_week = effective_date.isocalendar().week

                new_weekly_goal, created = Weekly_Production_Goal.objects.get_or_create(
                    part_number=part_number,
                    year=effective_year, 
                    week=effective_week,
                    defaults={&#39;goal&#39;: goal},)

                new_weekly_goal.goal = goal
                new_weekly_goal.save()

        form = WeeklyProdDate(request.POST)
        if form.is_valid():
            # Previous week
            if &#39;prev&#39; in request.POST:
                target = form.cleaned_data.get(&#39;date&#39;) - timedelta(days=7)
                new_effective_date = adjust_target_to_effective_date(target)
                context[&#39;update_form&#39;] = WeeklyProdUpdate(initial={&#39;effective_date&#39;: new_effective_date})
            # Specific week
            if &#39;specific&#39; in request.POST:
                target = form.cleaned_data.get(&#39;date&#39;)
                new_effective_date = adjust_target_to_effective_date(target)
                context[&#39;update_form&#39;] = WeeklyProdUpdate(initial={&#39;effective_date&#39;: new_effective_date})
            # Current week
            context[&#39;form&#39;] = WeeklyProdDate(initial={&#39;date&#39;: target})

    cursor = connections[&#39;prodrpt-md&#39;].cursor()

    # Date headers for table
    days_past_sunday = target.isoweekday() % 7
    sunday = target - timedelta(days=days_past_sunday)
    dates = []
    for i in range(1, 8):
        dates.append(sunday + timedelta(days=i))

    seconds_in_shift = 28800
    rows = []
    for part, shift_start_hour, source_machine_list in parameters:

        # Time stamps for each shift
        shift_start = datetime(target.year, target.month, target.day,
                               shift_start_hour, 0, 0)-timedelta(days=days_past_sunday)
        shift_starts = []
        start = datetime.timestamp(shift_start)
        for i in range(0, 21):
            shift_starts.append(start)
            start = start + seconds_in_shift
        last_shift_end = shift_starts[20] + seconds_in_shift

        # Goal
        end_of_period = last_shift_end
        goal = weekly_prod_goal(part,end_of_period)

        # One query for each machine used by part
        # sql &#34;in&#34; is very slow
        values_from_query = 21
        row = [0] * values_from_query
        for machine in source_machine_list:
            # Prepares select for query
            sum_string = &#39;&#39;
            for i in range(0, values_from_query):
                sum_string += f&#34;IFNULL(SUM(\n&#34;
                sum_string += f&#34;CASE\n&#34;
                sum_string += f&#34;WHEN TimeStamp &gt;= {shift_starts[i]}\n&#34;
                sum_string += f&#34;AND TimeStamp &lt;= {shift_starts[i] + seconds_in_shift} THEN 1\n&#34;
                sum_string += f&#34;ELSE 0\n&#34;
                sum_string += f&#34;END\n&#34;
                sum_string += f&#34;), 0) as quantitycol{i+1},&#34;
            sum_string = sum_string[:-1]
            sum_string = &#34;SELECT\n&#34; + sum_string

            # Prepares remainder of query
            sql_quantities = f&#34;\nFROM\n&#34;
            sql_quantities += f&#34;GFxPRoduction\n&#34;
            sql_quantities += f&#34;WHERE\n&#34;
            sql_quantities += f&#34;TimeStamp &gt;= {shift_starts[0]}\n&#34;
            sql_quantities += f&#34;AND TimeStamp &lt; {last_shift_end}\n&#34;
            sql_quantities += f&#34;AND Machine = &#39;{machine}&#39;\n&#34;
            sql_quantities += f&#34;AND Part = &#39;{part}&#39;&#34;

            # Executes query
            sql_quantities = sum_string + sql_quantities
            cursor.execute(sql_quantities)
            # The return value is a tuple with a single value, which this unpacks
            (res,) = cursor.fetchall()
            for i in range(0, values_from_query):
                row[i] += res[i]

        # Calculates:
        # The total parts actually produced
        # The predicted total by end of week
        #   based off of percent of time left in week
        #   sets the percent to 100% if the week is in the past
        # The difference between the predicted total and the goal
        # This processing occurs once per row
        week_total = sum(row)
        time_left = last_shift_end - datetime.timestamp(datetime.now())
        if time_left &lt; 0:
            predicted = round(int(week_total))
        else:
            proportion = time_left / 604800
            predicted = round(int(week_total)/(1-proportion))
        difference = round(predicted-int(goal))

        # Goal is inserted after the loop processing is completed, simplifying the indexes
        row.insert(0, part)
        row.append(week_total)
        row.append(predicted)
        row.append(goal)  # add in goal for reference
        row.append(difference)
        rows.append(row)

    context[&#39;dates&#39;] = dates
    context[&#39;rows&#39;] = rows
    context[&#39;page_title&#39;] = &#34;Weekly Production&#34;

    print(time.time()-tic)

    return render(request, &#39;prod_query/weekly-prod.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Generate and display a weekly production report for specified parts.</p>
<p>Allows selection of a target week via WeeklyProdDate form and updating production goals
via WeeklyProdUpdate form. For each configured part:
- Calculates shift start timestamps for 21 shifts over the week.
- Retrieves the actual production counts per shift from the <code>GFxPRoduction</code> database.
- Computes cumulative totals, predictions to week’s end, and variance against the set goal.
- Prepends the part number and appends week_total, predicted_total, goal, and difference to each row.</p>
<p>Context variables passed to the 'prod_query/weekly-prod.html' template:
- form:
WeeklyProdDate form for selecting the week.
- update_form:
WeeklyProdUpdate form for setting or updating the weekly goal.
- dates:
List of seven dates (Monday–Sunday) for the target week.
- rows:
List of data rows; each row contains:
[part, col1&hellip;col21, week_total, predicted, goal, difference].
- page_title:
"Weekly Production"</p>
<h2 id="request-methods">Request Methods</h2>
<h2 id="get">Get</h2>
<ul>
<li>Initializes <code>form</code> and <code>update_form</code> to the current or default week.</li>
<li>Renders the report with default parameters.</li>
</ul>
<h2 id="post">Post</h2>
<ul>
<li>If updating a goal, processes WeeklyProdUpdate and saves/overwrites the Weekly_Production_Goal.</li>
<li>Processes WeeklyProdDate to shift the target week forward, backward, or specific date.</li>
<li>Rebuilds <code>form</code> and <code>update_form</code> with the updated target and effective dates.</li>
<li>Renders the report for the newly selected week.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>django.http.HttpRequest</code></dt>
<dd>The incoming HTTP request. May be GET or POST with form data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>django.http.HttpResponse</code></dt>
<dd>Renders the 'prod_query/weekly-prod.html' template populated with the report data.</dd>
</dl></div>
</dd>
<dt id="prod_query.views.weekly_prod_goal"><code class="name flex">
<span>def <span class="ident">weekly_prod_goal</span></span>(<span>part, end_of_period)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def weekly_prod_goal(part, end_of_period):
    &#34;&#34;&#34;
    Retrieve the most recent production goal for a given part at or before a specified time.

    Queries Weekly_Production_Goal records for the given part, ordered by descending year and week.
    Converts each goal’s ISO week and year into a timestamp for the Sunday of that week (at midnight UTC-2 offset),
    and returns the first goal whose timestamp is less than or equal to `end_of_period`.

    Parameters
    ----------
    part : str
        The part_number to look up goals for.
    end_of_period : float
        Epoch timestamp (seconds) representing the end of the period to check against.

    Returns
    -------
    int
        The goal quantity for the matching week, or 0 if no prior goal is found.
    &#34;&#34;&#34;
    goals = Weekly_Production_Goal.objects.filter(part_number=part).order_by(&#39;-year&#39;, &#39;-week&#39;).all()
    for goal in goals:
        goal_date = date.fromisocalendar(year=goal.year, week=goal.week, day=7)
        goal_ts = datetime.combine(goal_date, datetime.min.time()).timestamp()-7200
        if goal_ts &lt;= end_of_period:
            return goal.goal
    return 0</code></pre>
</details>
<div class="desc"><p>Retrieve the most recent production goal for a given part at or before a specified time.</p>
<p>Queries Weekly_Production_Goal records for the given part, ordered by descending year and week.
Converts each goal’s ISO week and year into a timestamp for the Sunday of that week (at midnight UTC-2 offset),
and returns the first goal whose timestamp is less than or equal to <code>end_of_period</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>part</code></strong> :&ensp;<code>str</code></dt>
<dd>The part_number to look up goals for.</dd>
<dt><strong><code>end_of_period</code></strong> :&ensp;<code>float</code></dt>
<dd>Epoch timestamp (seconds) representing the end of the period to check against.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The goal quantity for the matching week, or 0 if no prior goal is found.</dd>
</dl></div>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="prod_query.views.add_partial_block_to_friday" href="#prod_query.views.add_partial_block_to_friday">add_partial_block_to_friday</a></code></li>
<li><code><a title="prod_query.views.adjust_target_to_effective_date" href="#prod_query.views.adjust_target_to_effective_date">adjust_target_to_effective_date</a></code></li>
<li><code><a title="prod_query.views.aggregate_line_metrics" href="#prod_query.views.aggregate_line_metrics">aggregate_line_metrics</a></code></li>
<li><code><a title="prod_query.views.aggregate_machine_groups" href="#prod_query.views.aggregate_machine_groups">aggregate_machine_groups</a></code></li>
<li><code><a title="prod_query.views.aggregate_machine_metrics" href="#prod_query.views.aggregate_machine_metrics">aggregate_machine_metrics</a></code></li>
<li><code><a title="prod_query.views.aggregate_operation_totals" href="#prod_query.views.aggregate_operation_totals">aggregate_operation_totals</a></code></li>
<li><code><a title="prod_query.views.annotate_targets" href="#prod_query.views.annotate_targets">annotate_targets</a></code></li>
<li><code><a title="prod_query.views.apply_color_gradient_to_line" href="#prod_query.views.apply_color_gradient_to_line">apply_color_gradient_to_line</a></code></li>
<li><code><a title="prod_query.views.apply_color_gradient_to_line_reversed" href="#prod_query.views.apply_color_gradient_to_line_reversed">apply_color_gradient_to_line_reversed</a></code></li>
<li><code><a title="prod_query.views.attach_spm_chart_data_to_blocks" href="#prod_query.views.attach_spm_chart_data_to_blocks">attach_spm_chart_data_to_blocks</a></code></li>
<li><code><a title="prod_query.views.calculate_A" href="#prod_query.views.calculate_A">calculate_A</a></code></li>
<li><code><a title="prod_query.views.calculate_Q" href="#prod_query.views.calculate_Q">calculate_Q</a></code></li>
<li><code><a title="prod_query.views.calculate_a_and_p_averages" href="#prod_query.views.calculate_a_and_p_averages">calculate_a_and_p_averages</a></code></li>
<li><code><a title="prod_query.views.calculate_adjusted_target" href="#prod_query.views.calculate_adjusted_target">calculate_adjusted_target</a></code></li>
<li><code><a title="prod_query.views.calculate_average_downtime" href="#prod_query.views.calculate_average_downtime">calculate_average_downtime</a></code></li>
<li><code><a title="prod_query.views.calculate_downtime_events" href="#prod_query.views.calculate_downtime_events">calculate_downtime_events</a></code></li>
<li><code><a title="prod_query.views.calculate_downtime_press" href="#prod_query.views.calculate_downtime_press">calculate_downtime_press</a></code></li>
<li><code><a title="prod_query.views.calculate_full_blocks" href="#prod_query.views.calculate_full_blocks">calculate_full_blocks</a></code></li>
<li><code><a title="prod_query.views.calculate_line_totals" href="#prod_query.views.calculate_line_totals">calculate_line_totals</a></code></li>
<li><code><a title="prod_query.views.calculate_monthly_totals" href="#prod_query.views.calculate_monthly_totals">calculate_monthly_totals</a></code></li>
<li><code><a title="prod_query.views.calculate_oa" href="#prod_query.views.calculate_oa">calculate_oa</a></code></li>
<li><code><a title="prod_query.views.calculate_oa_metrics" href="#prod_query.views.calculate_oa_metrics">calculate_oa_metrics</a></code></li>
<li><code><a title="prod_query.views.calculate_operaton_P_and_A_from_totals" href="#prod_query.views.calculate_operaton_P_and_A_from_totals">calculate_operaton_P_and_A_from_totals</a></code></li>
<li><code><a title="prod_query.views.calculate_p" href="#prod_query.views.calculate_p">calculate_p</a></code></li>
<li><code><a title="prod_query.views.calculate_percentage_downtime" href="#prod_query.views.calculate_percentage_downtime">calculate_percentage_downtime</a></code></li>
<li><code><a title="prod_query.views.calculate_percentage_week" href="#prod_query.views.calculate_percentage_week">calculate_percentage_week</a></code></li>
<li><code><a title="prod_query.views.calculate_planned_downtime" href="#prod_query.views.calculate_planned_downtime">calculate_planned_downtime</a></code></li>
<li><code><a title="prod_query.views.calculate_potential_minutes" href="#prod_query.views.calculate_potential_minutes">calculate_potential_minutes</a></code></li>
<li><code><a title="prod_query.views.calculate_runtime_press" href="#prod_query.views.calculate_runtime_press">calculate_runtime_press</a></code></li>
<li><code><a title="prod_query.views.calculate_totals" href="#prod_query.views.calculate_totals">calculate_totals</a></code></li>
<li><code><a title="prod_query.views.calculate_unplanned_downtime" href="#prod_query.views.calculate_unplanned_downtime">calculate_unplanned_downtime</a></code></li>
<li><code><a title="prod_query.views.compute_cycle_time" href="#prod_query.views.compute_cycle_time">compute_cycle_time</a></code></li>
<li><code><a title="prod_query.views.compute_downtime_percentage" href="#prod_query.views.compute_downtime_percentage">compute_downtime_percentage</a></code></li>
<li><code><a title="prod_query.views.compute_machine_downtime_percentage" href="#prod_query.views.compute_machine_downtime_percentage">compute_machine_downtime_percentage</a></code></li>
<li><code><a title="prod_query.views.compute_machine_oee" href="#prod_query.views.compute_machine_oee">compute_machine_oee</a></code></li>
<li><code><a title="prod_query.views.compute_oee_metrics" href="#prod_query.views.compute_oee_metrics">compute_oee_metrics</a></code></li>
<li><code><a title="prod_query.views.compute_overlap_label" href="#prod_query.views.compute_overlap_label">compute_overlap_label</a></code></li>
<li><code><a title="prod_query.views.compute_press_pa_oee" href="#prod_query.views.compute_press_pa_oee">compute_press_pa_oee</a></code></li>
<li><code><a title="prod_query.views.cycle_times" href="#prod_query.views.cycle_times">cycle_times</a></code></li>
<li><code><a title="prod_query.views.deep_dive" href="#prod_query.views.deep_dive">deep_dive</a></code></li>
<li><code><a title="prod_query.views.downtime_frequency_view" href="#prod_query.views.downtime_frequency_view">downtime_frequency_view</a></code></li>
<li><code><a title="prod_query.views.drilldown_calculate_P" href="#prod_query.views.drilldown_calculate_P">drilldown_calculate_P</a></code></li>
<li><code><a title="prod_query.views.fetch_chart_data" href="#prod_query.views.fetch_chart_data">fetch_chart_data</a></code></li>
<li><code><a title="prod_query.views.fetch_combined_oee_production_data" href="#prod_query.views.fetch_combined_oee_production_data">fetch_combined_oee_production_data</a></code></li>
<li><code><a title="prod_query.views.fetch_cycle_data" href="#prod_query.views.fetch_cycle_data">fetch_cycle_data</a></code></li>
<li><code><a title="prod_query.views.fetch_daily_scrap_data" href="#prod_query.views.fetch_daily_scrap_data">fetch_daily_scrap_data</a></code></li>
<li><code><a title="prod_query.views.fetch_downtime_by_date_ranges" href="#prod_query.views.fetch_downtime_by_date_ranges">fetch_downtime_by_date_ranges</a></code></li>
<li><code><a title="prod_query.views.fetch_downtime_results" href="#prod_query.views.fetch_downtime_results">fetch_downtime_results</a></code></li>
<li><code><a title="prod_query.views.fetch_line_metrics" href="#prod_query.views.fetch_line_metrics">fetch_line_metrics</a></code></li>
<li><code><a title="prod_query.views.fetch_machine_target" href="#prod_query.views.fetch_machine_target">fetch_machine_target</a></code></li>
<li><code><a title="prod_query.views.fetch_part_timeline" href="#prod_query.views.fetch_part_timeline">fetch_part_timeline</a></code></li>
<li><code><a title="prod_query.views.fetch_prdowntime1_entries_with_id" href="#prod_query.views.fetch_prdowntime1_entries_with_id">fetch_prdowntime1_entries_with_id</a></code></li>
<li><code><a title="prod_query.views.fetch_press_changeovers" href="#prod_query.views.fetch_press_changeovers">fetch_press_changeovers</a></code></li>
<li><code><a title="prod_query.views.fetch_press_prdowntime1_entries" href="#prod_query.views.fetch_press_prdowntime1_entries">fetch_press_prdowntime1_entries</a></code></li>
<li><code><a title="prod_query.views.fetch_production_by_date_ranges" href="#prod_query.views.fetch_production_by_date_ranges">fetch_production_by_date_ranges</a></code></li>
<li><code><a title="prod_query.views.fetch_production_count" href="#prod_query.views.fetch_production_count">fetch_production_count</a></code></li>
<li><code><a title="prod_query.views.fetch_shift_totals_by_day_and_shift" href="#prod_query.views.fetch_shift_totals_by_day_and_shift">fetch_shift_totals_by_day_and_shift</a></code></li>
<li><code><a title="prod_query.views.fetch_timestamps_for_timeblocks" href="#prod_query.views.fetch_timestamps_for_timeblocks">fetch_timestamps_for_timeblocks</a></code></li>
<li><code><a title="prod_query.views.find_first_sunday" href="#prod_query.views.find_first_sunday">find_first_sunday</a></code></li>
<li><code><a title="prod_query.views.get_active_part" href="#prod_query.views.get_active_part">get_active_part</a></code></li>
<li><code><a title="prod_query.views.get_all_lines" href="#prod_query.views.get_all_lines">get_all_lines</a></code></li>
<li><code><a title="prod_query.views.get_color_for_ratio" href="#prod_query.views.get_color_for_ratio">get_color_for_ratio</a></code></li>
<li><code><a title="prod_query.views.get_custom_time_blocks" href="#prod_query.views.get_custom_time_blocks">get_custom_time_blocks</a></code></li>
<li><code><a title="prod_query.views.get_cycle_metrics" href="#prod_query.views.get_cycle_metrics">get_cycle_metrics</a></code></li>
<li><code><a title="prod_query.views.get_cycle_time_for_part" href="#prod_query.views.get_cycle_time_for_part">get_cycle_time_for_part</a></code></li>
<li><code><a title="prod_query.views.get_distinct_machines" href="#prod_query.views.get_distinct_machines">get_distinct_machines</a></code></li>
<li><code><a title="prod_query.views.get_fallback_part_from_sc_production" href="#prod_query.views.get_fallback_part_from_sc_production">get_fallback_part_from_sc_production</a></code></li>
<li><code><a title="prod_query.views.get_line_details" href="#prod_query.views.get_line_details">get_line_details</a></code></li>
<li><code><a title="prod_query.views.get_machine_data" href="#prod_query.views.get_machine_data">get_machine_data</a></code></li>
<li><code><a title="prod_query.views.get_machine_part_numbers" href="#prod_query.views.get_machine_part_numbers">get_machine_part_numbers</a></code></li>
<li><code><a title="prod_query.views.get_machine_target" href="#prod_query.views.get_machine_target">get_machine_target</a></code></li>
<li><code><a title="prod_query.views.get_month_and_year" href="#prod_query.views.get_month_and_year">get_month_and_year</a></code></li>
<li><code><a title="prod_query.views.get_month_details" href="#prod_query.views.get_month_details">get_month_details</a></code></li>
<li><code><a title="prod_query.views.get_month_start_and_end" href="#prod_query.views.get_month_start_and_end">get_month_start_and_end</a></code></li>
<li><code><a title="prod_query.views.get_parts_for_machine" href="#prod_query.views.get_parts_for_machine">get_parts_for_machine</a></code></li>
<li><code><a title="prod_query.views.get_pr_downtime_entries" href="#prod_query.views.get_pr_downtime_entries">get_pr_downtime_entries</a></code></li>
<li><code><a title="prod_query.views.get_production_data" href="#prod_query.views.get_production_data">get_production_data</a></code></li>
<li><code><a title="prod_query.views.get_production_data_for_machine" href="#prod_query.views.get_production_data_for_machine">get_production_data_for_machine</a></code></li>
<li><code><a title="prod_query.views.get_reject_data" href="#prod_query.views.get_reject_data">get_reject_data</a></code></li>
<li><code><a title="prod_query.views.get_sc_production_data" href="#prod_query.views.get_sc_production_data">get_sc_production_data</a></code></li>
<li><code><a title="prod_query.views.get_sc_production_data_v2" href="#prod_query.views.get_sc_production_data_v2">get_sc_production_data_v2</a></code></li>
<li><code><a title="prod_query.views.get_sunday_to_friday_ranges" href="#prod_query.views.get_sunday_to_friday_ranges">get_sunday_to_friday_ranges</a></code></li>
<li><code><a title="prod_query.views.get_sunday_to_friday_ranges_custom" href="#prod_query.views.get_sunday_to_friday_ranges_custom">get_sunday_to_friday_ranges_custom</a></code></li>
<li><code><a title="prod_query.views.get_total_produced_last_op_for_block" href="#prod_query.views.get_total_produced_last_op_for_block">get_total_produced_last_op_for_block</a></code></li>
<li><code><a title="prod_query.views.gfx_downtime_and_produced_view" href="#prod_query.views.gfx_downtime_and_produced_view">gfx_downtime_and_produced_view</a></code></li>
<li><code><a title="prod_query.views.handle_remaining_days" href="#prod_query.views.handle_remaining_days">handle_remaining_days</a></code></li>
<li><code><a title="prod_query.views.machine_detail" href="#prod_query.views.machine_detail">machine_detail</a></code></li>
<li><code><a title="prod_query.views.machine_oee" href="#prod_query.views.machine_oee">machine_oee</a></code></li>
<li><code><a title="prod_query.views.moving_average" href="#prod_query.views.moving_average">moving_average</a></code></li>
<li><code><a title="prod_query.views.oa_by_day" href="#prod_query.views.oa_by_day">oa_by_day</a></code></li>
<li><code><a title="prod_query.views.oa_byline2" href="#prod_query.views.oa_byline2">oa_byline2</a></code></li>
<li><code><a title="prod_query.views.oa_display" href="#prod_query.views.oa_display">oa_display</a></code></li>
<li><code><a title="prod_query.views.oa_display_v2" href="#prod_query.views.oa_display_v2">oa_display_v2</a></code></li>
<li><code><a title="prod_query.views.oa_drilldown" href="#prod_query.views.oa_drilldown">oa_drilldown</a></code></li>
<li><code><a title="prod_query.views.parse_date_range" href="#prod_query.views.parse_date_range">parse_date_range</a></code></li>
<li><code><a title="prod_query.views.parse_dates" href="#prod_query.views.parse_dates">parse_dates</a></code></li>
<li><code><a title="prod_query.views.pr_downtime_view" href="#prod_query.views.pr_downtime_view">pr_downtime_view</a></code></li>
<li><code><a title="prod_query.views.press_runtime_wrapper" href="#prod_query.views.press_runtime_wrapper">press_runtime_wrapper</a></code></li>
<li><code><a title="prod_query.views.press_runtime_wrapper2" href="#prod_query.views.press_runtime_wrapper2">press_runtime_wrapper2</a></code></li>
<li><code><a title="prod_query.views.press_runtime_wrapper3" href="#prod_query.views.press_runtime_wrapper3">press_runtime_wrapper3</a></code></li>
<li><code><a title="prod_query.views.prod_query" href="#prod_query.views.prod_query">prod_query</a></code></li>
<li><code><a title="prod_query.views.prod_query_index_view" href="#prod_query.views.prod_query_index_view">prod_query_index_view</a></code></li>
<li><code><a title="prod_query.views.production_from_cycletime" href="#prod_query.views.production_from_cycletime">production_from_cycletime</a></code></li>
<li><code><a title="prod_query.views.recalculate_adjusted_targets" href="#prod_query.views.recalculate_adjusted_targets">recalculate_adjusted_targets</a></code></li>
<li><code><a title="prod_query.views.reject_query" href="#prod_query.views.reject_query">reject_query</a></code></li>
<li><code><a title="prod_query.views.save_machine_target" href="#prod_query.views.save_machine_target">save_machine_target</a></code></li>
<li><code><a title="prod_query.views.shift_start_end_from_form_times" href="#prod_query.views.shift_start_end_from_form_times">shift_start_end_from_form_times</a></code></li>
<li><code><a title="prod_query.views.shift_totals_view" href="#prod_query.views.shift_totals_view">shift_totals_view</a></code></li>
<li><code><a title="prod_query.views.stip_weekends" href="#prod_query.views.stip_weekends">stip_weekends</a></code></li>
<li><code><a title="prod_query.views.strokes_per_min_graph" href="#prod_query.views.strokes_per_min_graph">strokes_per_min_graph</a></code></li>
<li><code><a title="prod_query.views.strokes_per_minute_chart_data" href="#prod_query.views.strokes_per_minute_chart_data">strokes_per_minute_chart_data</a></code></li>
<li><code><a title="prod_query.views.sub_index" href="#prod_query.views.sub_index">sub_index</a></code></li>
<li><code><a title="prod_query.views.summarize_contiguous_intervals" href="#prod_query.views.summarize_contiguous_intervals">summarize_contiguous_intervals</a></code></li>
<li><code><a title="prod_query.views.target_create_ajax" href="#prod_query.views.target_create_ajax">target_create_ajax</a></code></li>
<li><code><a title="prod_query.views.target_delete_ajax" href="#prod_query.views.target_delete_ajax">target_delete_ajax</a></code></li>
<li><code><a title="prod_query.views.target_edit_ajax" href="#prod_query.views.target_edit_ajax">target_edit_ajax</a></code></li>
<li><code><a title="prod_query.views.targets_list" href="#prod_query.views.targets_list">targets_list</a></code></li>
<li><code><a title="prod_query.views.targets_load_more_ajax" href="#prod_query.views.targets_load_more_ajax">targets_load_more_ajax</a></code></li>
<li><code><a title="prod_query.views.test_view" href="#prod_query.views.test_view">test_view</a></code></li>
<li><code><a title="prod_query.views.total_scrap_for_line" href="#prod_query.views.total_scrap_for_line">total_scrap_for_line</a></code></li>
<li><code><a title="prod_query.views.total_scrap_view" href="#prod_query.views.total_scrap_view">total_scrap_view</a></code></li>
<li><code><a title="prod_query.views.update_target" href="#prod_query.views.update_target">update_target</a></code></li>
<li><code><a title="prod_query.views.validate_threshold" href="#prod_query.views.validate_threshold">validate_threshold</a></code></li>
<li><code><a title="prod_query.views.weekly_prod" href="#prod_query.views.weekly_prod">weekly_prod</a></code></li>
<li><code><a title="prod_query.views.weekly_prod_goal" href="#prod_query.views.weekly_prod_goal">weekly_prod_goal</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
