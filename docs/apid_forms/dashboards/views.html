<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>dashboards.views API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dashboards.views</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dashboards.views.Graph_Data"><code class="name flex">
<span>def <span class="ident">Graph_Data</span></span>(<span>t, u, machine, tmp, multiplier)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Graph_Data(t, u, machine, tmp, multiplier):
    # global tst
    cc = 0
    cr = 0
    cm = 0
    # last_by used for comparison
    last_by = 0
    temp_ctr = 0
    brk1 = 0
    brk2 = 0
    multiplier = multiplier / float(6)
    tm_sh = int((t-u)/600)
    px = [0 for x in range(tm_sh)]
    pp = [0 for x in range(tm_sh)]
    by = [0 for x in range(tm_sh)]
    ay = [0 for x in range(tm_sh)]
    cy = [0 for x in range(tm_sh)]
    for ab in range(0, tm_sh):
        temp_u = u + (cc*600)
        u_time = stamp_pdate4(temp_u)

        pp[ab] = u_time
        pp[ab] = u
        px[ab] = u + (cc*600)

        yy = px[ab]
        cc = cc + 1
        cr = cr + multiplier
        cm = cr * .8
        tst = []

        a = []
        ctr = 0
        for i in tmp:
            ctr = ctr+1
            a.append(i[4])

        op4 = list(filter(lambda c: c[4] &lt; yy, tmp))
        by[ab] = len(op4)

        ay[ab] = int(cr)
        cy[ab] = int(cm)

    tm_sh = tm_sh - 1

    gr_list = list(zip(px, by, ay, cy, pp))

    return gr_list, brk1, brk2, multiplier</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="dashboards.views.cell_track_1467"><code class="name flex">
<span>def <span class="ident">cell_track_1467</span></span>(<span>request, template)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@cache_page(5)
def cell_track_1467(request, template):
    &#34;&#34;&#34;Display real-time and cumulative production metrics for cell 1467 with short-term caching.

    This view performs the following steps:
      1. Retrieves the shift start and elapsed times via `stamp_shift_start()`.
      2. Reads the production target for part family &#34;50-1467&#34; from `request.site_variables`.
      3. Defines the line specification for machines 644–649.
      4. Calls `get_line_prod()` to fetch last-5-minute and shift-to-date counts, plus predictions.
      5. Logs shift counts via `log_shift_times()`.
      6. Assembles context variables:
         - `codes`: per-machine production tuples
         - `actual_counts`: time-series data for charting
         - `op`: per-operation aggregated production
         - `wip`: work-in-progress list (empty by default)
         - `args`: form arguments for history lookup
         - `runrate`: stored run-rate value
         - `elapsed`: view execution time
      7. On POST, captures date/shift for history and renders a redirect template.
      8. Otherwise, renders the specified dashboard template under `dashboards/`.

    Caching:
        The output is cached for 5 seconds via `@cache_page(5)` to reduce load under frequent reloads.

    Args:
        request (HttpRequest): Incoming request, including session and POST data.
        template (str): Filename of the dashboard template (e.g. &#39;cell_track_1467.html&#39;).

    Returns:
        HttpResponse: The rendered dashboard page or a history‐redirect page on POST.
    &#34;&#34;&#34;
    tic = time.time()  # track the execution time
    context = {}  # data sent to template

    target_production_1467 = int(
        request.site_variables.get(&#39;target_production_1467&#39;, 1400))

    # Get the Time Stamp info
    shift_start, shift_time, shift_left, shift_end = stamp_shift_start()
    context[&#39;t&#39;] = shift_start + shift_time
    request.session[&#34;shift_start&#34;] = shift_start

    line_spec = [
        (&#39;644&#39;, [&#39;644&#39;], 6, 10),
        (&#39;645&#39;, [&#39;645&#39;], 6, 10), 
        (&#39;646&#39;, [&#39;646&#39;], 6, 10),
        (&#39;647&#39;, [&#39;647&#39;], 6, 10), 
        (&#39;649&#39;, [&#39;649&#39;], 6, 10),
    ]

    # Right here I will call the new function

    machine_production, op_production = get_line_prod(
        line_spec, target_production_1467, &#39;&#34;50-1467&#34;&#39;, shift_start, shift_time)

    context[&#39;codes&#39;] = machine_production
    actual_counts = [(mp[0], mp[1]) for mp in machine_production]
    part_list = [&#34;50-1467&#34;]
    context[&#39;actual_counts&#39;] = log_shift_times(shift_start, shift_time, actual_counts, part_list)
    context[&#39;op&#39;] = op_production
    context[&#39;wip&#39;] = []

    # Date entry for History
    if request.POST:
        request.session[&#34;track_date&#34;] = request.POST.get(&#34;date_st&#34;)
        request.session[&#34;track_shift&#34;] = request.POST.get(&#34;shift&#34;)
        return render(request, &#39;redirect_cell_track_1467_history.html&#39;)
    else:
        form = sup_downForm()
    args = {}
    # args.update(csrf(request))
    args[&#39;form&#39;] = form
    context[&#39;args&#39;] = args
    request.session[&#39;runrate&#39;] = 1128
    context[&#39;elapsed&#39;] = time.time()-tic

    return render(request, f&#39;dashboards/{template}&#39;, context)</code></pre>
</details>
<div class="desc"><p>Display real-time and cumulative production metrics for cell 1467 with short-term caching.</p>
<p>This view performs the following steps:
1. Retrieves the shift start and elapsed times via <code><a title="dashboards.views.stamp_shift_start" href="#dashboards.views.stamp_shift_start">stamp_shift_start()</a></code>.
2. Reads the production target for part family "50-1467" from <code>request.site_variables</code>.
3. Defines the line specification for machines 644–649.
4. Calls <code><a title="dashboards.views.get_line_prod" href="#dashboards.views.get_line_prod">get_line_prod()</a></code> to fetch last-5-minute and shift-to-date counts, plus predictions.
5. Logs shift counts via <code><a title="dashboards.views.log_shift_times" href="#dashboards.views.log_shift_times">log_shift_times()</a></code>.
6. Assembles context variables:
- <code>codes</code>: per-machine production tuples
- <code>actual_counts</code>: time-series data for charting
- <code>op</code>: per-operation aggregated production
- <code>wip</code>: work-in-progress list (empty by default)
- <code>args</code>: form arguments for history lookup
- <code>runrate</code>: stored run-rate value
- <code>elapsed</code>: view execution time
7. On POST, captures date/shift for history and renders a redirect template.
8. Otherwise, renders the specified dashboard template under <code>dashboards/</code>.</p>
<h2 id="caching">Caching</h2>
<p>The output is cached for 5 seconds via <code>@cache_page(5)</code> to reduce load under frequent reloads.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>HttpRequest</code></dt>
<dd>Incoming request, including session and POST data.</dd>
<dt><strong><code>template</code></strong> :&ensp;<code>str</code></dt>
<dd>Filename of the dashboard template (e.g. 'cell_track_1467.html').</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>HttpResponse</code></dt>
<dd>The rendered dashboard page or a history‐redirect page on POST.</dd>
</dl></div>
</dd>
<dt id="dashboards.views.cell_track_9341"><code class="name flex">
<span>def <span class="ident">cell_track_9341</span></span>(<span>request, target)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@cache_page(5)
def cell_track_9341(request, target):
    &#34;&#34;&#34;Display real-time and predictive production metrics for cell 9341 (and 0455) with caching.

    Retrieves shift timing, production targets, and site variables, then:
      1. Computes the current shift start, elapsed, remaining, and end times.
      2. Fetches last-5-minute and cumulative production for part family &#34;50-9341&#34; 
         using `get_line_prod2()`, and logs shift counts via `log_shift_times()`.
      3. Computes per-operation actual output and OEE metrics with `compute_op_actual_and_oee()`.
      4. Repeats steps 2–3 for part family &#34;50-0455&#34;.
      5. Handles optional date/shift history submission via `sup_downForm`.
      6. Stores run rate and computes color codes for overall cell performance.
      7. Renders the appropriate template (`dashboards/cell_track_9341.html`) based on `target`.

    Caching:
        The page is cached for 5 seconds to reduce database load under rapid refresh.

    Args:
        request (HttpRequest): The incoming HTTP request containing session and POST data.
        target (str): Display mode indicator (e.g. &#39;tv&#39;, &#39;mobile&#39;) to select the template styling.

    Returns:
        HttpResponse: Rendered dashboard page with context containing:
            - &#39;codes&#39;, &#39;codes_60&#39;: per-machine production tuples
            - &#39;op&#39;, &#39;op_60&#39;: per-operation production/color tuples
            - &#39;op_actual&#39;, &#39;op_oee&#39;, &#39;op_actual_60&#39;, &#39;op_oee_60&#39;: actual/output and OEE metrics
            - Shift timing, run rate, WIP lists, color codes, and history form args.
    &#34;&#34;&#34;
    tic = time.time()  # track the execution time
    context = {}  # data sent to template
    context[&#39;page_title&#39;] = &#39;9341 Tracking&#39;

    target_production_9341 = int(
        request.site_variables.get(&#39;target_production_9341&#39;, 2900))
    target_production_0455 = int(
        request.site_variables.get(&#39;target_production_0455&#39;, 900))

    # Get the Time Stamp info
    shift_start, shift_time, shift_left, shift_end = stamp_shift_start()
    context[&#39;t&#39;] = shift_start + shift_time
    request.session[&#39;shift_start&#39;] = shift_start

    line_spec_9341 = [  # (&#39;Asset&#39;,&#39;source&#39;, rate, OP)
        # Main line
        (&#39;1504&#39;, &#39;1504&#39;, 8, 10), (&#39;1506&#39;, &#39;1506&#39;, 8, 10), (&#39;1519&#39;, &#39;1519&#39;, 8, 10), (&#39;1520&#39;, &#39;1520&#39;, 8, 10),
        (&#39;1502&#39;, &#39;1502&#39;, 4, 30), (&#39;1507&#39;, &#39;1507&#39;, 4, 30),
        (&#39;1501&#39;, &#39;1501&#39;, 4, 40), (&#39;1515&#39;, &#39;1515&#39;, 4, 40),
        (&#39;1508&#39;, &#39;1508&#39;, 4, 50), (&#39;1532&#39;, &#39;1532&#39;, 4, 50),
        (&#39;1509&#39;, &#39;1509&#39;, 2, 60),
        (&#39;1514&#39;, &#39;1514&#39;, 2, 70),
        (&#39;1510&#39;, &#39;1510&#39;, 2, 80),
        (&#39;1503&#39;, &#39;1503&#39;, 2, 100),
        (&#39;1511&#39;, &#39;1511&#39;, 2, 110),
        # Offline
        (&#39;1518&#39;, &#39;1518&#39;, 8, 10), (&#39;1521&#39;, &#39;1521&#39;, 8, 10), (&#39;1522&#39;, &#39;1522&#39;, 8, 10), (&#39;1523&#39;, &#39;1523&#39;, 8, 10),
        (&#39;1539&#39;, &#39;1539&#39;, 4, 30), (&#39;1540&#39;, &#39;1540&#39;, 4, 30),
        (&#39;1524&#39;, &#39;1524&#39;, 4, 40), (&#39;1525&#39;, &#39;1525&#39;, 4, 40),
        (&#39;1538&#39;, &#39;1538&#39;, 4, 50),
        (&#39;1541&#39;, &#39;1541&#39;, 2, 60),
        (&#39;1531&#39;, &#39;1541&#39;, 2, 70),
        (&#39;1527&#39;, &#39;1527&#39;, 2, 80),
        (&#39;1530&#39;, &#39;1530&#39;, 2, 100),
        (&#39;1528&#39;, &#39;1528&#39;, 2, 110),
        (&#39;1513&#39;, &#39;1513&#39;, 2, 90),
        (&#39;1533&#39;, &#39;1533&#39;, 2, 120),
        # uplift
        (&#39;1546&#39;, &#39;1546&#39;, 2, 30),
        (&#39;1547&#39;, &#39;1547&#39;, 2, 40),
        (&#39;1548&#39;, &#39;1548&#39;, 2, 50),
        (&#39;1549&#39;, &#39;1549&#39;, 2, 60),
        (&#39;594&#39;, &#39;1549&#39;, 2, 70),
        (&#39;1551&#39;, &#39;1551&#39;, 2, 80),
        (&#39;1552&#39;, &#39;1552&#39;, 2, 90),
        (&#39;751&#39;, &#39;751&#39;, 2, 100),
        (&#39;1554&#39;, &#39;1554&#39;, 2, 110),
    ]


    machine_production_9341, op_production_9341 = get_line_prod2(
        line_spec_9341, target_production_9341, &#39;&#34;50-9341&#34;&#39;, shift_start, shift_time)

    context[&#39;codes&#39;] = machine_production_9341
    actual_counts = [(mp[0], mp[1]) for mp in machine_production_9341]
    part_list = [&#34;50-9341&#34;]
    context[&#39;actual_counts&#39;] = log_shift_times(shift_start, shift_time, actual_counts, part_list)
    context[&#39;op&#39;] = op_production_9341

    # -- surgical insertion here --
    op_actual_9341, op_oee_9341 = compute_op_actual_and_oee(
        line_spec_9341,
        machine_production_9341,
        shift_start,
        shift_time,
        part_list=[&#34;50-9341&#34;]
    )
    context[&#39;op_actual&#39;] = op_actual_9341
    context[&#39;op_oee&#39;]    = op_oee_9341

    context[&#39;wip&#39;] = []

    line_spec = [  # (&#39;Asset&#39;,&#39;Count&#39;, rate, OP)
        # Main line
        (&#39;1800&#39;, &#39;1800&#39;, 2, 10), (&#39;1801&#39;, &#39;1801&#39;, 2, 10), (&#39;1802&#39;, &#39;1802&#39;, 2, 10),
        (&#39;1529&#39;, &#39;1529&#39;, 4, 30), (&#39;1543&#39;, &#39;1543&#39;, 4, 30), (&#39;776&#39;, &#39;776&#39;, 4, 30), (&#39;1824&#39;, &#39;1824&#39;, 4, 30),
        (&#39;1804&#39;, &#39;1804&#39;, 2, 40), (&#39;1805&#39;, &#39;1805&#39;, 2, 40),
        (&#39;1806&#39;, &#39;1806&#39;, 1, 50),
        (&#39;1808&#39;, &#39;1808&#39;, 1, 60),
        (&#39;1810&#39;, &#39;1810&#39;, 1, 70),
        (&#39;1815&#39;, &#39;1815&#39;, 1, 80),
        (&#39;1542&#39;, &#39;1812&#39;, 1, 90),
        (&#39;1812&#39;, &#39;1812&#39;, 1, 100),
        (&#39;1813&#39;, &#39;1813&#39;, 1, 110),
        (&#39;1816&#39;, &#39;1816&#39;, 1, 120),
    ]



    machine_production_0455, op_production_0455 = get_line_prod2(
        line_spec, target_production_0455, &#39;&#34;50-0455&#34;&#39;, shift_start, shift_time)

    context[&#39;codes_60&#39;] = machine_production_0455
    actual_counts = [(mp[0], mp[1]) for mp in machine_production_0455]
    part_list = [&#34;50-0455&#34;]
    context[&#39;actual_counts_60&#39;] = log_shift_times(shift_start, shift_time, actual_counts, part_list)
    context[&#39;op_60&#39;] = op_production_0455

    # -- surgical insertion here for 0455 OEE stuff --
    op_actual_60, op_oee_60 = compute_op_actual_and_oee(
        line_spec,
        machine_production_0455,
        shift_start,
        shift_time,
        part_list=[&#34;50-0455&#34;]
    )
    context[&#39;op_actual_60&#39;] = op_actual_60
    context[&#39;op_oee_60&#39;]    = op_oee_60

    context[&#39;wip_60&#39;] = []

    # Date entry for History
    if request.POST:
        request.session[&#34;track_date&#34;] = request.POST.get(&#34;date_st&#34;)
        request.session[&#34;track_shift&#34;] = request.POST.get(&#34;shift&#34;)
        return render(request, &#39;redirect_cell_track_9341_history.html&#39;)
    else:
        form = sup_downForm()
    args = {&#39;form&#39;: form}
    context[&#39;args&#39;] = args
    request.session[&#39;runrate&#39;] = 1128

    r80 = op_production_9341[120][0]
    c80 = &#34;#bdb4b3&#34;
    c60 = &#34;#bdb4b3&#34;
    if r80 &gt;= target_production_9341:
        c80 = &#34;#7FEB1E&#34;
    elif r80 &gt;= target_production_9341 * .9:
        c80 = &#34;#FFEB55&#34;
    else:
        c80 = &#34;#FF7355&#34;
    context[&#39;R80&#39;] = c80

    r60 = op_production_0455[120][0]
    if r60 &gt;= target_production_0455:
        c60 = &#34;#7FEB1E&#34;
    elif r60 &gt;= target_production_0455 * .9:
        c60 = &#34;#FFEB55&#34;
    else:
        c60 = &#34;#FF7355&#34;
    context[&#39;R60&#39;] = c60

    context[&#39;elapsed&#39;] = time.time()-tic
    context[&#39;target&#39;] = target
    if target == &#39;tv&#39;:
        template = &#39;dashboards/cell_track_9341.html&#39;
    elif target == &#39;mobile&#39;:
        template = &#39;dashboards/cell_track_9341.html&#39;
    else:
        template = &#39;dashboards/cell_track_9341.html&#39;

    return render(request, template, context)</code></pre>
</details>
<div class="desc"><p>Display real-time and predictive production metrics for cell 9341 (and 0455) with caching.</p>
<p>Retrieves shift timing, production targets, and site variables, then:
1. Computes the current shift start, elapsed, remaining, and end times.
2. Fetches last-5-minute and cumulative production for part family "50-9341"
using <code><a title="dashboards.views.get_line_prod2" href="#dashboards.views.get_line_prod2">get_line_prod2()</a></code>, and logs shift counts via <code><a title="dashboards.views.log_shift_times" href="#dashboards.views.log_shift_times">log_shift_times()</a></code>.
3. Computes per-operation actual output and OEE metrics with <code><a title="dashboards.views.compute_op_actual_and_oee" href="#dashboards.views.compute_op_actual_and_oee">compute_op_actual_and_oee()</a></code>.
4. Repeats steps 2–3 for part family "50-0455".
5. Handles optional date/shift history submission via <code><a title="dashboards.views.sup_downForm" href="#dashboards.views.sup_downForm">sup_downForm</a></code>.
6. Stores run rate and computes color codes for overall cell performance.
7. Renders the appropriate template (<code>dashboards/cell_track_9341.html</code>) based on <code>target</code>.</p>
<h2 id="caching">Caching</h2>
<p>The page is cached for 5 seconds to reduce database load under rapid refresh.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>HttpRequest</code></dt>
<dd>The incoming HTTP request containing session and POST data.</dd>
<dt><strong><code>target</code></strong> :&ensp;<code>str</code></dt>
<dd>Display mode indicator (e.g. 'tv', 'mobile') to select the template styling.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>HttpResponse</code></dt>
<dd>Rendered dashboard page with context containing:
- 'codes', 'codes_60': per-machine production tuples
- 'op', 'op_60': per-operation production/color tuples
- 'op_actual', 'op_oee', 'op_actual_60', 'op_oee_60': actual/output and OEE metrics
- Shift timing, run rate, WIP lists, color codes, and history form args.</dd>
</dl></div>
</dd>
<dt id="dashboards.views.cell_track_trilobe"><code class="name flex">
<span>def <span class="ident">cell_track_trilobe</span></span>(<span>request, template)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@cache_page(5)
def cell_track_trilobe(request, template):
    &#34;&#34;&#34;Display real-time and predictive production and OEE metrics for the Trilobe cell line.

    Caches the view for 5 seconds to reduce load under frequent refresh.

    Workflow:
      1. Reads four production targets from `request.site_variables`:
         - `target_production_trilobe_sinter`
         - `target_production_trilobe_optimized`
         - `target_production_trilobe_trilobe`
         - `target_production_trilobe_optimized` (again, if configured)
      2. Uses `stamp_shift_start_3()` to determine the current 8-hour shift start, elapsed time, etc.
      3. For each of four column specifications (`line_spec_col_1` through `line_spec_col_4`):
         a. Calls `get_line_prod()` to fetch last-5-minute and shift-to-date counts plus predictions.  
         b. Logs shift counts via `log_shift_times()`.  
         c. Computes per-operation actual output and OEE metrics via `compute_op_actual_and_oee()`.  
         d. Populates context keys:
             - `codes_colN`, `actual_counts_colN`, `op_colN`, `op_actual_colN`, `op_oee_colN`, `wip_colN`
      4. On POST, captures `date_st` and `shift` into the session and renders a history-redirect template.
      5. Measures total execution time and passes it in context.

    Args:
        request (HttpRequest): The incoming request, including session, site variables, and POST data.
        template (str): The name of the dashboard template to render (e.g. `&#39;cell_track_trilobe.html&#39;`).

    Returns:
        HttpResponse: The rendered dashboard page with context containing production metrics, OEE, timing, and history form.
    &#34;&#34;&#34;
    tic = time.time()  # track the execution time
    context = {}  # data sent to template

    target_production_col1 = int(
        request.site_variables.get(&#39;target_production_trilobe_sinter&#39;, 300))
    target_production_col2 = int(
        request.site_variables.get(&#39;target_production_trilobe_optimized&#39;, 300))
    target_production_col3 = int(
        request.site_variables.get(&#39;target_production_trilobe_trilobe&#39;, 300))
    target_production_col4 = int(request.site_variables.get(
        &#39;target_production_trilobe_optimized&#39;, 300))

    # Get the Time Stamp info
    shift_start, shift_time, shift_left, shift_end = stamp_shift_start_3()
    context[&#39;t&#39;] = shift_start + shift_time
    request.session[&#34;shift_start&#34;] = shift_start

    line_spec_col_1 = [
        (&#39;262&#39;, [&#39;262&#39;], 2, 10),  # Compact
        (&#39;263&#39;, [&#39;263&#39;], 2, 10),  # Compact
        (&#39;859&#39;, [&#39;859&#39;], 1, 20),  # nothing
        (&#39;992&#39;, [&#39;992&#39;], 1, 30),  # nothing
    ]


    machine_production_col1, op_production_col1 = get_line_prod(
        line_spec_col_1, target_production_col1, None, shift_start, shift_time)

    context[&#39;codes_col1&#39;] = machine_production_col1
    actual_counts = [(mp[0], mp[1]) for mp in machine_production_col1]
    part_list = None
    context[&#39;actual_counts_col1&#39;] = log_shift_times(shift_start, shift_time, actual_counts, part_list)
    context[&#39;op_col1&#39;] = op_production_col1

    # -- surgical insertion here for Col 1 OEE stuff --
    op_actual_col1, op_oee_col1 = compute_op_actual_and_oee(
        line_spec_col_1,
        machine_production_col1,
        shift_start,
        shift_time,
        part_list=None
    )
    context[&#39;op_actual_col1&#39;] = op_actual_col1
    context[&#39;op_oee_col1&#39;]    = op_oee_col1


    context[&#39;wip&#39;] = []

    line_spec_col_2 = [
        (&#39;784&#39;, [&#39;770&#39;], 1, 10),  # 50-1467, 50-3050, 50-5710
        (&#39;770&#39;, [&#39;770&#39;], 1, 20),  # 50-1467, 50-3050, 50-5710
        (&#39;618&#39;, [&#39;618&#39;], 4, 30),  # magna
        (&#39;575&#39;, [&#39;575&#39;], 4, 30),  # manga
        (&#39;624&#39;, [&#39;624&#39;], 4, 30),  # magna
        (&#39;619&#39;, [&#39;619&#39;], 4, 30),  # magna
        (&#39;769&#39;, [&#39;769&#39;], 1, 40),  # 50-1467, 50-3050, 50-5710
    ]


    machine_production_col2, op_production_col2 = get_line_prod(
        line_spec_col_2, target_production_col2, None, shift_start, shift_time)

    context[&#39;codes_col2&#39;] = machine_production_col2
    actual_counts = [(mp[0], mp[1]) for mp in machine_production_col2]
    part_list = None
    context[&#39;actual_counts_col2&#39;] = log_shift_times(shift_start, shift_time, actual_counts, part_list)
    context[&#39;op_col2&#39;] = op_production_col2


    # -- surgical insertion here for Col 2 OEE stuff --
    op_actual_col2, op_oee_col2 = compute_op_actual_and_oee(
        line_spec_col_2,
        machine_production_col2,
        shift_start,
        shift_time,
        part_list=None
    )
    context[&#39;op_actual_col2&#39;] = op_actual_col2
    context[&#39;op_oee_col2&#39;]    = op_oee_col2



    context[&#39;wip_col2&#39;] = []

    line_spec_col_3 = [
        (&#39;573&#39;, [&#39;728&#39;], 1, 10),  # 50-1467
        (&#39;728&#39;, [&#39;728&#39;], 1, 20),  # 50-1467
        (&#39;644&#39;, [&#39;644&#39;], 6, 30),  # 50-1467
        (&#39;645&#39;, [&#39;645&#39;], 6, 30),  # 50-1467
        (&#39;646&#39;, [&#39;646&#39;], 6, 30),  # 50-1467
        (&#39;647&#39;, [&#39;647&#39;], 6, 30),  # 50-1467
        (&#39;649&#39;, [&#39;649&#39;], 6, 30),  # 50-1467
        (&#39;742&#39;, [&#39;742&#39;, &#39;650L&#39;, &#39;650R&#39;], 1, 40),  # 50-1467    # 650L and 650R replaced with 742 5/28/2024
    ]


    machine_production_col3, op_production_col3 = get_line_prod(
        line_spec_col_3, target_production_col3, None, shift_start, shift_time)

    context[&#39;codes_col3&#39;] = machine_production_col3
    actual_counts = [(mp[0], mp[1]) for mp in machine_production_col3]
    part_list = None
    context[&#39;actual_counts_col3&#39;] = log_shift_times(shift_start, shift_time, actual_counts, part_list)
    context[&#39;op_col3&#39;] = op_production_col3

    # -- surgical insertion here for Col 3 OEE stuff --
    op_actual_col3, op_oee_col3 = compute_op_actual_and_oee(
        line_spec_col_3,
        machine_production_col3,
        shift_start,
        shift_time,
        part_list=None
    )
    context[&#39;op_actual_col3&#39;] = op_actual_col3
    context[&#39;op_oee_col3&#39;]    = op_oee_col3

    context[&#39;wip_col3&#39;] = []

    line_spec_col_4 = [
        (&#39;636&#39;, [&#39;636&#39;], 1, 10),  # 50-5710
        (&#39;625&#39;, [&#39;625&#39;], 1, 20),  # 50-5710
        (&#39;Prediction&#39;, [&#39;625&#39;, &#39;636&#39;], 1, 30),
    ]

    machine_production_col4, op_production_col4 = get_line_prod(
        line_spec_col_4, target_production_col4, None, shift_start, shift_time)

    context[&#39;codes_col4&#39;] = machine_production_col4
    actual_counts = [(mp[0], mp[1]) for mp in machine_production_col4]
    part_list = None
    context[&#39;actual_counts_col4&#39;] = log_shift_times(shift_start, shift_time, actual_counts, part_list)
    context[&#39;op_col4&#39;] = op_production_col4


    # -- surgical insertion here for Col 4 OEE stuff --
    op_actual_col4, op_oee_col4 = compute_op_actual_and_oee(
        line_spec_col_4,
        machine_production_col4,
        shift_start,
        shift_time,
        part_list=None
    )
    context[&#39;op_actual_col4&#39;] = op_actual_col4
    context[&#39;op_oee_col4&#39;]    = op_oee_col4


    context[&#39;wip_col4&#39;] = []

    # Date entry for History
    if request.POST:
        request.session[&#34;track_date&#34;] = request.POST.get(&#34;date_st&#34;)
        request.session[&#34;track_shift&#34;] = request.POST.get(&#34;shift&#34;)
        return render(request, &#39;redirect_cell_track_8670_history.html&#39;)
    else:
        form = sup_downForm()
    args = {}
    # args.update(csrf(request))
    args[&#39;form&#39;] = form
    context[&#39;args&#39;] = args

    context[&#39;elapsed&#39;] = time.time()-tic
    return render(request, f&#39;dashboards/{template}&#39;, context)</code></pre>
</details>
<div class="desc"><p>Display real-time and predictive production and OEE metrics for the Trilobe cell line.</p>
<p>Caches the view for 5 seconds to reduce load under frequent refresh.</p>
<h2 id="workflow">Workflow</h2>
<ol>
<li>Reads four production targets from <code>request.site_variables</code>:</li>
<li><code>target_production_trilobe_sinter</code></li>
<li><code>target_production_trilobe_optimized</code></li>
<li><code>target_production_trilobe_trilobe</code></li>
<li><code>target_production_trilobe_optimized</code> (again, if configured)</li>
<li>Uses <code><a title="dashboards.views.stamp_shift_start_3" href="#dashboards.views.stamp_shift_start_3">stamp_shift_start_3()</a></code> to determine the current 8-hour shift start, elapsed time, etc.</li>
<li>For each of four column specifications (<code>line_spec_col_1</code> through <code>line_spec_col_4</code>):
a. Calls <code><a title="dashboards.views.get_line_prod" href="#dashboards.views.get_line_prod">get_line_prod()</a></code> to fetch last-5-minute and shift-to-date counts plus predictions.<br>
b. Logs shift counts via <code><a title="dashboards.views.log_shift_times" href="#dashboards.views.log_shift_times">log_shift_times()</a></code>.<br>
c. Computes per-operation actual output and OEE metrics via <code><a title="dashboards.views.compute_op_actual_and_oee" href="#dashboards.views.compute_op_actual_and_oee">compute_op_actual_and_oee()</a></code>.<br>
d. Populates context keys:<ul>
<li><code>codes_colN</code>, <code>actual_counts_colN</code>, <code>op_colN</code>, <code>op_actual_colN</code>, <code>op_oee_colN</code>, <code>wip_colN</code></li>
</ul>
</li>
<li>On POST, captures <code>date_st</code> and <code>shift</code> into the session and renders a history-redirect template.</li>
<li>Measures total execution time and passes it in context.</li>
</ol>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>HttpRequest</code></dt>
<dd>The incoming request, including session, site variables, and POST data.</dd>
<dt><strong><code>template</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the dashboard template to render (e.g. <code>'cell_track_trilobe.html'</code>).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>HttpResponse</code></dt>
<dd>The rendered dashboard page with context containing production metrics, OEE, timing, and history form.</dd>
</dl></div>
</dd>
<dt id="dashboards.views.compute_op_actual_and_oee"><code class="name flex">
<span>def <span class="ident">compute_op_actual_and_oee</span></span>(<span>line_spec, machine_production, shift_start, shift_time, part_list=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_op_actual_and_oee(line_spec,
                              machine_production,
                              shift_start,
                              shift_time,
                              part_list=None):
    &#34;&#34;&#34;
    Returns two lists:
      op_actual_list[i] = total actual for OP i
      op_oee_list[i]    = int OEE% (or &#34;N/A&#34;) for OP i

    Only for machines in machines_requiring_part_list will we call
      get_machine_target(asset, shift_start, part_list)
    and treat its return as the period target.
    All others get the weekly target scaled by shift_time/7200.
    &#34;&#34;&#34;
    minutes_elapsed = shift_time / 60.0
    factor          = minutes_elapsed / 7200.0

    # map asset → OP
    asset2op = {asset: op for asset, *_, op in line_spec}

    # accumulators
    op_actual   = defaultdict(int)
    op_adjusted = defaultdict(float)

    for asset, actual_count, *_ in machine_production:
        op = asset2op.get(asset)
        if op is None:
            continue

        # choose per-machine target logic
        if part_list and asset in machines_requiring_part_list:
            # smart‐total for this exact period &amp; parts
            period_target = get_machine_target(asset, shift_start, part_list) or 0
        else:
            # fall back to weekly target → scale for this shift
            weekly_target = get_machine_target(asset, shift_start) or 0
            period_target = weekly_target * factor

        # accumulate
        op_actual[op]   += actual_count
        op_adjusted[op] += period_target

    # build output lists
    max_op = max(op_actual.keys() | op_adjusted.keys(), default=-1)
    op_actual_list = [0] * (max_op + 1)
    op_oee_list    = [None] * (max_op + 1)

    for op, actual in op_actual.items():
        op_actual_list[op] = actual

    for op, adjusted in op_adjusted.items():
        if adjusted &gt; 0:
            op_oee_list[op] = int(op_actual[op] / adjusted * 100)
        else:
            op_oee_list[op] = &#34;N/A&#34;

    return op_actual_list, op_oee_list</code></pre>
</details>
<div class="desc"><p>Returns two lists:
op_actual_list[i] = total actual for OP i
op_oee_list[i]
= int OEE% (or "N/A") for OP i</p>
<p>Only for machines in machines_requiring_part_list will we call
get_machine_target(asset, shift_start, part_list)
and treat its return as the period target.
All others get the weekly target scaled by shift_time/7200.</p></div>
</dd>
<dt id="dashboards.views.compute_part_durations_for_machine"><code class="name flex">
<span>def <span class="ident">compute_part_durations_for_machine</span></span>(<span>machine_number: str, shift_start_epoch: int, shift_end_epoch: int | None = None) ‑> List[Dict]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_part_durations_for_machine(
    machine_number: str,
    shift_start_epoch: int,
    shift_end_epoch: Optional[int] = None,
) -&gt; List[Dict]:
    &#34;&#34;&#34;
    Return a list of contiguous part‐runs for `machine_number` between the
    two epoch timestamps. Adds debug prints when machine_number == &#34;1703L&#34;.
    Each element:
        {part, start_ts, end_ts, duration}
    &#34;&#34;&#34;
    if shift_end_epoch is None:
        shift_end_epoch = int(timezone.now().timestamp())


    cursor = connections[&#34;prodrpt-md&#34;].cursor()

    # ── what was running at shift start? ───────────────────────────────
    cursor.execute(
        &#34;&#34;&#34;
        SELECT Part, TimeStamp
        FROM   GFxPRoduction
        WHERE  Machine   = %s
          AND  TimeStamp &lt; %s
        ORDER  BY TimeStamp DESC
        LIMIT  1
        &#34;&#34;&#34;,
        [machine_number, shift_start_epoch],
    )
    row = cursor.fetchone()
    initial_part, _ = row if row else (None, None)


    # ── all records inside the window ──────────────────────────────────
    cursor.execute(
        &#34;&#34;&#34;
        SELECT Part, TimeStamp
        FROM   GFxPRoduction
        WHERE  Machine   = %s
          AND  TimeStamp BETWEEN %s AND %s
        ORDER  BY TimeStamp ASC
        &#34;&#34;&#34;,
        [machine_number, shift_start_epoch, shift_end_epoch],
    )
    rows = cursor.fetchall()


    # ── walk through and segment contiguous runs ───────────────────────
    runs: List[Dict] = []
    current_part = None
    current_start = None

    if initial_part is not None:
        current_part, current_start = initial_part, shift_start_epoch

    for part, ts in rows:
        if current_part is None:
            current_part, current_start = part, max(shift_start_epoch, ts)
            continue

        if part == current_part:
            continue

        # part changed → close previous run
        duration = int(ts - current_start)
        runs.append({
            &#34;part&#34;: current_part,
            &#34;start_ts&#34;: current_start,
            &#34;end_ts&#34;: ts,
            &#34;duration&#34;: duration,
        })

        current_part, current_start = part, ts

    # whatever is still running at shift end
    if current_part is not None:
        final_duration = int(shift_end_epoch - current_start)
        runs.append({
            &#34;part&#34;: current_part,
            &#34;start_ts&#34;: current_start,
            &#34;end_ts&#34;: shift_end_epoch,
            &#34;duration&#34;: final_duration,
        })


    return runs</code></pre>
</details>
<div class="desc"><p duration end_ts_="end_ts," part_="part," start_ts_="start_ts,">Return a list of contiguous part‐runs for <code>machine_number</code> between the
two epoch timestamps. Adds debug prints when machine_number == "1703L".
Each element:</p></div>
</dd>
<dt id="dashboards.views.dashboard_current_shift"><code class="name flex">
<span>def <span class="ident">dashboard_current_shift</span></span>(<span>request, pages: str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dashboard_current_shift(request, pages: str):
    &#34;&#34;&#34;Render a live‐updating shift dashboard for one or two programs with efficiency coloring.

    Splits the `pages` argument on “&amp;” to allow one or two program names (e.g. “programA” or
    “programA&amp;programB”), validates against the `PAGES` configuration, and returns a
    400‐BadRequest if the format is invalid or if any program is unknown.

    For each requested program, this view:
      1. Determines the 8-hour shift boundaries in Eastern Time (day/afternoon/night)
         based on a program-specific base hour.
      2. Converts those boundaries to UTC timestamps for database queries.
      3. Builds a set of machines (including expanded sources for any aliases) and
         captures their part groupings.
      4. Runs two SQL aggregations against `GFxPRoduction` to get per-machine, per-part
         counts for the full shift and the last 5 minutes.
      5. Calls `compute_part_durations_for_machine` to fetch part run durations over both intervals.
      6. Annotates each “cell” in the program template with:
         - Cumulative and recent piece counts
         - Cycle time(s) and “smart” targets
         - Shift-long and 5-min efficiencies
         - A color code based on recent efficiency
      7. Constructs alias cells by summing metrics across their source machines, applying
         the same efficiency and coloring logic.
      8. Pads each operation line to a uniform width, filters part runs to declared parts,
         then computes per-operation totals and efficiencies (excluding machines with no target),
         adding a “recent_efficiency” and “color” for each operation.
      9. Collects all program objects into `all_programs`, then renders
         `dashboards/dashboard_renewed.html` with context:
         ```python
         {
             &#34;pages&#34;: pages,
             &#34;programs&#34;: all_programs
         }
         ```

    Args:
        request (HttpRequest): The incoming request, containing session and timezone context.
        pages (str): A single program name or two names joined by &#34;&amp;&#34; indicating which
                     program dashboards to render.

    Returns:
        HttpResponse: Renders the renewed dashboard template with JSON-ready program data,
                      or returns HttpResponseBadRequest for invalid input.
    &#34;&#34;&#34;
    &#34;&#34;&#34;
    pages: either &#34;programA&#34; or &#34;programA&amp;programB&#34;
    We split on &#34;&amp;&#34;, ensure 1 or 2 valid program names, run the annotation logic
    for each machine, and—when computing per-op totals—exclude any machines
    whose smart_target is None or zero so they don’t skew the efficiency.
    Now also computes a 5-minute “recent efficiency” at the operation level and
    colors the operation cell accordingly.  Machines like “733” can be aliased
    to sum the data from multiple source machines (e.g. “1701L” &amp; “1701R”).
    &#34;&#34;&#34;

    # ── 1) Split on &#34;&amp;&#34; and validate count ──────────────────────────────────
    parts = [p.strip() for p in pages.split(&#34;&amp;&#34;) if p.strip()]
    if len(parts) == 0 or len(parts) &gt; 2:
        return HttpResponseBadRequest(
            {&#34;error&#34;: f&#34;Invalid URL segment &#39;{pages}&#39;.  Use /dashboard/foo/ or /dashboard/foo&amp;bar/.  At most two programs allowed.&#34;},
            content_type=&#34;application/json&#34;,
        )

    # ── 2) Ensure each program name exists in PAGES ─────────────────────────
    for prog_name in parts:
        if prog_name not in PAGES:
            return HttpResponseBadRequest(
                {
                    &#34;error&#34;: f&#34;Unknown program &#39;{prog_name}&#39;. &#34;
                             f&#34;Valid programs are: {list(PAGES.keys())}&#34;
                },
                content_type=&#34;application/json&#34;,
            )

    # ── Helper for deciding base hour per program ───────────────────────────
    def get_base_hour_for(program: str) -&gt; int:
        return 7 if program in (&#34;8670&#34;, &#34;plant3&#34;, &#34;trilobe&#34;, &#34;Area2&#34;) else 6

    # ── Compute “now” once, in EST ───────────────────────────────────────────
    tz_est  = pytz.timezone(&#34;America/New_York&#34;)
    now_est = timezone.now().astimezone(tz_est)

    all_programs: List[Dict] = []

    # ── Loop over each (one or two) requested program ────────────────────────
    for prog_name in parts:
        # 3) Compute base‐hour in EST for this program
        base_hr = get_base_hour_for(prog_name)
        base_est = tz_est.localize(
            datetime(now_est.year, now_est.month, now_est.day, base_hr, 0, 0)
        )
        if now_est &lt; base_est:
            base_est -= timedelta(days=1)

        # Define the three shift boundaries in EST
        day_start  = base_est
        aft_start  = base_est + timedelta(hours=8)
        nite_start = base_est + timedelta(hours=16)

        if day_start &lt;= now_est &lt; aft_start:
            current_shift = &#34;day&#34;
            shift_start   = day_start
        elif aft_start &lt;= now_est &lt; nite_start:
            current_shift = &#34;afternoon&#34;
            shift_start   = aft_start
        else:
            current_shift = &#34;night&#34;
            shift_start   = nite_start

        shift_start_epoch = int(shift_start.astimezone(pytz.UTC).timestamp())
        shift_end_epoch   = int(timezone.now().timestamp())
        shift_length      = shift_end_epoch - shift_start_epoch

        # “Last 5 minutes” cutoff
        last5_start_epoch = shift_end_epoch - 300

        # 4) Deep‐copy this program’s config so we can annotate in place
        programs_copy = copy.deepcopy(PAGES[prog_name][&#34;programs&#34;])
        machine_set: Set[str] = set()
        # machine_occ maps (machine_id, frozenset_of_parts) → list of cell‐dicts
        machine_occ: Dict[Tuple[str, Optional[FrozenSet[str]]], List[Dict]] = {}

        # Build initial machine_set &amp; machine_occ from PAGES
        for prog_obj in programs_copy:
            for line in prog_obj[&#34;lines&#34;]:
                for op in line[&#34;operations&#34;]:
                    for m in op[&#34;machines&#34;]:
                        mid = m[&#34;number&#34;]
                        machine_set.add(mid)
                        if &#34;parts&#34; in m:
                            pk = frozenset(m[&#34;parts&#34;])
                        else:
                            pk = None
                        machine_occ.setdefault((mid, pk), []).append(m)

        # ── 5) Handle aliases: remove alias keys, add their source machines ────
        # alias_occ will hold the original cell‐dict lists (for later annotation)
        alias_occ: Dict[Tuple[str, Optional[FrozenSet[str]]], List[Dict]] = {}

        for alias_mid, sources in ALIASES.items():
            # For each parts_key under which this alias appears:
            for (mid_key, pk_key) in list(machine_occ.keys()):
                if mid_key == alias_mid:
                    # extract that cell list
                    alias_occ[(mid_key, pk_key)] = machine_occ.pop((mid_key, pk_key))
            # If alias was in machine_set, remove it
            if alias_mid in machine_set:
                machine_set.remove(alias_mid)
            # Add all sources into machine_set so we compute their metrics
            for src in sources:
                machine_set.add(src)

        # ── 6) Query total pieces since shift start ────────────────────────────
        placeholders = &#34;,&#34;.join([&#34;%s&#34;] * len(machine_set))
        params       = list(machine_set) + [shift_start_epoch]
        sql = f&#34;&#34;&#34;
            SELECT Machine, Part, SUM(`Count`) AS cnt
            FROM   GFxPRoduction
            WHERE  Machine IN ({placeholders})
              AND  TimeStamp &gt;= %s
            GROUP  BY Machine, Part
        &#34;&#34;&#34;
        cur = connections[&#34;prodrpt-md&#34;].cursor()
        cur.execute(sql, params)
        counts_by_mp: Dict[Tuple[str, str], int] = {
            (str(m), p): int(c) for m, p, c in cur.fetchall()
        }

        totals_by_machine: Dict[str, int] = defaultdict(int)
        for (m, _p), c in counts_by_mp.items():
            totals_by_machine[m] += c

        # ── 7) Query total pieces in last 5 minutes ───────────────────────────
        params5 = list(machine_set) + [last5_start_epoch]
        sql5 = f&#34;&#34;&#34;
            SELECT Machine, Part, SUM(`Count`) AS cnt
            FROM   GFxPRoduction
            WHERE  Machine IN ({placeholders})
              AND  TimeStamp &gt;= %s
            GROUP  BY Machine, Part
        &#34;&#34;&#34;
        cur.execute(sql5, params5)
        counts5_by_mp: Dict[Tuple[str, str], int] = {
            (str(m), p): int(c) for m, p, c in cur.fetchall()
        }

        totals5_by_machine: Dict[str, int] = defaultdict(int)
        for (m, _p), c in counts5_by_mp.items():
            totals5_by_machine[m] += c

        # ── 8) Compute part_runs for entire shift &amp; last 5 minutes ─────────────
        part_runs: Dict[str, List[Dict]]      = {}
        part_runs_5min: Dict[str, List[Dict]] = {}
        for mid in machine_set:
            runs  = compute_part_durations_for_machine(mid, shift_start_epoch, shift_end_epoch)
            runs5 = compute_part_durations_for_machine(mid, last5_start_epoch, shift_end_epoch)
            part_runs[mid]      = runs
            part_runs_5min[mid] = runs5

        # ── 9) Annotate each REAL “machine‐cell” with shift‐wide &amp; 5min metrics ─
        for (mid, parts_key), cells in list(machine_occ.items()):
            # If this key was one of the alias keys, we removed it above, so skip
            if mid in ALIASES:
                continue

            # (a) shift‐wide pieces made for this machine &amp; part‐group
            if parts_key is None:
                pieces_made = totals_by_machine.get(mid, 0)
            else:
                pieces_made = sum(
                    counts_by_mp.get((mid, p), 0) for p in parts_key
                )

            # (b) last 5min pieces for this machine &amp; part‐group
            if parts_key is None:
                pieces5_made = totals5_by_machine.get(mid, 0)
            else:
                pieces5_made = sum(
                    counts5_by_mp.get((mid, p), 0) for p in parts_key
                )

            # (c) cycle times &amp; “smart targets”
            if parts_key is None:
                # No explicit part grouping → use single cycle time
                ct_single = get_cycle_time_seconds(mid)  # part=None internally
                cycle_by_part: Dict[str, Optional[float]] = {}
                if ct_single is not None:
                    for run in part_runs[mid]:
                        cycle_by_part[run[&#34;part&#34;]] = ct_single
                rep_ct = ct_single

                if ct_single:
                    # shift‐long “smart target” = floor(sum(run_duration/ct_single))
                    smart_pcs = sum(run[&#34;duration&#34;] / ct_single for run in part_runs[mid])
                    smart_target = int(math.floor(smart_pcs)) if smart_pcs &gt; 0 else None
                    # 5min “smart target”
                    smart5_pcs = sum(
                        run5[&#34;duration&#34;] / ct_single for run5 in part_runs_5min[mid]
                    )
                    smart_target_5min = int(math.floor(smart5_pcs)) if smart5_pcs &gt; 0 else None
                else:
                    smart_target = None
                    smart_target_5min = None

            else:
                # Mixed‐part grouping → call cycle_time per part, take first non‐None
                cycle_by_part = {p: get_cycle_time_seconds(mid, p) for p in parts_key}
                rep_ct = next((v for v in cycle_by_part.values() if v is not None), None)
                if rep_ct:
                    smart_target      = int(math.floor(shift_length / rep_ct))
                    smart_target_5min = int(math.floor(300 / rep_ct))
                else:
                    smart_target = None
                    smart_target_5min = None

            # (d) annotate each cell in this group (for this real machine)
            for cell in cells:
                cell[&#34;count&#34;]            = pieces_made
                cell[&#34;pieces5_made&#34;]     = pieces5_made
                cell[&#34;cycle_time&#34;]       = rep_ct
                cell[&#34;cycle_by_part&#34;]    = cycle_by_part
                cell[&#34;smart_target&#34;]     = smart_target or 0
                cell[&#34;smart_target_5min&#34;]= smart_target_5min or 0

                # compute cell‐level efficiency for shift‐long
                if pieces_made &lt;= 0 or not smart_target:
                    cell[&#34;efficiency&#34;] = None
                    cell[&#34;color&#34;]      = &#34;#cccccc&#34;
                else:
                    eff_pct = int((pieces_made / smart_target) * 100)
                    eff_pct = max(0, min(eff_pct, 100))
                    cell[&#34;efficiency&#34;] = eff_pct

                    # compute 5‐min efficiency for this machine
                    if pieces5_made &lt;= 0 or not smart_target_5min:
                        eff_5min = 0 if pieces5_made == 0 else None
                    else:
                        eff_5min = int((pieces5_made / smart_target_5min) * 100)
                        eff_5min = max(0, min(eff_5min, 100))

                    # color according to 5‐min eff if available
                    cell[&#34;color&#34;] = (
                        efficiency_color(eff_5min) if eff_5min is not None else &#34;#cccccc&#34;
                    )

        # ── 10) Build “alias” cells by summing their source machines ────────────
        # At this point, machine_occ no longer contains alias entries; alias_occ
        # holds the original cell‐dict lists from PAGES. We will compute each
        # alias’s metrics from its sources (which we included in machine_set).
        for (alias_mid, parts_key), cells in alias_occ.items():
            sources = ALIASES.get(alias_mid, [])
            # (a) Sum shift‐long pieces_made across sources
            pieces_made_alias = sum(totals_by_machine.get(src, 0) for src in sources)
            # (b) Sum 5min pieces across sources
            pieces5_made_alias = sum(totals5_by_machine.get(src, 0) for src in sources)

            # (c) Compute alias’s “smart” targets by summing each source’s smart_pcs
            alias_smart_pcs     = 0.0
            alias_smart_pcs_5   = 0.0
            for src in sources:
                ct_src = get_cycle_time_seconds(src)
                if ct_src:
                    # sum fractional “parts” from durations
                    alias_smart_pcs   += sum(run[&#34;duration&#34;] / ct_src for run in part_runs[src])
                    alias_smart_pcs_5 += sum(run5[&#34;duration&#34;] / ct_src for run5 in part_runs_5min[src])
            smart_target_alias      = (
                int(math.floor(alias_smart_pcs)) if alias_smart_pcs &gt; 0 else None
            )
            smart_target_5min_alias = (
                int(math.floor(alias_smart_pcs_5)) if alias_smart_pcs_5 &gt; 0 else None
            )

            # (d) Determine alias’s shift‐long efficiency and 5min efficiency
            if smart_target_alias and smart_target_alias &gt; 0:
                eff_alias = int((pieces_made_alias / smart_target_alias) * 100)
                eff_alias = max(0, min(eff_alias, 100))
            else:
                eff_alias = None

            if smart_target_5min_alias and smart_target_5min_alias &gt; 0:
                eff5_alias = int((pieces5_made_alias / smart_target_5min_alias) * 100)
                eff5_alias = max(0, min(eff5_alias, 100))
            else:
                eff5_alias = None

            # (e) Color the alias by its 5min efficiency (or gray if none)
            alias_color = (
                efficiency_color(eff5_alias) if eff5_alias is not None else &#34;#808080&#34;
            )

            # (f) Annotate each original “m” dict (from PAGES) in place
            for cell in cells:
                cell[&#34;number&#34;]            = alias_mid
                cell[&#34;count&#34;]             = pieces_made_alias
                cell[&#34;pieces5_made&#34;]      = pieces5_made_alias
                cell[&#34;cycle_time&#34;]        = None
                cell[&#34;cycle_by_part&#34;]     = {}
                cell[&#34;smart_target&#34;]      = smart_target_alias or 0
                cell[&#34;smart_target_5min&#34;] = smart_target_5min_alias or 0
                cell[&#34;efficiency&#34;]        = eff_alias
                cell[&#34;color&#34;]             = alias_color

            # (g) Re‐insert alias entry into machine_occ so that downstream logic runs
            machine_occ[(alias_mid, parts_key)] = cells

        # ── 11) “Padding” each line exactly as before ─────────────────────────
        for prog_obj in programs_copy:
            for line in prog_obj[&#34;lines&#34;]:
                max_m = max((len(op[&#34;machines&#34;]) for op in line[&#34;operations&#34;]), default=1)
                line[&#34;max_machines&#34;] = max_m
                for op in line[&#34;operations&#34;]:
                    op[&#34;pad&#34;] = [None] * (max_m - len(op[&#34;machines&#34;]))

        # ── 12) Filter part_runs for parts declared in config (no change) ─────
        filtered_part_runs: Dict[str, List[Dict]] = {}
        for mid, runs in part_runs.items():
            declared_parts = {
                p
                for (m, pk) in machine_occ
                if m == mid and pk is not None
                for p in pk
            }
            if declared_parts:
                runs = [r for r in runs if r[&#34;part&#34;] in declared_parts]
            filtered_part_runs[mid] = runs

        # ── 13) Compute total_produced &amp; efficiency at the OP level,
        #          excluding any machine where smart_target &lt;= 0,
        #          then compute 5-minute op-level efficiency and set op[&#34;color&#34;]. ─
        for prog_obj in programs_copy:
            for line in prog_obj[&#34;lines&#34;]:
                for op in line[&#34;operations&#34;]:
                    # consider only machines whose shift-long smart_target &gt; 0
                    valid_machines = [m for m in op[&#34;machines&#34;] if m.get(&#34;smart_target&#34;, 0) &gt; 0]

                    # (a) shift‐long op totals
                    total_produced = sum(m[&#34;count&#34;] for m in valid_machines)
                    total_smart    = sum(m[&#34;smart_target&#34;] for m in valid_machines)

                    if total_smart &gt; 0:
                        op_eff = int(math.floor((total_produced / total_smart) * 100))
                        op_eff = max(0, min(op_eff, 100))
                    else:
                        op_eff = None

                    op[&#34;total_produced&#34;]     = total_produced
                    op[&#34;total_smart_target&#34;] = total_smart
                    op[&#34;efficiency&#34;]         = op_eff

                    # (a) shift‐long op totals
                    total_produced = sum(m[&#34;count&#34;] for m in valid_machines)
                    total_smart    = sum(m[&#34;smart_target&#34;] for m in valid_machines)
                    if total_smart &gt; 0:
                        op_eff = int(math.floor((total_produced / total_smart) * 100))
                        op_eff = max(0, min(op_eff, 100))
                    else:
                        op_eff = None

                    op[&#34;total_produced&#34;]     = total_produced
                    op[&#34;total_smart_target&#34;] = total_smart
                    op[&#34;efficiency&#34;]         = op_eff

                    # (b) last‐5‐minute op totals
                    total5_produced = sum(m[&#34;pieces5_made&#34;] for m in valid_machines)
                    total5_smart    = sum(m[&#34;smart_target_5min&#34;] for m in valid_machines)
                    if total5_smart &gt; 0:
                        op_eff_5min = int(math.floor((total5_produced / total5_smart) * 100))
                        op_eff_5min = max(0, min(op_eff_5min, 100))
                    else:
                        op_eff_5min = None

                    op[&#34;recent_efficiency&#34;] = op_eff_5min

                    # (c) color the op cell by its shift‐to‐date efficiency (or gray if none)
                    op[&#34;color&#34;] = (
                        efficiency_color(op_eff) if op_eff is not None else &#34;#808080&#34;
                    )

        # ── 14) Merge each prog_obj into all_programs ─────────────────────────
        for prog_obj in programs_copy:
            all_programs.append(prog_obj)

    # ── 15) Render the template with updated efficiency &amp; coloring logic ─────
    context = {
        &#34;pages&#34;:    pages,
        &#34;programs&#34;: all_programs,
    }
    return render(request, &#34;dashboards/dashboard_renewed.html&#34;, context)</code></pre>
</details>
<div class="desc"><p>Render a live‐updating shift dashboard for one or two programs with efficiency coloring.</p>
<p>Splits the <code>pages</code> argument on “&amp;” to allow one or two program names (e.g. “programA” or
“programA&amp;programB”), validates against the <code>PAGES</code> configuration, and returns a
400‐BadRequest if the format is invalid or if any program is unknown.</p>
<p>For each requested program, this view:
1. Determines the 8-hour shift boundaries in Eastern Time (day/afternoon/night)
based on a program-specific base hour.
2. Converts those boundaries to UTC timestamps for database queries.
3. Builds a set of machines (including expanded sources for any aliases) and
captures their part groupings.
4. Runs two SQL aggregations against <code>GFxPRoduction</code> to get per-machine, per-part
counts for the full shift and the last 5 minutes.
5. Calls <code><a title="dashboards.views.compute_part_durations_for_machine" href="#dashboards.views.compute_part_durations_for_machine">compute_part_durations_for_machine()</a></code> to fetch part run durations over both intervals.
6. Annotates each “cell” in the program template with:
- Cumulative and recent piece counts
- Cycle time(s) and “smart” targets
- Shift-long and 5-min efficiencies
- A color code based on recent efficiency
7. Constructs alias cells by summing metrics across their source machines, applying
the same efficiency and coloring logic.
8. Pads each operation line to a uniform width, filters part runs to declared parts,
then computes per-operation totals and efficiencies (excluding machines with no target),
adding a “recent_efficiency” and “color” for each operation.
9. Collects all program objects into <code>all_programs</code>, then renders
<code>dashboards/dashboard_renewed.html</code> with context:
<code>python
{
"pages": pages,
"programs": all_programs
}</code></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>HttpRequest</code></dt>
<dd>The incoming request, containing session and timezone context.</dd>
<dt><strong><code>pages</code></strong> :&ensp;<code>str</code></dt>
<dd>A single program name or two names joined by "&amp;" indicating which
program dashboards to render.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>HttpResponse</code></dt>
<dd>Renders the renewed dashboard template with JSON-ready program data,
or returns HttpResponseBadRequest for invalid input.</dd>
</dl></div>
</dd>
<dt id="dashboards.views.dashboard_index_view"><code class="name flex">
<span>def <span class="ident">dashboard_index_view</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dashboard_index_view(request):
    context = {}
    context[&#34;main_heading&#34;] = &#34;Dashboard Index&#34;
    context[&#34;title&#34;] = &#34;Dashboard Index - pmdsdata12&#34;
    return render(request, f&#39;dashboards/index_dashboard.html&#39;, context)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="dashboards.views.display_shift_points"><code class="name flex">
<span>def <span class="ident">display_shift_points</span></span>(<span>request, tv_number)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def display_shift_points(request, tv_number):
    &#34;&#34;&#34;Render the list of shift points for a specific TV number.

    Retrieves the `ShiftPoint` instance matching the provided `tv_number`, extracts its
    `points` list, and renders the `display_shift_points.html` template with both the
    model instance and the list of points.

    Args:
        request (HttpRequest): The incoming HTTP request.
        tv_number (int): The TV number identifying which `ShiftPoint` to display.

    Returns:
        HttpResponse: Renders `dashboards/display_shift_points.html` with context:
            - `shift_point`: the `ShiftPoint` instance
            - `shift_points`: list of strings representing the shift points
    &#34;&#34;&#34;
    shift_point = get_object_or_404(ShiftPoint, tv_number=tv_number)
    shift_points = shift_point.points
    return render(request, &#39;dashboards/display_shift_points.html&#39;, {&#39;shift_point&#39;: shift_point, &#39;shift_points&#39;: shift_points})</code></pre>
</details>
<div class="desc"><p>Render the list of shift points for a specific TV number.</p>
<p>Retrieves the <code>ShiftPoint</code> instance matching the provided <code>tv_number</code>, extracts its
<code>points</code> list, and renders the <code>display_shift_points.html</code> template with both the
model instance and the list of points.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>HttpRequest</code></dt>
<dd>The incoming HTTP request.</dd>
<dt><strong><code>tv_number</code></strong> :&ensp;<code>int</code></dt>
<dd>The TV number identifying which <code>ShiftPoint</code> to display.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>HttpResponse</code></dt>
<dd>Renders <code>dashboards/display_shift_points.html</code> with context:
- <code>shift_point</code>: the <code>ShiftPoint</code> instance
- <code>shift_points</code>: list of strings representing the shift points</dd>
</dl></div>
</dd>
<dt id="dashboards.views.efficiency_color"><code class="name flex">
<span>def <span class="ident">efficiency_color</span></span>(<span>eff: int) ‑> str</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def efficiency_color(eff: int) -&gt; str:
    &#34;&#34;&#34;
    Given an efficiency percentage (0–100), return a hex color:
      •  0% → pure red   (#ff0000)
      • 50% → yellow     (#ffff00)
      •100% → forest‐green (#228b22)

    Below  0 or above 100 will be clamped.
    &#34;&#34;&#34;
    # Clamp onto [0,100]
    if eff &lt; 0:
        eff = 0
    elif eff &gt; 100:
        eff = 100

    if eff &lt;= 50:
        # Fade from red → yellow: keep R=255, increase G from 0→255
        r = 255
        g = int((eff / 50) * 255)
        b = 0
    else:
        # Fade from yellow → forest‐green
        #   At eff=50: (255,255,0)
        #   At eff=100: ( 34,139,34)  ← “forest green”
        proportion = (eff - 50) / 50.0
        # Linearly interpolate each channel:
        start_r, start_g, start_b = 255, 255, 0
        target_r, target_g, target_b = 34, 139, 34
        r = int(start_r + (target_r - start_r) * proportion)
        g = int(start_g + (target_g - start_g) * proportion)
        b = int(start_b + (target_b - start_b) * proportion)

    return f&#34;#{r:02x}{g:02x}{b:02x}&#34;</code></pre>
</details>
<div class="desc"><p>Given an efficiency percentage (0–100), return a hex color:
•
0% → pure red
(#ff0000)
• 50% → yellow
(#ffff00)
•100% → forest‐green (#228b22)</p>
<p>Below
0 or above 100 will be clamped.</p></div>
</dd>
<dt id="dashboards.views.fetch_pie_chart_data"><code class="name flex">
<span>def <span class="ident">fetch_pie_chart_data</span></span>(<span>machine)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_pie_chart_data(machine):
    &#34;&#34;&#34;Retrieve 24-hour production and reject counts with percentage breakdown and color coding.

    Connects to the GFxPRoduction table to count “good” and “reject” entries for the given
    machine (and its “REJ” suffix) over the last 24 hours. Computes the overall total,
    the percentage share of each category, and chooses a Bootstrap text color class
    based on the reject rate.

    Args:
        machine (str): Identifier of the machine whose production to analyze.

    Returns:
        dict: {
            &#34;total&#34; (int): Sum of good + reject counts,
            &#34;grades&#34; (dict[str, int]): {&#34;Good&#34;: good_count, &#34;Reject&#34;: reject_count},
            &#34;percentages&#34; (dict[str, float]): {&#34;Good&#34;: good_pct, &#34;Reject&#34;: reject_pct},
            &#34;failures_total&#34; (int): Same as reject_count,
            &#34;reject_color&#34; (str): Bootstrap text class based on reject_pct
                (&#34;text-success&#34; if &lt;2.5%, &#34;text-warning&#34; if &lt;5%, else &#34;text-danger&#34;)
        }
    &#34;&#34;&#34;
    now = datetime.now()
    cutoff = now.timestamp() - 24 * 3600
    conn = get_db_connection()

    with conn.cursor() as cursor:
        cursor.execute(
            &#34;SELECT COUNT(*) FROM GFxPRoduction &#34;
            &#34;WHERE Machine = %s AND TimeStamp &gt;= %s&#34;,
            [machine, cutoff]
        )
        good = cursor.fetchone()[0]

        cursor.execute(
            &#34;SELECT COUNT(*) FROM GFxPRoduction &#34;
            &#34;WHERE Machine = %s AND TimeStamp &gt;= %s&#34;,
            [f&#34;{machine}REJ&#34;, cutoff]
        )
        rejects = cursor.fetchone()[0]

    total = good + rejects
    # avoid divide‐by‐zero
    pct_good   = round((good   / total * 100), 2) if total else 0.0
    pct_reject = round((rejects/ total * 100), 2) if total else 0.0


    # ←— NEW: pick the right bootstrap class by percentage
    if pct_reject &lt; 2.5:
        reject_color = &#34;text-success&#34;
    elif pct_reject &lt; 5.0:
        reject_color = &#34;text-warning&#34;
    else:
        reject_color = &#34;text-danger&#34;

    return {
        &#34;total&#34;: total,
        &#34;grades&#34;: {
            &#34;Good&#34;: good,
            &#34;Reject&#34;: rejects,
        },
        &#34;percentages&#34;: {
            &#34;Good&#34;: pct_good,
            &#34;Reject&#34;: pct_reject,
        },
        &#34;failures_total&#34;: rejects,
        # ←— NEW FIELD your frontend will just apply
        &#34;reject_color&#34;: reject_color,
    }</code></pre>
</details>
<div class="desc"><p>Retrieve 24-hour production and reject counts with percentage breakdown and color coding.</p>
<p>Connects to the GFxPRoduction table to count “good” and “reject” entries for the given
machine (and its “REJ” suffix) over the last 24 hours. Computes the overall total,
the percentage share of each category, and chooses a Bootstrap text color class
based on the reject rate.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>Identifier of the machine whose production to analyze.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>{
"total" (int): Sum of good + reject counts,
"grades" (dict[str, int]): {"Good": good_count, "Reject": reject_count},
"percentages" (dict[str, float]): {"Good": good_pct, "Reject": reject_pct},
"failures_total" (int): Same as reject_count,
"reject_color" (str): Bootstrap text class based on reject_pct
("text-success" if &lt;2.5%, "text-warning" if &lt;5%, else "text-danger")</dd>
</dl>
<p>}</p></div>
</dd>
<dt id="dashboards.views.fetch_weekly_data_for_machine"><code class="name flex">
<span>def <span class="ident">fetch_weekly_data_for_machine</span></span>(<span>machine)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_weekly_data_for_machine(machine):
    &#34;&#34;&#34;Retrieve 7-day production and reject statistics for a machine in 8-hour intervals.

    This function:
      1. Defines the start of the 7-day window (midnight 7 days ago).
      2. Iterates over each day and 8-hour block (00:00–08:00, 08:00–16:00, 16:00–24:00),
         skipping any blocks that start in the future.
      3. For each block, queries the GFxPRoduction table for both the machine’s “good”
         records and its rejects (machine identifier suffixed with &#34;REJ&#34;).
      4. Builds a `breakdown` list of dictionaries containing:
         - `&#34;interval_start&#34;`: formatted block start time
         - `&#34;interval_end&#34;`: formatted block end time
         - `&#34;total_count&#34;`: sum of good + rejects
         - `&#34;grade_counts&#34;`: nested dict with `&#34;Good&#34;` and `&#34;Reject&#34;` each as
            `&#34;count (percentage%)&#34;`
      5. Rolls up totals across all blocks to compute:
         - `total_count_last_7_days`
         - `grade_counts_last_7_days` with formatted `&#34;count (percentage%)&#34;` per category

    Args:
        machine (str): Identifier of the machine to analyze.

    Returns:
        dict: {
            &#34;asset&#34;: machine,
            &#34;total_count_last_7_days&#34;: int,
            &#34;grade_counts_last_7_days&#34;: {
                &#34;Good&#34;: &#34;count (pct%)&#34;,
                &#34;Reject&#34;: &#34;count (pct%)&#34;
            },
            &#34;breakdown_data&#34;: list of {
                &#34;interval_start&#34;: str,
                &#34;interval_end&#34;: str,
                &#34;total_count&#34;: int,
                &#34;grade_counts&#34;: {&#34;Good&#34;: str, &#34;Reject&#34;: str}
            }
        }
    &#34;&#34;&#34;
    now = datetime.now()
    start_dt = (now - timedelta(days=7)).replace(
        hour=0, minute=0, second=0, microsecond=0
    )
    interval_hours = [0, 8, 16]
    breakdown = []
    conn = get_db_connection()

    with conn.cursor() as cursor:
        for day in range(8):  # 7 days + today
            day_base = start_dt + timedelta(days=day)
            for h in interval_hours:
                block_start = day_base + timedelta(hours=h)
                block_end   = block_start + timedelta(hours=8)
                if block_start &gt;= now:
                    continue

                s_ts = block_start.timestamp()
                e_ts = block_end.timestamp()

                # good
                cursor.execute(
                    &#34;SELECT COUNT(*) FROM GFxPRoduction &#34;
                    &#34;WHERE Machine = %s AND TimeStamp &gt;= %s AND TimeStamp &lt; %s&#34;,
                    [machine, s_ts, e_ts]
                )
                good_cnt = cursor.fetchone()[0]

                # reject
                cursor.execute(
                    &#34;SELECT COUNT(*) FROM GFxPRoduction &#34;
                    &#34;WHERE Machine = %s AND TimeStamp &gt;= %s AND TimeStamp &lt; %s&#34;,
                    [f&#34;{machine}REJ&#34;, s_ts, e_ts]
                )
                rej_cnt = cursor.fetchone()[0]

                total = good_cnt + rej_cnt
                if total == 0:
                    continue

                breakdown.append({
                    &#34;interval_start&#34;: block_start.strftime(&#34;%b-%d %H:%M&#34;),
                    &#34;interval_end&#34;:   block_end.strftime(&#34;%b-%d %H:%M&#34;),
                    &#34;total_count&#34;:    total,
                    &#34;grade_counts&#34;: {
                        &#34;Good&#34;:  f&#34;{good_cnt} ({round(good_cnt/total*100,2)}%)&#34;,
                        &#34;Reject&#34;: f&#34;{rej_cnt} ({round(rej_cnt/total*100,2)}%)&#34;,
                    }
                })

    # roll-up for the 7-day totals
    total_count = sum(item[&#34;total_count&#34;] for item in breakdown)
    total_good   = sum(int(item[&#34;grade_counts&#34;][&#34;Good&#34;].split()[0]) for item in breakdown)
    total_rej    = sum(int(item[&#34;grade_counts&#34;][&#34;Reject&#34;].split()[0]) for item in breakdown)

    pct_good = round((total_good   / total_count * 100), 2) if total_count else 0
    pct_rej  = round((total_rej    / total_count * 100), 2) if total_count else 0

    return {
        &#34;asset&#34;: machine,
        &#34;total_count_last_7_days&#34;: total_count,
        &#34;grade_counts_last_7_days&#34;: {
            &#34;Good&#34;:  f&#34;{total_good} ({pct_good}%)&#34;,
            &#34;Reject&#34;: f&#34;{total_rej} ({pct_rej}%)&#34;,
        },
        &#34;breakdown_data&#34;: breakdown,
    }</code></pre>
</details>
<div class="desc"><p>Retrieve 7-day production and reject statistics for a machine in 8-hour intervals.</p>
<p>This function:
1. Defines the start of the 7-day window (midnight 7 days ago).
2. Iterates over each day and 8-hour block (00:00–08:00, 08:00–16:00, 16:00–24:00),
skipping any blocks that start in the future.
3. For each block, queries the GFxPRoduction table for both the machine’s “good”
records and its rejects (machine identifier suffixed with "REJ").
4. Builds a <code>breakdown</code> list of dictionaries containing:
- <code>"interval_start"</code>: formatted block start time
- <code>"interval_end"</code>: formatted block end time
- <code>"total_count"</code>: sum of good + rejects
- <code>"grade_counts"</code>: nested dict with <code>"Good"</code> and <code>"Reject"</code> each as
<code>"count (percentage%)"</code>
5. Rolls up totals across all blocks to compute:
- <code>total_count_last_7_days</code>
- <code>grade_counts_last_7_days</code> with formatted <code>"count (percentage%)"</code> per category</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>Identifier of the machine to analyze.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>{
"asset": machine,
"total_count_last_7_days": int,
"grade_counts_last_7_days": {
"Good": "count (pct%)",
"Reject": "count (pct%)"
},
"breakdown_data": list of {
"interval_start": str,
"interval_end": str,
"total_count": int,
"grade_counts": {"Good": str, "Reject": str}
}</dd>
</dl>
<p>}</p></div>
</dd>
<dt id="dashboards.views.get_cycle_time_seconds"><code class="name flex">
<span>def <span class="ident">get_cycle_time_seconds</span></span>(<span>machine_id: str,<br>part: str | List[str] | None = None,<br>as_of_epoch: int | None = None) ‑> float | None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cycle_time_seconds(
    machine_id: str,
    part: Optional[Union[str, List[str]]] = None,
    as_of_epoch: Optional[int] = None,
) -&gt; Optional[float]:
    &#34;&#34;&#34;Retrieve the cycle time (seconds per part) for a machine, optionally across multiple parts.

    If `part` is a list of part numbers, this function calls itself for each part and
    returns the maximum cycle time among them. Otherwise, it queries the
    `OAMachineTargets` model for the most recent target (by `effective_date_unix`)
    where `machine_id` matches and `effective_date_unix` is on or before `as_of_epoch`.

    For single-part lookups:
      - If `part` is provided, filters targets by that part.
      - If `part` is `None` or omitted, filters for entries where `part__isnull=True`.
      - Returns `None` if no valid target row is found or if `row.target &lt;= 0`.
      - Otherwise computes `seconds = _SECONDS_PER_WEEK_7200 / row.target`.

    Debug prints can be enabled by uncommenting the `print` calls; e.g., for
    `machine_id == &#34;1703L&#34;`.

    Args:
        machine_id (str): Identifier of the machine to look up in `OAMachineTargets`.
        part (str | list[str], optional): A single part number or a list of parts.
            If a list, the max cycle time across those parts is returned.
        as_of_epoch (int, optional): Unix timestamp cutoff; only targets with
            `effective_date_unix &lt;= as_of_epoch` are considered. Defaults to now.

    Returns:
        float | None: The cycle time in seconds (seconds per part), or `None` if
        no valid target is found.
    &#34;&#34;&#34;
    &#34;&#34;&#34;
    If `part` is a list of strings, return the *max* cycle time among those parts.
    Otherwise, behave exactly as before. Adds debug prints when machine_id == &#34;1703L&#34;.
    &#34;&#34;&#34;
    if as_of_epoch is None:
        as_of_epoch = int(timezone.now().timestamp())

    # If part is a list, compute each individually and take max
    if isinstance(part, list):

        cts = []
        for p in part:
            single_ct = get_cycle_time_seconds(machine_id, p, as_of_epoch)
            if single_ct is not None:
                cts.append(single_ct)

        if not cts:
            # print(f&#34;NA: {machine_id} /{&#39;,&#39;.join(part)}&#34;)
            return None

        chosen = max(cts)
        return chosen

    # Single-part (or no-part) logic
    qs = (
        OAMachineTargets.objects
        .filter(machine_id=machine_id, isDeleted=False, effective_date_unix__lte=as_of_epoch)
    )
    if part:
        qs = qs.filter(part=part)
    else:
        qs = qs.filter(part__isnull=True)


    row = qs.order_by(&#34;-effective_date_unix&#34;).first()
    tag = f&#34;{machine_id}{&#39; /&#39; + part if part else &#39;&#39;}&#34;


    if not row or not row.target or row.target &lt;= 0:
        # print(f&#34;NA: {tag}&#34;)
        return None

    seconds = _SECONDS_PER_WEEK_7200 / row.target


    return seconds</code></pre>
</details>
<div class="desc"><p>Retrieve the cycle time (seconds per part) for a machine, optionally across multiple parts.</p>
<p>If <code>part</code> is a list of part numbers, this function calls itself for each part and
returns the maximum cycle time among them. Otherwise, it queries the
<code>OAMachineTargets</code> model for the most recent target (by <code>effective_date_unix</code>)
where <code>machine_id</code> matches and <code>effective_date_unix</code> is on or before <code>as_of_epoch</code>.</p>
<p>For single-part lookups:
- If <code>part</code> is provided, filters targets by that part.
- If <code>part</code> is <code>None</code> or omitted, filters for entries where <code>part__isnull=True</code>.
- Returns <code>None</code> if no valid target row is found or if <code>row.target &lt;= 0</code>.
- Otherwise computes <code>seconds = _SECONDS_PER_WEEK_7200 / row.target</code>.</p>
<p>Debug prints can be enabled by uncommenting the <code>print</code> calls; e.g., for
<code>machine_id == "1703L"</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>machine_id</code></strong> :&ensp;<code>str</code></dt>
<dd>Identifier of the machine to look up in <code>OAMachineTargets</code>.</dd>
<dt><strong><code>part</code></strong> :&ensp;<code>str | list[str]</code>, optional</dt>
<dd>A single part number or a list of parts.
If a list, the max cycle time across those parts is returned.</dd>
<dt><strong><code>as_of_epoch</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Unix timestamp cutoff; only targets with
<code>effective_date_unix &lt;= as_of_epoch</code> are considered. Defaults to now.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float | None</code></dt>
<dd>The cycle time in seconds (seconds per part), or <code>None</code> if</dd>
</dl>
<p>no valid target is found.</p></div>
</dd>
<dt id="dashboards.views.get_db_connection"><code class="name flex">
<span>def <span class="ident">get_db_connection</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_db_connection():
    &#34;&#34;&#34;Establish and return a MySQL database connection using configured settings.

    Reads the hostname, username, password, and database name from Django settings
    (`NEW_HOST`, `DAVE_USER`, `DAVE_PASSWORD`, `DAVE_DB`) and opens a connection
    via MySQLdb.

    Returns:
        MySQLdb.connections.Connection: A new MySQL database connection.

    Raises:
        MySQLdb.Error: If the connection cannot be established.
    &#34;&#34;&#34;
    return MySQLdb.connect(
        host=settings.NEW_HOST,
        user=settings.DAVE_USER,
        passwd=settings.DAVE_PASSWORD,
        db=settings.DAVE_DB
    )</code></pre>
</details>
<div class="desc"><p>Establish and return a MySQL database connection using configured settings.</p>
<p>Reads the hostname, username, password, and database name from Django settings
(<code>NEW_HOST</code>, <code>DAVE_USER</code>, <code>DAVE_PASSWORD</code>, <code>DAVE_DB</code>) and opens a connection
via MySQLdb.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>MySQLdb.connections.Connection</code></dt>
<dd>A new MySQL database connection.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>MySQLdb.Error</code></dt>
<dd>If the connection cannot be established.</dd>
</dl></div>
</dd>
<dt id="dashboards.views.get_line_prod"><code class="name flex">
<span>def <span class="ident">get_line_prod</span></span>(<span>line_spec, line_target, parts, shift_start, shift_time)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_line_prod(line_spec, line_target, parts, shift_start, shift_time):
    &#34;&#34;&#34;Compute current and predicted production metrics for each machine and operation.

    Queries the GFxPRoduction table to get counts over two intervals:
      1. The last 5 minutes (for short‐term rate/color coding).
      2. Since the start of the shift (for cumulative and prediction).

    It then:
      - Calculates `prod_last_five` and `prod_now` per machine (applying any scale factor).
      - Estimates `predicted_production` for the 8-hour shift based on current rate.
      - Determines a `cell_colour` based on how the last‐five‐minute output compares to the per-machine target.
      - Aggregates predicted production by `operation`.

    Args:
        line_spec (list of tuple): Machine specifications. Each tuple is:
            (asset, sources, machine_rate, operation[, scale]) where:
            - asset (str): identifier on the dashboard,
            - sources (iterable): list of machine IDs in the DB,
            - machine_rate (int): number of machines contributing to the line’s target,
            - operation (int): index for grouping results,
            - scale (float, optional): multiplier for counts (default=1).
        line_target (int | float): Total production goal for the entire line over the shift.
        parts (str): SQL fragment for `AND Part IN (…)` or empty string for no filter.
        shift_start (int): Unix timestamp marking the start of the current shift.
        shift_time (int): Seconds elapsed since `shift_start`.

    Returns:
        tuple:
            machine_production (list of tuple): One tuple per machine:
                (asset, prod_now, cell_colour, predicted_production, operation, machine_rate)
            operation_production (list of int): Predicted production aggregated by operation index.
    &#34;&#34;&#34;
    cursor = connections[&#39;prodrpt-md&#39;].cursor()

    sql =  &#39;SELECT Machine, COUNT(*) &#39;
    sql += &#39;FROM GFxPRoduction &#39;
    sql += &#39;WHERE TimeStamp &gt;= %s &#39;
    if parts:
        sql += f&#39;AND Part IN ({parts}) &#39;
    sql += &#39;GROUP BY Machine;&#39;

    # Get production from last 5 mins for color coding
    five_mins_ago = shift_start + shift_time - 300
    cursor.execute(sql, [five_mins_ago])
    prod_last5 = cursor.fetchall()

    # Get production since start of shift for current and prediciton
    cursor.execute(sql, [shift_start])
    prod_shift = cursor.fetchall()

    machine_production = []
    operation_production = [0]*200

    for machine in line_spec:  # build the list of tupples for the template
        asset = machine[0]  # this is the asset number on the dashboard
        # change this to the asset you want to take the count from
        sources = machine[1]
        machine_rate = machine[2]
        operation = machine[3]
        scale = 1
        if len(machine) == 5:
            scale = machine[4]

        prod_last_five = 0
        prod_now = 0

        for source in sources:
            count_index = next(
                (i for i, v in enumerate(prod_last5) if v[0] == source), -1)
            if count_index &gt; -1:
                prod_last_five += prod_last5[count_index][1] * scale
            else:
                prod_last_five += 0

            count_index = next(
                (i for i, v in enumerate(prod_shift) if v[0] == source), -1)
            if count_index &gt; -1:
                prod_now += prod_shift[count_index][1] * scale
            else:
                prod_now += 0

        # Pediction
        try:
            shift_rate = prod_now / float(shift_time)
        except:
            shift_time = 100
            shift_rate = prod_now / float(shift_time)

        predicted_production = int(
            prod_now + (shift_rate * (28800 - shift_time)))

        # choose a color based on last 5 mins production vs machine rate
        # need 3200 in 8 hours.  Machine is one of X machines
        machine_target = line_target / machine_rate
        # need &#39;rate&#39; parts in 5 minutes to make 3200 across cell
        five_minute_target = (machine_target / 28800) * 300
        five_minute_percentage = int(prod_last_five / five_minute_target * 100)
        if five_minute_percentage &gt;= 100:
            cell_colour = &#39;#009700&#39;
        elif five_minute_percentage &gt;= 90:
            cell_colour = &#39;#4FC34F&#39;
        elif five_minute_percentage &gt;= 80:
            cell_colour = &#39;#A4F6A4&#39;
        elif five_minute_percentage &gt;= 70:
            cell_colour = &#39;#C3C300&#39;
        elif five_minute_percentage &gt;= 50:
            cell_colour = &#39;#DADA3F&#39;
        elif five_minute_percentage &gt;= 25:
            cell_colour = &#39;#F6F687&#39;  # light Yellow
        elif five_minute_percentage &gt;= 10:
            cell_colour = &#39;#F7BA84&#39;  # brown
        elif five_minute_percentage &gt; 0:
            cell_colour = &#39;#EC7371&#39;  # faded red
        else:
            if predicted_production == 0:
                cell_colour = &#39;#D5D5D5&#39;  # Grey
            else:
                cell_colour = &#39;#FF0400&#39;  # Red

        machine_production.append(
            (asset, prod_now, cell_colour,
             predicted_production, operation, machine_rate)
        )
        operation_production[operation] += predicted_production

    return machine_production, operation_production</code></pre>
</details>
<div class="desc"><p>Compute current and predicted production metrics for each machine and operation.</p>
<p>Queries the GFxPRoduction table to get counts over two intervals:
1. The last 5 minutes (for short‐term rate/color coding).
2. Since the start of the shift (for cumulative and prediction).</p>
<p>It then:
- Calculates <code>prod_last_five</code> and <code>prod_now</code> per machine (applying any scale factor).
- Estimates <code>predicted_production</code> for the 8-hour shift based on current rate.
- Determines a <code>cell_colour</code> based on how the last‐five‐minute output compares to the per-machine target.
- Aggregates predicted production by <code>operation</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>line_spec</code></strong> :&ensp;<code>list</code> of <code>tuple</code></dt>
<dd>Machine specifications. Each tuple is:
(asset, sources, machine_rate, operation[, scale]) where:
- asset (str): identifier on the dashboard,
- sources (iterable): list of machine IDs in the DB,
- machine_rate (int): number of machines contributing to the line’s target,
- operation (int): index for grouping results,
- scale (float, optional): multiplier for counts (default=1).</dd>
<dt><strong><code>line_target</code></strong> :&ensp;<code>int | float</code></dt>
<dd>Total production goal for the entire line over the shift.</dd>
<dt><strong><code>parts</code></strong> :&ensp;<code>str</code></dt>
<dd>SQL fragment for <code>AND Part IN (…)</code> or empty string for no filter.</dd>
<dt><strong><code>shift_start</code></strong> :&ensp;<code>int</code></dt>
<dd>Unix timestamp marking the start of the current shift.</dd>
<dt><strong><code>shift_time</code></strong> :&ensp;<code>int</code></dt>
<dd>Seconds elapsed since <code>shift_start</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>tuple:
machine_production (list of tuple): One tuple per machine:
(asset, prod_now, cell_colour, predicted_production, operation, machine_rate)
operation_production (list of int): Predicted production aggregated by operation index.</p></div>
</dd>
<dt id="dashboards.views.get_line_prod2"><code class="name flex">
<span>def <span class="ident">get_line_prod2</span></span>(<span>line_spec, line_target, parts, shift_start, shift_time)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_line_prod2(line_spec, line_target, parts, shift_start, shift_time):
    &#34;&#34;&#34;Compute detailed production metrics with color‐coding for machines and operations.

    Retrieves counts from the GFxPRoduction table for both:
      - The last 5 minutes (for real‐time color thresholds), and
      - Since the shift start (for cumulative and prediction).

    For each machine in `line_spec`, it calculates:
      1. `prod_last_five` and `prod_now` (applying an optional scale factor).
      2. A `predicted_production` value for the full 8‐hour shift based on current rate.
      3. A `cell_colour` based on how the last‐five‐minute output compares to the per‐machine target.

    Then aggregates predicted production by `operation` and applies color thresholds
    at the operation level to produce an “expanded OP” structure.

    Args:
        line_spec (list of tuple):
            Each tuple defines a machine:
               (asset, source, machine_rate, operation[, scale])
        line_target (int | float):
            Total production goal across all machines for the shift.
        parts (str):
            SQL fragment for filtering `Part IN (…)`, or empty string for no filter.
        shift_start (int):
            Unix timestamp marking the shift’s start.
        shift_time (int):
            Seconds elapsed since `shift_start`.

    Returns:
        tuple:
            machine_production (list of tuple):
                One entry per machine:
                (asset, prod_now, cell_colour, predicted_production, operation, machine_rate)
            coloured_op_production (list of tuple):
                Indexed by operation, each value is:
                (aggregated_predicted_production, color) for that operation.
    &#34;&#34;&#34;
    cursor = connections[&#39;prodrpt-md&#39;].cursor()

    sql =  &#39;SELECT Machine, COUNT(*) &#39;
    sql += &#39;FROM GFxPRoduction &#39;
    sql += &#39;WHERE TimeStamp &gt;= %s &#39;
    if parts:
        sql += f&#39;AND Part IN ({parts}) &#39;
    sql += &#39;GROUP BY Machine;&#39;

    # Get production from last 5 mins for color coding
    five_mins_ago = shift_start + shift_time - 300
    cursor.execute(sql, [five_mins_ago])
    prod_last5 = cursor.fetchall()

    # Get production since start of shift for current and prediciton
    cursor.execute(sql, [shift_start])
    prod_shift = cursor.fetchall()

    machine_production = []
    operation_production = [0]*200

    for machine in line_spec:  # build the list of tupples for the template
        asset = machine[0]  # this is the asset number on the dashboard
        # change this to the asset you want to take the count from
        source = machine[1]
        machine_rate = machine[2]
        operation = machine[3]
        scale = 1
        if len(machine) == 5:
            scale = machine[4]

        count_index = next(
            (i for i, v in enumerate(prod_last5) if v[0] == source), -1)
        if count_index &gt; -1:
            prod_last_five = prod_last5[count_index][1] * scale
        else:
            prod_last_five = 0

        count_index = next(
            (i for i, v in enumerate(prod_shift) if v[0] == source), -1)
        if count_index &gt; -1:
            prod_now = prod_shift[count_index][1] * scale
        else:
            prod_now = 0

        # Pediction
        try:
            shift_rate = prod_now / float(shift_time)
        except:
            shift_time = 100
            shift_rate = prod_now / float(shift_time)

        predicted_production = int(
            prod_now + (shift_rate * (28800 - shift_time)))

        # choose a color based on last 5 mins production vs machine rate
        # need 3200 in 8 hours.  Machine is one of X machines
        machine_target = line_target / machine_rate
        # need &#39;rate&#39; parts in 5 minutes to make 3200 across cell
        five_minute_target = (machine_target / 28800) * 300
        five_minute_percentage = int(prod_last_five / five_minute_target * 100)
        if five_minute_percentage &gt;= 100:
            cell_colour = &#39;#009700&#39;
        elif five_minute_percentage &gt;= 90:
            cell_colour = &#39;#4FC34F&#39;
        elif five_minute_percentage &gt;= 80:
            cell_colour = &#39;#A4F6A4&#39;
        elif five_minute_percentage &gt;= 70:
            cell_colour = &#39;#C3C300&#39;
        elif five_minute_percentage &gt;= 50:
            cell_colour = &#39;#DADA3F&#39;
        elif five_minute_percentage &gt;= 25:
            cell_colour = &#39;#F6F687&#39;  # light Yellow
        elif five_minute_percentage &gt;= 10:
            cell_colour = &#39;#F7BA84&#39;  # brown
        elif five_minute_percentage &gt; 0:
            cell_colour = &#39;#EC7371&#39;  # faded red
        else:
            if predicted_production == 0:
                cell_colour = &#39;#D5D5D5&#39;  # Grey
            else:
                cell_colour = &#39;#FF0400&#39;  # Red

        machine_production.append(
            (asset, prod_now, cell_colour,
             predicted_production, operation, machine_rate)
        )
        operation_production[operation] += predicted_production

    coloured_op_production = [0 for x in range(200)]
    for idx, op in enumerate(operation_production):
        if op &gt; line_target:
            color = &#39;#68FF33&#39;
        elif op &gt; line_target*.85:
            color = &#39;#F9FF33&#39;
        else:
            color = &#39;#FF9333&#39;
        coloured_op_production[idx] = (op, color)

    return machine_production, coloured_op_production</code></pre>
</details>
<div class="desc"><p>Compute detailed production metrics with color‐coding for machines and operations.</p>
<p>Retrieves counts from the GFxPRoduction table for both:
- The last 5 minutes (for real‐time color thresholds), and
- Since the shift start (for cumulative and prediction).</p>
<p>For each machine in <code>line_spec</code>, it calculates:
1. <code>prod_last_five</code> and <code>prod_now</code> (applying an optional scale factor).
2. A <code>predicted_production</code> value for the full 8‐hour shift based on current rate.
3. A <code>cell_colour</code> based on how the last‐five‐minute output compares to the per‐machine target.</p>
<p>Then aggregates predicted production by <code>operation</code> and applies color thresholds
at the operation level to produce an “expanded OP” structure.</p>
<h2 id="args">Args</h2>
<p>line_spec (list of tuple):
Each tuple defines a machine:
(asset, source, machine_rate, operation[, scale])
line_target (int | float):
Total production goal across all machines for the shift.
parts (str):
SQL fragment for filtering <code>Part IN (…)</code>, or empty string for no filter.
shift_start (int):
Unix timestamp marking the shift’s start.
shift_time (int):
Seconds elapsed since <code>shift_start</code>.</p>
<h2 id="returns">Returns</h2>
<p>tuple:
machine_production (list of tuple):
One entry per machine:
(asset, prod_now, cell_colour, predicted_production, operation, machine_rate)
coloured_op_production (list of tuple):
Indexed by operation, each value is:
(aggregated_predicted_production, color) for that operation.</p></div>
</dd>
<dt id="dashboards.views.get_machine_target"><code class="name flex">
<span>def <span class="ident">get_machine_target</span></span>(<span>machine_id, shift_start_unix, part_list=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_machine_target(machine_id, shift_start_unix, part_list=None):
    &#34;&#34;&#34;
    Returns the most recent non-deleted target for a given machine (or its alias group),
    optionally filtered by part_list, at or before the shift start.
    Tries the machine_id directly, or strips trailing letter, or sums targets from aliases.

    If part_list is provided, prints run‐minutes + scaled targets per part and a summary,
    then returns the truncated int “smart total” instead of the normal target.
    &#34;&#34;&#34;
    cursor = connections[&#39;prodrpt-md&#39;].cursor()

    def query_target(mid):
        qs = (
            OAMachineTargets.objects
            .filter(
                machine_id=mid,
                isDeleted=False,
                effective_date_unix__lte=shift_start_unix
            )
        )
        if part_list:
            qs = qs.filter(part__in=part_list)
        return qs.order_by(&#39;-effective_date_unix&#39;).first()

    def _compute_and_print_smart_total(mid):
        # only runs when part_list is provided
        start_ts = shift_start_unix
        end_ts   = time.time()

        # fetch ordered events for this machine &amp; those parts
        placeholder = &#34;, &#34;.join([&#34;%s&#34;] * len(part_list))
        sql = f&#34;&#34;&#34;
            SELECT TimeStamp, Part
              FROM GFxPRoduction
             WHERE Machine   = %s
               AND TimeStamp &gt;= %s
               AND TimeStamp &lt;  %s
               AND Part IN ({placeholder})
             ORDER BY TimeStamp ASC
        &#34;&#34;&#34;
        params = [mid, start_ts, end_ts] + part_list
        cursor.execute(sql, params)
        rows = cursor.fetchall()

        # accumulate run‐seconds per part
        totals = {p: 0.0 for p in part_list}
        if rows:
            current_part = rows[0][1]
            run_start    = rows[0][0]
            for ts, part in rows[1:]:
                if part != current_part:
                    totals[current_part] += (ts - run_start)
                    current_part = part
                    run_start    = ts
            totals[current_part] += (end_ts - run_start)

        # compute &amp; print per‐part plus sum up the smart total
        total_smart = 0.0
        for part, sec in totals.items():
            mins = int(sec // 60)

            part_obj = (
                OAMachineTargets.objects
                .filter(
                    machine_id=mid,
                    part=part,
                    isDeleted=False,
                    effective_date_unix__lte=shift_start_unix
                )
                .order_by(&#39;-effective_date_unix&#39;)
                .first()
            )

            if part_obj and part_obj.target is not None:
                # target is pieces per 7,200 min; rate per min = target/7200
                scaled = (part_obj.target / 7200.0) * mins
                total_smart += scaled
                # print(
                #     f&#34;Machine {mid} ran part {part} for {mins} minutes since shift start; &#34;
                #     f&#34;target for that period is {scaled:.2f}&#34;
                # )
            else:
                print(
                    f&#34;Machine {mid} ran part {part} for {mins} minutes since shift start; &#34;
                    f&#34;no target found for this part&#34;
                )

        # summary line
        # print(
        #     f&#34;So since shift start the total target across the part list for this machine is &#34;
        #     f&#34;{int(total_smart)}&#34;
        # )

        return int(total_smart)


    # —— original lookup logic follows —— #

    # Case 1: use machine_id directly
    result = query_target(machine_id)
    if result:
        if part_list:
            return _compute_and_print_smart_total(machine_id)
        return result.target

    # Case 2: strip trailing letter if needed
    if machine_id and machine_id[-1].isalpha():
        fallback_id     = machine_id[:-1]
        fallback_result = query_target(fallback_id)
        if fallback_result:
            if part_list:
                return _compute_and_print_smart_total(fallback_id)
            return fallback_result.target

    # Case 3: sum aliases
    if machine_id in MACHINE_TARGET_ALIASES:
        # if parts → sum each alias’s smart total
        if part_list:
            group_total = 0
            for aliased_id in MACHINE_TARGET_ALIASES[machine_id]:
                group_total += _compute_and_print_smart_total(aliased_id)
            return group_total

        # otherwise original target‐sum logic
        total = 0
        for aliased_id in MACHINE_TARGET_ALIASES[machine_id]:
            aliased_result = query_target(aliased_id)
            if aliased_result:
                total += aliased_result.target
        return total if total &gt; 0 else None

    return None</code></pre>
</details>
<div class="desc"><p>Returns the most recent non-deleted target for a given machine (or its alias group),
optionally filtered by part_list, at or before the shift start.
Tries the machine_id directly, or strips trailing letter, or sums targets from aliases.</p>
<p>If part_list is provided, prints run‐minutes + scaled targets per part and a summary,
then returns the truncated int “smart total” instead of the normal target.</p></div>
</dd>
<dt id="dashboards.views.list_and_update_shift_points"><code class="name flex">
<span>def <span class="ident">list_and_update_shift_points</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@login_required(login_url=&#34;login&#34;)
def list_and_update_shift_points(request):
    &#34;&#34;&#34;Display, add, update, or delete ShiftPoint entries based on TV number selection.

    **GET**:
        - Renders a list of all `ShiftPoint` objects.
        - If `tv_number` is provided in the query string, highlights the selected entry.
    
    **POST**:
        - **add_tv**:  
          Creates a new `ShiftPoint` with default points, assigning the next available `tv_number`,  
          then redirects to select the newly created entry.
        - **update_tv**:  
          Updates the `points` list of the specified `ShiftPoint` (by `update_tv_number`),  
          saving any changes and redirecting with a confirmation flag.
        - **delete_tv**:  
          Deletes the specified `ShiftPoint`, then decrements the `tv_number` of all subsequent entries  
          to maintain a continuous sequence, and redirects back to the list view.

    Args:
        request (HttpRequest): Incoming request, optionally containing:
            - `GET[&#39;tv_number&#39;]`: TV number of the entry to select.
            - `POST[&#39;add_tv&#39;]`, `POST[&#39;update_tv_number&#39;]`, or `POST[&#39;delete_tv_number&#39;]`.

    Returns:
        HttpResponse: Renders `dashboards/list_and_update_shift_points.html` with context:
            - `shift_points`: all `ShiftPoint` objects.
            - `selected_shift_point`: the currently selected entry (if any).
            - `selected_tv_number`: the selected TV number.
            - `new_tv_number`: the number assigned to a newly created entry (if added).
    &#34;&#34;&#34;
    selected_tv_number = request.GET.get(&#39;tv_number&#39;)
    shift_points = ShiftPoint.objects.all()
    selected_shift_point = None
    new_tv_number = None

    if selected_tv_number:
        selected_shift_point = get_object_or_404(ShiftPoint, tv_number=selected_tv_number)

    if request.method == &#39;POST&#39;:
        if &#39;add_tv&#39; in request.POST:
            points = [
                &#34;This is shift point 1.&#34;,
                &#34;This is shift point 2.&#34;,
                &#34;This is shift point 3.&#34;,
                &#34;This is shift point 4.&#34;
            ]  # Default points

            # Find the max tv_number in the database
            max_tv_number = ShiftPoint.objects.aggregate(Max(&#39;tv_number&#39;))[&#39;tv_number__max&#39;]
            if max_tv_number is None:
                max_tv_number = 0  # Handle case where there are no existing entries
            new_tv_number = max_tv_number + 1

            ShiftPoint.objects.create(tv_number=new_tv_number, points=points)
            return redirect(f&#39;{request.path}?tv_number={new_tv_number}&#39;)

        elif &#39;update_tv&#39; in request.POST:
            tv_number = request.POST.get(&#39;update_tv_number&#39;)
            shift_point = get_object_or_404(ShiftPoint, tv_number=tv_number)
            points = request.POST.getlist(&#39;point&#39;)
            if points == [&#39;&#39;]:  # Handle case where all points are removed
                points = []
            shift_point.points = points
            shift_point.save()
            return redirect(f&#34;{request.path}?tv_number={tv_number}&amp;changes_saved=true&#34;)

        elif &#39;delete_tv&#39; in request.POST:
            tv_number = int(request.POST.get(&#39;delete_tv_number&#39;))
            shift_point = get_object_or_404(ShiftPoint, tv_number=tv_number)
            shift_point.delete()
            
            # Decrement tv_number of subsequent TVs
            ShiftPoint.objects.filter(tv_number__gt=tv_number).update(tv_number=F(&#39;tv_number&#39;) - 1)
            return redirect(&#39;dashboards:list_and_update_shift_points&#39;)

    return render(request, &#39;dashboards/list_and_update_shift_points.html&#39;, {
        &#39;shift_points&#39;: shift_points,
        &#39;selected_shift_point&#39;: selected_shift_point,
        &#39;selected_tv_number&#39;: selected_tv_number,
        &#39;new_tv_number&#39;: new_tv_number,
    })</code></pre>
</details>
<div class="desc"><p>Display, add, update, or delete ShiftPoint entries based on TV number selection.</p>
<p><strong>GET</strong>:
- Renders a list of all <code>ShiftPoint</code> objects.
- If <code>tv_number</code> is provided in the query string, highlights the selected entry.</p>
<p><strong>POST</strong>:
- <strong>add_tv</strong>:<br>
Creates a new <code>ShiftPoint</code> with default points, assigning the next available <code>tv_number</code>,<br>
then redirects to select the newly created entry.
- <strong>update_tv</strong>:<br>
Updates the <code>points</code> list of the specified <code>ShiftPoint</code> (by <code>update_tv_number</code>),<br>
saving any changes and redirecting with a confirmation flag.
- <strong>delete_tv</strong>:<br>
Deletes the specified <code>ShiftPoint</code>, then decrements the <code>tv_number</code> of all subsequent entries<br>
to maintain a continuous sequence, and redirects back to the list view.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>HttpRequest</code></dt>
<dd>Incoming request, optionally containing:
- <code>GET['tv_number']</code>: TV number of the entry to select.
- <code>POST['add_tv']</code>, <code>POST['update_tv_number']</code>, or <code>POST['delete_tv_number']</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>HttpResponse</code></dt>
<dd>Renders <code>dashboards/list_and_update_shift_points.html</code> with context:
- <code>shift_points</code>: all <code>ShiftPoint</code> objects.
- <code>selected_shift_point</code>: the currently selected entry (if any).
- <code>selected_tv_number</code>: the selected TV number.
- <code>new_tv_number</code>: the number assigned to a newly created entry (if added).</dd>
</dl></div>
</dd>
<dt id="dashboards.views.log_shift_times"><code class="name flex">
<span>def <span class="ident">log_shift_times</span></span>(<span>shift_start, shift_time, actual_counts, part_list)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_shift_times(shift_start, shift_time, actual_counts, part_list):
    &#34;&#34;&#34;Calculate per-machine completion percentages against shift targets.

    Converts the shift start timestamp to local datetime, computes elapsed time,
    and for each machine in `actual_counts`, retrieves its raw shift target via
    `get_machine_target()`. If `part_list` is provided and the machine requires it,
    uses the raw target directly; otherwise scales the target by elapsed time
    over an 8-hour shift. Returns each machine’s actual count as a percentage
    of its target or &#34;N/A&#34; if no valid target exists.

    Args:
        shift_start (int): Unix timestamp marking the beginning of the shift.
        shift_time (int): Seconds elapsed since `shift_start`.
        actual_counts (list[tuple[str, int]]): List of `(machine_id, count)` pairs.
        part_list (list[str] | None): List of part numbers for machines that need
            a part-specific target lookup; use `None` if not applicable.

    Returns:
        list[tuple[str, int | str]]: For each machine, a tuple of
        `(machine_id, percentage)` where `percentage` is an integer
        percent of target completion or `&#34;N/A&#34;` if no target was found.
    &#34;&#34;&#34;
    from datetime import datetime, timedelta
    from zoneinfo import ZoneInfo



    # ————————————————————————————————————————————————————————————————

    est = ZoneInfo(&#34;America/New_York&#34;)
    start_dt = datetime.fromtimestamp(shift_start, tz=est)
    elapsed = timedelta(seconds=shift_time)

    total_actual = sum(count for _, count in actual_counts)
    minutes_elapsed = shift_time / 60.0

    # Prepare new list to hold (machine, pct_or_NA)
    swapped_counts = []

    for machine, count in actual_counts:
        # decide whether to pass part_list into the target lookup
        if part_list and machine in machines_requiring_part_list:
            raw_target = get_machine_target(machine, shift_start, part_list) or 0
            
        else:
            raw_target = get_machine_target(machine, shift_start) or 0


        if part_list and machine in machines_requiring_part_list:
            # compute pct only if we had a real target; otherwise N/A
            if raw_target &gt; 0:
                pct = int(count / raw_target * 100)
            else:
                pct = &#34;N/A&#34;
        else:
            # adjust for shift duration
            adjusted_target = raw_target * (minutes_elapsed / 7200.0)

            # compute pct only if we had a real target; otherwise N/A
            if adjusted_target &gt; 0:
                pct = int(count / adjusted_target * 100)
            else:
                pct = &#34;N/A&#34;


        # swap out the count for the pct or &#34;N/A&#34;
        swapped_counts.append((machine, pct))

    return swapped_counts</code></pre>
</details>
<div class="desc"><p>Calculate per-machine completion percentages against shift targets.</p>
<p>Converts the shift start timestamp to local datetime, computes elapsed time,
and for each machine in <code>actual_counts</code>, retrieves its raw shift target via
<code><a title="dashboards.views.get_machine_target" href="#dashboards.views.get_machine_target">get_machine_target()</a></code>. If <code>part_list</code> is provided and the machine requires it,
uses the raw target directly; otherwise scales the target by elapsed time
over an 8-hour shift. Returns each machine’s actual count as a percentage
of its target or "N/A" if no valid target exists.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>shift_start</code></strong> :&ensp;<code>int</code></dt>
<dd>Unix timestamp marking the beginning of the shift.</dd>
<dt><strong><code>shift_time</code></strong> :&ensp;<code>int</code></dt>
<dd>Seconds elapsed since <code>shift_start</code>.</dd>
<dt><strong><code>actual_counts</code></strong> :&ensp;<code>list[tuple[str, int]]</code></dt>
<dd>List of <code>(machine_id, count)</code> pairs.</dd>
<dt><strong><code>part_list</code></strong> :&ensp;<code>list[str] | None</code></dt>
<dd>List of part numbers for machines that need
a part-specific target lookup; use <code>None</code> if not applicable.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list[tuple[str, int | str]]</code></dt>
<dd>For each machine, a tuple of</dd>
</dl>
<p><code>(machine_id, percentage)</code> where <code>percentage</code> is an integer
percent of target completion or <code>"N/A"</code> if no target was found.</p></div>
</dd>
<dt id="dashboards.views.pms_index_view"><code class="name flex">
<span>def <span class="ident">pms_index_view</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pms_index_view(request):
    &#34;&#34;&#34;Render the PMDSData12 index page, collecting metadata from each installed app.

    Iterates over `settings.INSTALLED_APPS`, skipping Django internals and specified
    middleware/apps. For each remaining app, it attempts to import `&lt;app&gt;.app_info` and,
    if a `get_app_info()` function is present, calls it and collects its result.
    Finally, renders `index_pms.html` with:
      - `main_heading`: &#34;PMDSData12 Index&#34;
      - `title`: &#34;Index - pmdsdata12&#34;
      - `app_infos`: List of metadata objects returned by each app&#39;s `get_app_info()`.

    Args:
        request (HttpRequest): The incoming request object.

    Returns:
        HttpResponse: The rendered index page with the collected app information.
    &#34;&#34;&#34;
    context = {}
    context[&#34;main_heading&#34;] = &#34;PMDSData12 Index&#34;
    context[&#34;title&#34;] = &#34;Index - pmdsdata12&#34;
    
    app_infos = []
    for app in settings.INSTALLED_APPS:
        if app.startswith(&#39;django.&#39;) or app in [&#39;whitenoise.runserver_nostatic&#39;, &#39;debug_toolbar&#39;, &#39;django_bootstrap5&#39;, &#39;widget_tweaks&#39;, &#39;corsheaders&#39;]:
            continue

        try:
            app_info_module = import_module(f&#34;{app}.app_info&#34;)
            if hasattr(app_info_module, &#39;get_app_info&#39;):
                app_info = app_info_module.get_app_info()
                app_infos.append(app_info)
        except ModuleNotFoundError:
            pass
        except AttributeError as e:
            pass

    context[&#34;app_infos&#34;] = app_infos
    
    return render(request, &#39;index_pms.html&#39;, context)</code></pre>
</details>
<div class="desc"><p>Render the PMDSData12 index page, collecting metadata from each installed app.</p>
<p>Iterates over <code>settings.INSTALLED_APPS</code>, skipping Django internals and specified
middleware/apps. For each remaining app, it attempts to import <code>&lt;app&gt;.app_info</code> and,
if a <code>get_app_info()</code> function is present, calls it and collects its result.
Finally, renders <code>index_pms.html</code> with:
- <code>main_heading</code>: "PMDSData12 Index"
- <code>title</code>: "Index - pmdsdata12"
- <code>app_infos</code>: List of metadata objects returned by each app's <code>get_app_info()</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>HttpRequest</code></dt>
<dd>The incoming request object.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>HttpResponse</code></dt>
<dd>The rendered index page with the collected app information.</dd>
</dl></div>
</dd>
<dt id="dashboards.views.rejects_dashboard"><code class="name flex">
<span>def <span class="ident">rejects_dashboard</span></span>(<span>request, line)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rejects_dashboard(request, line):
    &#34;&#34;&#34;Display a rejects‐focused dashboard for a specified production line.

    Looks up the list of machine identifiers for the given `line` from `LINE_TO_MACHINES`,
    then for each machine:
      1. Fetches weekly production and reject breakdown via `fetch_weekly_data_for_machine()`.
      2. Fetches 24-hour pie chart data via `fetch_pie_chart_data()`.
      3. Embeds the pie data into the weekly stats.

    The aggregated data is JSON-encoded and passed to the `&#34;dashboards/rejects_dashboard.html&#34;` template.

    Args:
        request (HttpRequest): The incoming HTTP request.
        line (str): Key identifying the production line (e.g. `&#34;10R80&#34;`).

    Returns:
        HttpResponse: Renders the rejects dashboard template with context:
            `{&#34;json_data&#34;: &lt;pretty-printed JSON of per-machine stats&gt;}`.

    Raises:
        Http404: If `line` is not defined in `LINE_TO_MACHINES`.
    &#34;&#34;&#34;
    &#34;&#34;&#34;
    Renders the dashboard for a given line (e.g. 10R80),
    which internally shows machines defined in LINE_TO_MACHINES[line].
    &#34;&#34;&#34;
    machines = LINE_TO_MACHINES.get(line)
    if not machines:
        raise Http404(f&#34;Unknown line: {line}&#34;)

    data = {}
    for m in machines:
        weekly = fetch_weekly_data_for_machine(m)
        pie    = fetch_pie_chart_data(m)
        weekly[&#34;pie_chart_data&#34;] = pie
        data[m] = weekly

    return render(
        request,
        &#34;dashboards/rejects_dashboard.html&#34;,
        {&#34;json_data&#34;: json.dumps(data, indent=4)}
    )</code></pre>
</details>
<div class="desc"><p>Display a rejects‐focused dashboard for a specified production line.</p>
<p>Looks up the list of machine identifiers for the given <code>line</code> from <code>LINE_TO_MACHINES</code>,
then for each machine:
1. Fetches weekly production and reject breakdown via <code><a title="dashboards.views.fetch_weekly_data_for_machine" href="#dashboards.views.fetch_weekly_data_for_machine">fetch_weekly_data_for_machine()</a></code>.
2. Fetches 24-hour pie chart data via <code><a title="dashboards.views.fetch_pie_chart_data" href="#dashboards.views.fetch_pie_chart_data">fetch_pie_chart_data()</a></code>.
3. Embeds the pie data into the weekly stats.</p>
<p>The aggregated data is JSON-encoded and passed to the <code>"dashboards/rejects_dashboard.html"</code> template.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>HttpRequest</code></dt>
<dd>The incoming HTTP request.</dd>
<dt><strong><code>line</code></strong> :&ensp;<code>str</code></dt>
<dd>Key identifying the production line (e.g. <code>"10R80"</code>).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>HttpResponse</code></dt>
<dd>Renders the rejects dashboard template with context:
<code>{"json_data": &lt;pretty-printed JSON of per-machine stats&gt;}</code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Http404</code></dt>
<dd>If <code>line</code> is not defined in <code>LINE_TO_MACHINES</code>.</dd>
</dl></div>
</dd>
<dt id="dashboards.views.rejects_dashboard_finder"><code class="name flex">
<span>def <span class="ident">rejects_dashboard_finder</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rejects_dashboard_finder(request):
    &#34;&#34;&#34;Render a line‐selection page or redirect to the rejects dashboard for that line.

    On **GET**:
      - Displays a list of available production lines (keys of `LINE_TO_MACHINES`) 
        via the `&#34;dashboards/rejects_dashboard_finder.html&#34;` template.

    On **POST**:
      - Reads the selected `line` from `request.POST`.
      - If valid, redirects to the `rejects_dashboard_by_line` view, passing `line` as a URL argument.

    Args:
        request (HttpRequest): The incoming HTTP request, which on POST should include
            a `&#34;line&#34;` form field matching one of the available lines.

    Returns:
        HttpResponse: 
          - On GET, renders the finder template with context `{&#34;lines&#34;: lines}`.
          - On valid POST, returns an `HttpResponseRedirect` to the line’s rejects dashboard.
    &#34;&#34;&#34;
    lines = list(LINE_TO_MACHINES.keys())   # [&#34;10R80&#34;, &#34;AB1V&#34;, …]
    if request.method == &#34;POST&#34;:
        chosen = request.POST.get(&#34;line&#34;)
        if chosen in lines:
            return redirect(&#34;rejects_dashboard_by_line&#34;, line=chosen)
    return render(request,
                  &#34;dashboards/rejects_dashboard_finder.html&#34;,
                  {&#34;lines&#34;: lines})</code></pre>
</details>
<div class="desc"><p>Render a line‐selection page or redirect to the rejects dashboard for that line.</p>
<p>On <strong>GET</strong>:
- Displays a list of available production lines (keys of <code>LINE_TO_MACHINES</code>)
via the <code>"dashboards/rejects_dashboard_finder.html"</code> template.</p>
<p>On <strong>POST</strong>:
- Reads the selected <code>line</code> from <code>request.POST</code>.
- If valid, redirects to the <code>rejects_dashboard_by_line</code> view, passing <code>line</code> as a URL argument.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>HttpRequest</code></dt>
<dd>The incoming HTTP request, which on POST should include
a <code>"line"</code> form field matching one of the available lines.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>HttpResponse</code></dt>
<dd>
<ul>
<li>On GET, renders the finder template with context <code>{"lines": lines}</code>.</li>
<li>On valid POST, returns an <code>HttpResponseRedirect</code> to the line’s rejects dashboard.</li>
</ul>
</dd>
</dl></div>
</dd>
<dt id="dashboards.views.stamp_pdate4"><code class="name flex">
<span>def <span class="ident">stamp_pdate4</span></span>(<span>stamp)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stamp_pdate4(stamp):
    &#34;&#34;&#34;Format a Unix timestamp into a zero-padded &#39;HH:MM&#39; time string.

    Converts the given Unix timestamp to local time and returns the hour and
    minute, each left-padded with a &#39;0&#39; if necessary, in the format &#39;HH:MM&#39;.

    Args:
        stamp (int): Unix timestamp (seconds since epoch).

    Returns:
        str: Local time formatted as &#39;HH:MM&#39;.
    &#34;&#34;&#34;
    tm = time.localtime(stamp)
    ma = &#39;&#39;
    da = &#39;&#39;
    ha = &#39;&#39;
    mia = &#39;&#39;
    if tm[1] &lt; 10:
        ma = &#39;0&#39;
    if tm[2] &lt; 10:
        da = &#39;0&#39;
    if tm[3] &lt; 10:
        ha = &#39;0&#39;
    if tm[4] &lt; 10:
        mia = &#39;0&#39;
    y1 = str(tm[0])
    m1 = str(tm[1])
    d1 = str(tm[2])
    h1 = str(tm[3])
    mi1 = str(tm[4])

    pdate = y1 + &#39;-&#39; + (ma + m1) + &#39;-&#39; + (da + d1) + \
        &#39; &#39; + (ha + h1) + &#39;:&#39; + (mia + mi1)
    pdate = (ha + h1) + &#39;:&#39; + (mia + mi1)

    return pdate</code></pre>
</details>
<div class="desc"><p>Format a Unix timestamp into a zero-padded 'HH:MM' time string.</p>
<p>Converts the given Unix timestamp to local time and returns the hour and
minute, each left-padded with a '0' if necessary, in the format 'HH:MM'.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>stamp</code></strong> :&ensp;<code>int</code></dt>
<dd>Unix timestamp (seconds since epoch).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Local time formatted as 'HH:MM'.</dd>
</dl></div>
</dd>
<dt id="dashboards.views.stamp_shift_start"><code class="name flex">
<span>def <span class="ident">stamp_shift_start</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stamp_shift_start():
    &#34;&#34;&#34;Compute the Unix timestamps and durations for the current 8-hour shift.

    Determines which 8-hour shift block the local time falls into:
      - 06:00–14:00
      - 14:00–22:00
      - 22:00–06:00 (overnight)

    Returns:
        tuple:
            u (int): Unix timestamp at the start of the current shift.
            shift_time (int): Number of seconds elapsed since the shift started.
            shift_left (int): Number of seconds remaining until the shift ends.
            shift_end (int): Unix timestamp at the end of the current shift.
    &#34;&#34;&#34;
    stamp = int(time.time())
    tm = time.localtime(stamp)
    hour1 = tm[3]
    t = int(time.time())
    tm = time.localtime(t)
    shift_start = -2
    current_shift = 3
    if tm[3] &lt; 22 and tm[3] &gt;= 14:
        shift_start = 14
    elif tm[3] &lt; 14 and tm[3] &gt;= 6:
        shift_start = 6
    cur_hour = tm[3]
    if cur_hour == 22:
        cur_hour = -1

    # Unix Time Stamp for start of shift Area 1
    u = t - (((cur_hour-shift_start)*60*60)+(tm[4]*60)+tm[5])

    # Amount of seconds run so far on the shift
    shift_time = t-u

    # Amount of seconds left on the shift to run
    shift_left = 28800 - shift_time

    # Unix Time Stamp for the end of the shift
    shift_end = t + shift_left

    return u, shift_time, shift_left, shift_end</code></pre>
</details>
<div class="desc"><p>Compute the Unix timestamps and durations for the current 8-hour shift.</p>
<p>Determines which 8-hour shift block the local time falls into:
- 06:00–14:00
- 14:00–22:00
- 22:00–06:00 (overnight)</p>
<h2 id="returns">Returns</h2>
<p>tuple:
u (int): Unix timestamp at the start of the current shift.
shift_time (int): Number of seconds elapsed since the shift started.
shift_left (int): Number of seconds remaining until the shift ends.
shift_end (int): Unix timestamp at the end of the current shift.</p></div>
</dd>
<dt id="dashboards.views.stamp_shift_start_3"><code class="name flex">
<span>def <span class="ident">stamp_shift_start_3</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stamp_shift_start_3():
    &#34;&#34;&#34;Calculate the start, elapsed, remaining, and end times for 8-hour shifts.

    This uses a three-shift schedule with local start times at:
      - 07:00–15:00
      - 15:00–23:00
      - 23:00–07:00 (overnight)

    It determines the current shift based on the local hour, then computes:
      - `u`: Unix timestamp at the shift’s start
      - `shift_time`: seconds elapsed since `u`
      - `shift_left`: seconds remaining until the 8-hour shift ends
      - `shift_end`: Unix timestamp at the shift’s end

    Returns:
        tuple[int, int, int, int]:
            u (int): Shift start timestamp.
            shift_time (int): Seconds elapsed in current shift.
            shift_left (int): Seconds remaining in current shift.
            shift_end (int): Shift end timestamp.
    &#34;&#34;&#34;
    stamp = int(time.time())
    tm = time.localtime(stamp)
    hour1 = tm[3]
    t = int(time.time())
    tm = time.localtime(t)
    shift_start = -2
    current_shift = 3
    if tm[3] &lt; 23 and tm[3] &gt;= 15:
        shift_start = 15
    elif tm[3] &lt; 15 and tm[3] &gt;= 7:
        shift_start = 7
    cur_hour = tm[3]
    if cur_hour == 23:
        cur_hour = -1

    # Unix Time Stamp for start of shift Area 1
    u = t - (((cur_hour-shift_start)*60*60)+(tm[4]*60)+tm[5])

    # Amount of seconds run so far on the shift
    shift_time = t-u

    # Amount of seconds left on the shift to run
    shift_left = 28800 - shift_time

    # Unix Time Stamp for the end of the shift
    shift_end = t + shift_left

    return u, shift_time, shift_left, shift_end</code></pre>
</details>
<div class="desc"><p>Calculate the start, elapsed, remaining, and end times for 8-hour shifts.</p>
<p>This uses a three-shift schedule with local start times at:
- 07:00–15:00
- 15:00–23:00
- 23:00–07:00 (overnight)</p>
<p>It determines the current shift based on the local hour, then computes:
- <code>u</code>: Unix timestamp at the shift’s start
- <code>shift_time</code>: seconds elapsed since <code>u</code>
- <code>shift_left</code>: seconds remaining until the 8-hour shift ends
- <code>shift_end</code>: Unix timestamp at the shift’s end</p>
<h2 id="returns">Returns</h2>
<p>tuple[int, int, int, int]:
u (int): Shift start timestamp.
shift_time (int): Seconds elapsed in current shift.
shift_left (int): Seconds remaining in current shift.
shift_end (int): Shift end timestamp.</p></div>
</dd>
<dt id="dashboards.views.sub_index"><code class="name flex">
<span>def <span class="ident">sub_index</span></span>(<span>request)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sub_index(request):
    return redirect(&#39;dashboards:dashboard_index&#39;) </code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="dashboards.views.track_data"><code class="name flex">
<span>def <span class="ident">track_data</span></span>(<span>request, shift_end, shift_start, part, rate)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def track_data(request, shift_end, shift_start, part, rate):
    m = &#39;1533&#39;
    asset1 = request.session[&#39;asset1_area&#39;]
    asset2 = request.session[&#39;asset2_area&#39;]
    asset3 = request.session[&#39;asset3_area&#39;]
    asset4 = request.session[&#39;asset4_area&#39;]
    mrr = (rate*(28800))/float(28800)
    cursor = connections[&#39;prodrpt-md&#39;].cursor()
    sql = f&#39;SELECT * FROM GFxPRoduction&#39;
    sql += f&#39; where TimeStamp &gt;= {shift_start} and TimeStamp&lt; {shift_end} and part = &#34;{part}&#34;&#39;
    sql += f&#39; and Machine IN (&#34;{asset1}&#34;,&#34;{asset2}&#34;,&#34;{asset3}&#34;,&#34;{asset4}&#34;)&#39;
    cursor.execute(sql)
    result = cursor.fetchall()
    gr_list, brk1, brk2, multiplier = Graph_Data(
        shift_end, shift_start, m, result, mrr)
    return gr_list</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="dashboards.views.track_graph_track"><code class="name flex">
<span>def <span class="ident">track_graph_track</span></span>(<span>request, index)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def track_graph_track(request, index):
    &#34;&#34;&#34;Generate and display a time-series production graph for a single machine during the shift.

    This view:
    1. Sets a human-readable description in `session[&#39;track_track&#39;]`.
    2. Looks up the machine’s rate and part family (`prt`) from a hard-coded list based on `index`.
    3. Computes the effective per-second production rate from the 8-hour target.
    4. Stores the machine asset in several session keys (`asset1_area`, etc.).
    5. Determines the current shift window using `session[&#39;shift_start&#39;]` and a fixed 8-hour duration.
    6. Calls `track_data(request, end_time, start_time, prt, rate)` to retrieve the graph points.
    7. Renders the `&#34;dashboards/graph_track_track.html&#34;` template with the context key `&#39;GList&#39;`.

    Args:
        request (HttpRequest): The incoming HTTP request, which must include
            `session[&#39;shift_start&#39;]` (Unix timestamp for shift start).
        index (str): The machine identifier to track (used to select rate and part).

    Returns:
        HttpResponse: Renders the graph template with context `{&#39;GList&#39;: gr_list}`.
    &#34;&#34;&#34;
    prt = &#39;50-9341&#39;
    request.session[&#39;track_track&#39;] = &#39;Shift Track for Machine &#39; + str(index)

    mr7 = [
        # mainline
        (&#39;1504&#39;, 8, &#39;50-9341&#39;), (&#39;1506&#39;, 8, &#39;50-9341&#39;), (&#39;1519&#39;,
                                                         8, &#39;50-9341&#39;), (&#39;1520&#39;, 8, &#39;50-9341&#39;),  # Op10/20
        (&#39;1502&#39;, 4, &#39;50-9341&#39;), (&#39;1507&#39;, 4, &#39;50-9341&#39;),  # op30
        (&#39;1501&#39;, 4, &#39;50-9341&#39;), (&#39;1515&#39;, 4, &#39;50-9341&#39;),  # op40
        (&#39;1508&#39;, 3, &#39;50-9341&#39;), (&#39;1532&#39;, 3, &#39;50-9341&#39;),  # op50
        (&#39;1509&#39;, 2, &#39;50-9341&#39;),  # op60
        (&#39;1514&#39;, 2, &#39;50-9341&#39;),  # op70
        (&#39;1510&#39;, 2, &#39;50-9341&#39;),  # op80
        (&#39;1513&#39;, 2, &#39;50-9341&#39;),  # op90
        (&#39;1503&#39;, 2, &#39;50-9341&#39;),  # op100
        (&#39;1511&#39;, 2, &#39;50-9341&#39;),  # op110
        # offline
        (&#39;1518&#39;, 8, &#39;50-9341&#39;), (&#39;1521&#39;, 8, &#39;50-9341&#39;), (&#39;1522&#39;,
                                                         8, &#39;50-9341&#39;), (&#39;1523&#39;, 8, &#39;50-9341&#39;),  # Op10/20
        (&#39;1539&#39;, 4, &#39;50-9341&#39;), (&#39;1540&#39;, 4, &#39;50-9341&#39;),  # Op30
        (&#39;1524&#39;, 4, &#39;50-9341&#39;), (&#39;1525&#39;, 4, &#39;50-9341&#39;),  # Op40
        (&#39;1538&#39;, 3, &#39;50-9341&#39;),  # Op50
        (&#39;1541&#39;, 2, &#39;50-9341&#39;),  # Op60
        (&#39;1531&#39;, 2, &#39;50-9341&#39;),  # Op70
        (&#39;1527&#39;, 2, &#39;50-9341&#39;),  # Op80
        (&#39;1530&#39;, 2, &#39;50-9341&#39;),  # Op100
        (&#39;1528&#39;, 2, &#39;50-9341&#39;),  # Op110
        (&#39;1533&#39;, 1, &#39;50-9341&#39;),  # Final
        (&#39;1800&#39;, 2, &#39;50-0455&#39;), (&#39;1801&#39;, 2,
                                 &#39;50-0455&#39;), (&#39;1802&#39;, 2, &#39;50-0455&#39;),  # Op10/20
        (&#39;1529&#39;, 4, &#39;50-0455&#39;), (&#39;1543&#39;, 4, &#39;50-0455&#39;), (&#39;776&#39;,
                                                         4, &#39;50-0455&#39;), (&#39;1824&#39;, 4, &#39;50-0455&#39;),  # Op30
        (&#39;1804&#39;, 2, &#39;50-0455&#39;), (&#39;1805&#39;, 2, &#39;50-0455&#39;),  # Op40
        (&#39;1806&#39;, 1, &#39;50-0455&#39;),  # Op50
        (&#39;1808&#39;, 1, &#39;50-0455&#39;),  # Op60
        (&#39;1810&#39;, 1, &#39;50-0455&#39;),  # Op70
        (&#39;1815&#39;, 1, &#39;50-0455&#39;),  # Op80
        (&#39;1542&#39;, 1, &#39;50-0455&#39;),  # Op90
        (&#39;1812&#39;, 1, &#39;50-0455&#39;),  # Op100
        (&#39;1813&#39;, 1, &#39;50-0455&#39;),  # Op110
        (&#39;1816&#39;, 1, &#39;50-0455&#39;),  # Final
    ]


    for i in mr7:
        if i[0] == index:
            rate = i[1]
            prt = i[2]
    rate2 = 3200 / rate
    rate = rate2 / 8

    request.session[&#39;asset1_area&#39;] = index
    request.session[&#39;asset2_area&#39;] = index
    request.session[&#39;asset3_area&#39;] = index
    request.session[&#39;asset4_area&#39;] = index

    u = int(request.session[&#39;shift_start&#39;])
    t = int(u) + 28800
    t = int(time.time())

    gr_list = track_data(request, t, u, prt, rate)  # Get the Graph Data
    return render(request, &#34;dashboards/graph_track_track.html&#34;, {&#39;GList&#39;: gr_list})</code></pre>
</details>
<div class="desc"><p>Generate and display a time-series production graph for a single machine during the shift.</p>
<p>This view:
1. Sets a human-readable description in <code>session['track_track']</code>.
2. Looks up the machine’s rate and part family (<code>prt</code>) from a hard-coded list based on <code>index</code>.
3. Computes the effective per-second production rate from the 8-hour target.
4. Stores the machine asset in several session keys (<code>asset1_area</code>, etc.).
5. Determines the current shift window using <code>session['shift_start']</code> and a fixed 8-hour duration.
6. Calls <code><a title="dashboards.views.track_data" href="#dashboards.views.track_data">track_data()</a>(request, end_time, start_time, prt, rate)</code> to retrieve the graph points.
7. Renders the <code>"dashboards/graph_track_track.html"</code> template with the context key <code>'GList'</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>request</code></strong> :&ensp;<code>HttpRequest</code></dt>
<dd>The incoming HTTP request, which must include
<code>session['shift_start']</code> (Unix timestamp for shift start).</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>str</code></dt>
<dd>The machine identifier to track (used to select rate and part).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>HttpResponse</code></dt>
<dd>Renders the graph template with context <code>{'GList': gr_list}</code>.</dd>
</dl></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dashboards.views.sup_downForm"><code class="flex name class">
<span>class <span class="ident">sup_downForm</span></span>
<span>(</span><span>data=None,<br>files=None,<br>auto_id='id_%s',<br>prefix=None,<br>initial=None,<br>error_class=django.forms.utils.ErrorList,<br>label_suffix=None,<br>empty_permitted=False,<br>field_order=None,<br>use_required_attribute=None,<br>renderer=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class sup_downForm(forms.Form):
    machine = forms.CharField()
    reason = forms.CharField()
    priority = forms.CharField()</code></pre>
</details>
<div class="desc"><p>A collection of Fields, plus their associated data.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>django.forms.forms.Form</li>
<li>django.forms.forms.BaseForm</li>
<li>django.forms.utils.RenderableFormMixin</li>
<li>django.forms.utils.RenderableMixin</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dashboards.views.sup_downForm.base_fields"><code class="name">var <span class="ident">base_fields</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dashboards.views.sup_downForm.declared_fields"><code class="name">var <span class="ident">declared_fields</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="dashboards.views.sup_downForm.media"><code class="name">prop <span class="ident">media</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def _media(self):
    # Get the media property of the superclass, if it exists
    sup_cls = super(cls, self)
    try:
        base = sup_cls.media
    except AttributeError:
        base = Media()

    # Get the media definition for this class
    definition = getattr(cls, &#34;Media&#34;, None)
    if definition:
        extend = getattr(definition, &#34;extend&#34;, True)
        if extend:
            if extend is True:
                m = base
            else:
                m = Media()
                for medium in extend:
                    m += base[medium]
            return m + Media(definition)
        return Media(definition)
    return base</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dashboards.views.Graph_Data" href="#dashboards.views.Graph_Data">Graph_Data</a></code></li>
<li><code><a title="dashboards.views.cell_track_1467" href="#dashboards.views.cell_track_1467">cell_track_1467</a></code></li>
<li><code><a title="dashboards.views.cell_track_9341" href="#dashboards.views.cell_track_9341">cell_track_9341</a></code></li>
<li><code><a title="dashboards.views.cell_track_trilobe" href="#dashboards.views.cell_track_trilobe">cell_track_trilobe</a></code></li>
<li><code><a title="dashboards.views.compute_op_actual_and_oee" href="#dashboards.views.compute_op_actual_and_oee">compute_op_actual_and_oee</a></code></li>
<li><code><a title="dashboards.views.compute_part_durations_for_machine" href="#dashboards.views.compute_part_durations_for_machine">compute_part_durations_for_machine</a></code></li>
<li><code><a title="dashboards.views.dashboard_current_shift" href="#dashboards.views.dashboard_current_shift">dashboard_current_shift</a></code></li>
<li><code><a title="dashboards.views.dashboard_index_view" href="#dashboards.views.dashboard_index_view">dashboard_index_view</a></code></li>
<li><code><a title="dashboards.views.display_shift_points" href="#dashboards.views.display_shift_points">display_shift_points</a></code></li>
<li><code><a title="dashboards.views.efficiency_color" href="#dashboards.views.efficiency_color">efficiency_color</a></code></li>
<li><code><a title="dashboards.views.fetch_pie_chart_data" href="#dashboards.views.fetch_pie_chart_data">fetch_pie_chart_data</a></code></li>
<li><code><a title="dashboards.views.fetch_weekly_data_for_machine" href="#dashboards.views.fetch_weekly_data_for_machine">fetch_weekly_data_for_machine</a></code></li>
<li><code><a title="dashboards.views.get_cycle_time_seconds" href="#dashboards.views.get_cycle_time_seconds">get_cycle_time_seconds</a></code></li>
<li><code><a title="dashboards.views.get_db_connection" href="#dashboards.views.get_db_connection">get_db_connection</a></code></li>
<li><code><a title="dashboards.views.get_line_prod" href="#dashboards.views.get_line_prod">get_line_prod</a></code></li>
<li><code><a title="dashboards.views.get_line_prod2" href="#dashboards.views.get_line_prod2">get_line_prod2</a></code></li>
<li><code><a title="dashboards.views.get_machine_target" href="#dashboards.views.get_machine_target">get_machine_target</a></code></li>
<li><code><a title="dashboards.views.list_and_update_shift_points" href="#dashboards.views.list_and_update_shift_points">list_and_update_shift_points</a></code></li>
<li><code><a title="dashboards.views.log_shift_times" href="#dashboards.views.log_shift_times">log_shift_times</a></code></li>
<li><code><a title="dashboards.views.pms_index_view" href="#dashboards.views.pms_index_view">pms_index_view</a></code></li>
<li><code><a title="dashboards.views.rejects_dashboard" href="#dashboards.views.rejects_dashboard">rejects_dashboard</a></code></li>
<li><code><a title="dashboards.views.rejects_dashboard_finder" href="#dashboards.views.rejects_dashboard_finder">rejects_dashboard_finder</a></code></li>
<li><code><a title="dashboards.views.stamp_pdate4" href="#dashboards.views.stamp_pdate4">stamp_pdate4</a></code></li>
<li><code><a title="dashboards.views.stamp_shift_start" href="#dashboards.views.stamp_shift_start">stamp_shift_start</a></code></li>
<li><code><a title="dashboards.views.stamp_shift_start_3" href="#dashboards.views.stamp_shift_start_3">stamp_shift_start_3</a></code></li>
<li><code><a title="dashboards.views.sub_index" href="#dashboards.views.sub_index">sub_index</a></code></li>
<li><code><a title="dashboards.views.track_data" href="#dashboards.views.track_data">track_data</a></code></li>
<li><code><a title="dashboards.views.track_graph_track" href="#dashboards.views.track_graph_track">track_graph_track</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dashboards.views.sup_downForm" href="#dashboards.views.sup_downForm">sup_downForm</a></code></h4>
<ul class="">
<li><code><a title="dashboards.views.sup_downForm.base_fields" href="#dashboards.views.sup_downForm.base_fields">base_fields</a></code></li>
<li><code><a title="dashboards.views.sup_downForm.declared_fields" href="#dashboards.views.sup_downForm.declared_fields">declared_fields</a></code></li>
<li><code><a title="dashboards.views.sup_downForm.media" href="#dashboards.views.sup_downForm.media">media</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
